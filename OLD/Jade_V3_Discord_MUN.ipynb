{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jade_V3_Discord_MUN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "HQfBYlHPqRve",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FUSE For Google Drive\n",
        "Yes, you need this."
      ]
    },
    {
      "metadata": {
        "id": "DC7Lh4iYEYAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2381
        },
        "outputId": "ff5daa12-b73d-47da-e1aa-510d21a0bc9a"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpc4yjgs2q/pubring.gpg' created\n",
            "gpg: /tmp/tmpc4yjgs2q/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19816 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bGlnU9MEEayc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yeAPcfm4EcuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "65013335-69a0-4166-8333-867afc82ff05"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v08a5t8YEeMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5776
        },
        "outputId": "c6c43a62-a0f5-43aa-9118-997f35308519"
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print('Files in Drive:')\n",
        "!ls drive/\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in Drive:\n",
            "ls: reading directory 'drive/': Input/output error\n",
            "1.4.ods\n",
            "20170130_115904.jpg\n",
            "2017-05-17_21-19-51.mp4\n",
            "2.7 Graphing.ods\n",
            "3.06.ods\n",
            "3.07.ods\n",
            "3-5.ods\n",
            "980ed059a1825a1150702d643aae6fb6_2_3_photo.jpg\n",
            "AcaPrep Responsibility.pdf\n",
            "AgateV2\n",
            "Alternate Ending F. 451.odt\n",
            "baby.net\n",
            "Badminton - Jess Fan.odt\n",
            "bin\n",
            "Brainstorming SAQ APUSH.odt\n",
            "Calling.odt\n",
            "Chap 5 Project - Wednesday.odt\n",
            "ChatLearner-master\n",
            "Chem L80 test results.odt\n",
            "Citizenship.pdf\n",
            "Classroom\n",
            "Classroom (1913bb2c)\n",
            "Colab Notebooks\n",
            "Compare and Contrast Poetry Essay - Jess Fan.odt\n",
            "Compare and Contrast Poetry Essay - Jess Fan (Revision).odt\n",
            "compassion (1).ppt.pdf\n",
            "compassion.ppt\n",
            "CONCLUSION.odt\n",
            "Copy of Academic Success Plan Reflection.odt\n",
            "Copy of Academic Success Plan Reflection.odt (78574d68)\n",
            "Copy of AcaPrep 9 - Student Academic Plan.odt\n",
            "Copy of Acaprep Final.odt\n",
            "Copy of Action Poem - Jess Fan.odt\n",
            "Copy of Activity Request Form.odt\n",
            "Copy of Alternate Ending F. 451.odt\n",
            "Copy of Catalog Poem - Jess Fan.odt\n",
            "Copy of Chalk Project-Justin, Joey, Jess, and Issabella.pdf\n",
            "Copy of Chalk Project-Justin, Joey, Jess, and Issabella.pdf (76308f45)\n",
            "Copy of Copy of Alternate Ending F. 451.odt\n",
            "Copy of Copy of Jess Fan - Final draft -Lab Report -Bunsen Burner.odt\n",
            "Copy of Copy of KCS #4 Outline - Od-Ed or Essay.odt\n",
            "Copy of Copy of  R&J Act III Lit Circle Questions.odt\n",
            "Copy of Copy of R&J Act II Lit Circle Questions.odt\n",
            "Copy of Copy of Sketchnotes for Shakespeare.odt\n",
            "Copy of Copy of Sketchnotes for Shakespeare.odt (ad51d9b5)\n",
            "Copy of Copy of WoW Revised Template.odt\n",
            "Copy of Copy of WoW Revised Template.odt (2083a3b2)\n",
            "Copy of Digital Footprint Quiz.odt\n",
            "Copy of Digital Leadership Day 1.pdf\n",
            "Copy of Digital Leadership Day 3.pdf\n",
            "Copy of Empathy.pdf\n",
            "Copy of ENG 1.odt\n",
            "Copy of Final Essay Revions.odt\n",
            "Copy of Final Essay Revision Checklist CCP.odt\n",
            "Copy of Graphic Organizer Literature Circle Roles DD.odt\n",
            "Copy of Graphic Organizer Literature Circle Roles LITILLUM.odt\n",
            "Copy of Graphic Organizer Literature Circle Roles SUMM.odt\n",
            "Copy of Graphic Organizer Literature Circle Roles WW.odt\n",
            "Copy of Guest Pass.odt\n",
            "Copy of Homework Essay V2.odt\n",
            "Copy of Jess Fan - Rough draft -Lab Report -Bunsen Burner.odt\n",
            "Copy of KCS #4 Outline - Od-Ed or Essay.odt\n",
            "Copy of KCS Essay Outline Revised 2016.odt\n",
            "Copy of Logic Assignment 2017.doc.odt\n",
            "Copy of Metaphor.docx.odt\n",
            "Copy of Reading Qs 65-76.odt\n",
            "Copy of REVISED Chalk Project-Justin, Joey, Jess, and Issabella.pdf\n",
            "Copy of Sample Source Cards.pdf\n",
            "Copy of Search Strings Practice.odt\n",
            "Copy of Self Awareness and Self Advocacy.docx.odt\n",
            "Copy of Senior Brag Sheet.odt\n",
            "Copy of Sketchnote AcaPrep (March 10 & 13).pdf\n",
            "Copy of Source and Note Cards (print double-sided).pdf\n",
            "Copy of Source and Note Cards (print double-sided).pdf (35ef63f3)\n",
            "Copy of  Spark Talk Outline - Jess Fan.odt\n",
            "Copy of Steve Jobs Essay.odt\n",
            "Copy of Storyboard and Shotlist Worksheet.odt\n",
            "Copy of Team Logo.pdf\n",
            "Copy of [Template] Making Chalk Update 1 P-6.odt\n",
            "Copy of The Big Game Commercial Analysis.odt\n",
            "Copy of TPCASTT(revised).docx.odt\n",
            "Copy of Yearbook Feedback.zip\n",
            "created.txt\n",
            "CYBER PATRIOT PROGRAM (SNACK SELECTION???.zip\n",
            "DATA\n",
            "DRAMA LITERARY TERMS.pdf.odt\n",
            "DSC01186.JPG\n",
            "DSC01187.JPG\n",
            "DSC01188.JPG\n",
            "DSC01521.JPG\n",
            "DSC01522.JPG\n",
            "DSC01523.JPG\n",
            "DSC01524.JPG\n",
            "DSC01525.JPG\n",
            "DSC01540.JPG\n",
            "DSC01541.JPG\n",
            "DSC01542.JPG\n",
            "DSC01543.JPG\n",
            "DSC01544.JPG\n",
            "DSC01545.JPG\n",
            "DSC01546.JPG\n",
            "DSC01547.JPG\n",
            "DSC01551.JPG\n",
            "DSC01552.JPG\n",
            "DSC01553.JPG\n",
            "DSC01554.JPG\n",
            "Dumaine.pdf\n",
            "E 45 Aircraft Cycles Render and High-Poly.mp4\n",
            "Eglamour.pdf\n",
            "ENG 1.odt\n",
            "English 9H Literary Devices Deck.pdf\n",
            "English 9H Literary Devices Deck Pt 2.pdf\n",
            "English Dialect Valentine.odt\n",
            "EnglishHonors9SummerReadingAssignment.docx.odt\n",
            "English Linking sentences.odt\n",
            "Enviro. Proj.odt\n",
            "Everybody’s lost.odt\n",
            "Exigent.odt\n",
            "Experiment Procedure (Chalk).odt\n",
            "Final Draft Lab Report (Catalase) - Jess Fan.odt\n",
            "Final Essay Revision Checklist IDOL.odt\n",
            "Final Essay Revision Checklist NITA.odt\n",
            "FIN N FAN EP1.mp4\n",
            "GAN\n",
            "GAN1\n",
            "GECA.odt\n",
            "Getting started\n",
            "Getting started (4609328f)\n",
            "girder.net\n",
            "girl1.png\n",
            "GO RE\n",
            "Graphing 2.5.ods\n",
            "Graphing 2.8.ods\n",
            "Griffin2 1080p.jpg\n",
            "GS_FIN02.mp4\n",
            "head.net\n",
            "Hi.odt\n",
            "History Poster.odt\n",
            "Homage of WoW Revised Template.odt\n",
            "Homer\n",
            "Homework Essay V1.odt\n",
            "Homework Essay V3.odt\n",
            "Homework & Impact(s) research\n",
            "Homework PRT.wav\n",
            "HW_GIF.gif\n",
            "HW (Responses).ods\n",
            "Image (5).jpg\n",
            "Image (9).jpg.pdf\n",
            "img\n",
            "IMG_3884.JPG\n",
            "IMG_4631 (EDT).jpg\n",
            "IMG_4631.JPG\n",
            "IMG_4632.JPG\n",
            "IMG_4633.JPG\n",
            "IMG_4634.JPG\n",
            "IMG_4635.JPG\n",
            "IMG_4637 (EDT).jpg\n",
            "IMG_4637.JPG\n",
            "IMG_4639 (EDT).jpg\n",
            "IMG_4639.JPG\n",
            "IMG_4710 (EDT).png\n",
            "IMG_4710.JPG\n",
            "IMG_4710.psd\n",
            "IMG_4712 (EDT).png\n",
            "IMG_4712.JPG\n",
            "IMG_4712.psd\n",
            "Imogen.pdf\n",
            "IT Email Draft.odt\n",
            "Jack Dab.gif\n",
            "Jade_Chess\n",
            "Jade_Site\n",
            "Jade_ST_v1.2.0 (test)\n",
            "Jade v02\n",
            "Jade V2\n",
            "JadeV3\n",
            "Jade_V3_Discord (1).ipynb\n",
            "Jade_V3_Discord (66c16b97).ipynb\n",
            "Jade_V3_Discord.ipynb\n",
            "JadeV3Train\n",
            "Java\n",
            "Jess Fan Andrew Tan Kahlo Constructed Response.odt\n",
            "Jess Fan - How Can We Make Chalk (2474fffc).docx\n",
            "Jess Fan - How Can We Make Chalk.docx\n",
            "Jess Fan - Rubric for Making Chalk (c2c072bf).docx\n",
            "Jess Fan - Rubric for Making Chalk.docx\n",
            "Jess Fan - Write a letter to a future GECA student.  Please follow the instructions detailed in the attached doc..odt\n",
            "jess loves life. really. he does..odt\n",
            "JF4000.png\n",
            "J&S1\n",
            "KCS #2\n",
            "KCS #2 - AcaPrep Time Management - Jess Fan.odt\n",
            "L90 Diagram.png\n",
            "Lab Report Graphs.ods\n",
            "Lab Report.odt\n",
            "lesson_5_absolute_zero_powerpoint.pptx.pdf\n",
            "Literary Devices Deck.pdf\n",
            "Lotus-Eaters Essay Draft Prompt.odt\n",
            "Lotus Eaters Essay.odt\n",
            "Lyricist.pdf\n",
            "M3.04.01H.odt\n",
            "M3.04.02H.odt\n",
            "main.30102.com.imageline.FLM.obb\n",
            "Math 5 Questions.odt\n",
            "Math_Homework\n",
            "Math Proj 1.odt\n",
            "MATH (U6)\n",
            "M&M1\n",
            "Mock GECA 9th grade Petition to run for ASB_Leadership office 2015-2016.odt\n",
            "Moist paper towels.ods\n",
            "MVI_3345.MOV\n",
            "MVI_3374.MOV\n",
            "neck.net\n",
            "neural_style.ipynb\n",
            "neural-style-tf-master\n",
            "Nice Sad thing.mp3\n",
            "nmt-chatbot-master\n",
            "Nonconformity in the Alchemist.odt\n",
            "Nyan Temmie + JEF Nyan Cat Remix.mp4\n",
            "Outline - lit analysis.doc (Jess).odt\n",
            "p31ProgramFromHeaven\n",
            "Picture Request Form (HW DANCE).zip\n",
            "Pixel Gun 3D Hack With Myster07's API.apk\n",
            "Plagiarism AcaPrep.pdf\n",
            "prefixless_CH.txt\n",
            "Pressing a button poem.odt\n",
            "Princeton APUSH.odt\n",
            "programs_187.pdf\n",
            "PSAT Practice.odt\n",
            "pygame-1.9.4-cp27-cp27m-win_amd64.whl\n",
            "rdcman.msi\n",
            "reader.net\n",
            "result.png\n",
            "results-20180520-114635.csv.ods\n",
            "results-20180520-115828.csv.ods\n",
            "results-20180520-132728.csv.ods\n",
            "Resume.odt\n",
            "RE_train\n",
            "Riley Curry.ods\n",
            "Says, Means, Matters.odt\n",
            "Semester 1 Essay (APWH).odt\n",
            "SENIORS.gif\n",
            "Shogi_REENF\n",
            "span chap 11.odt\n",
            "Span chap 12.odt\n",
            "SpanChap9.odt\n",
            "Spanish Chap 4.odt\n",
            "Spanish Chap 8.odt\n",
            "Spanish chaper 5.odt\n",
            "Spanish Chapter 6.odt\n",
            "Spanish Final.odt\n",
            "Spanish pg1-28 wkbk .odt\n",
            "Spanish pg29-59.odt\n",
            "Spanish pg61-92.odt\n",
            "SPAN WKST.odt\n",
            "Speech V1.odt\n",
            "Steve Jobs Essay.odt\n",
            "Steve Jobs.odt\n",
            "STORYBOARD.odt\n",
            "Story_Data\n",
            "StrayerAP3e_TRM_CH14_Detailed Chapter Outline\n",
            "strayersources3e_guidedreadingexercise_ch11.docx\n",
            "strayersources3e_guidedreadingexercise_ch11.docx.odt\n",
            "Stress management - Jess Fan.pptx.pdf\n",
            "style2paints\n",
            "Style_PNTR\n",
            "swow_cppw.indd.pdf\n",
            "tail.net\n",
            "The way words are carefully grouped around the word “sky” and have an.odt\n",
            "Time management Final.odt\n",
            "Time management.odt\n",
            "Time Management - Reflection.pdf\n",
            "tmp\n",
            "ToMakeaPowerfulSpeech.docx.odt\n",
            "To Make a Powerful Speech.pptx.pdf\n",
            "T REEEEEEEEEEEEEEEEEEEEEEEE.odt\n",
            "U72DXG576ML3IJLT2OC9OKUNNQOJDJQC_0.jpg\n",
            "ubiquitous.odt\n",
            "Unilever’s Threat to Technological Advertisement Mediums.odt\n",
            "Untitled document.odt\n",
            "Untitled document.odt (1a045902)\n",
            "Untitled document.odt (56ac85d9)\n",
            "Untitled document.odt (59eccf8f)\n",
            "Untitled document.odt (6e154fed)\n",
            "Untitled document.odt (81f5ca5d)\n",
            "Untitled document.odt (8454a114)\n",
            "Untitled document.odt (84c176d9)\n",
            "Untitled document.odt (864b3313)\n",
            "Untitled document.odt (a3768958)\n",
            "Untitled document.odt (af925bcb)\n",
            "Untitled document.odt (b4a6a2d1)\n",
            "Untitled document.odt (bf49feb7)\n",
            "Untitled document.odt (c6555399)\n",
            "Untitled document.odt (ce96c4ec)\n",
            "Untitled document.odt (d1a87c4d)\n",
            "Untitled document.odt (d1e2f4e0)\n",
            "Untitled drawing.png\n",
            "Untitled presentation.pdf\n",
            "Untitled spreadsheet.ods\n",
            "Untitled spreadsheet.ods (44488b81)\n",
            "Untitled spreadsheet.ods (56321541)\n",
            "Untitled spreadsheet.ods (9b5c8f64)\n",
            "Untitled spreadsheet.ods (afcf166d)\n",
            "Untitled spreadsheet.ods (be38b9b4)\n",
            "Untitled spreadsheet.ods (cfdbd8b6)\n",
            "U.S.D.A. Approves Modified Potato. Next Up: French Fry Fans..odt\n",
            "Visual_.pdf\n",
            "wallhaven-607479.jpg\n",
            "Water Outline.odt\n",
            "Water Research Paper Draft (Copy).odt\n",
            "Water Research Paper.odt\n",
            "WEEEEEEEEEEW EEEEEEEEMAIIL.odt\n",
            "WF Final.gif\n",
            "Windows.iso\n",
            "word-rnn-tensorflow-master\n",
            "Works cited HW essay.odt\n",
            "WOW Deception.odt\n",
            "WOW \"Oddesey\".odt\n",
            "written (1).txt.odt\n",
            "written.txt.odt\n",
            "XUGQ0NR59CODIGUGX7L0YWJCW74OK4VX_0.jpg\n",
            "Yearbook Feedback (Responses).ods\n",
            "Yearbook Feedback.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K2mfRGkIqk7X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Imports\n",
        "You may or may not know this, but Jade needs these things."
      ]
    },
    {
      "metadata": {
        "id": "KJwBNcoB0Ly_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d66d4c7-cd66-4bef-b899-fdc5797f7281"
      },
      "cell_type": "code",
      "source": [
        "!ls ./"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JSGF6pDgnLpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4390
        },
        "outputId": "49529431-9df3-453c-af30-586b1d5a8fb2"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
        "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!rm -rf models\n",
        "!pip install discord.py\n",
        "!pip install dblpy\n",
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install plotly"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Counting objects: 21671, done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 21671 (delta 0), reused 0 (delta 0), pack-reused 21665\u001b[K\n",
            "Receiving objects: 100% (21671/21671), 558.45 MiB | 42.35 MiB/s, done.\n",
            "Resolving deltas: 100% (12803/12803), done.\n",
            "Checking out files: 100% (2670/2670), done.\n",
            "Selecting previously unselected package libprotobuf10:amd64.\n",
            "(Reading database ... 19845 files and directories currently installed.)\n",
            "Preparing to unpack .../libprotobuf10_3.0.0-9ubuntu5_amd64.deb ...\n",
            "Unpacking libprotobuf10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Selecting previously unselected package libprotoc10:amd64.\n",
            "Preparing to unpack .../libprotoc10_3.0.0-9ubuntu5_amd64.deb ...\n",
            "Unpacking libprotoc10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Selecting previously unselected package libprotobuf-java.\n",
            "Preparing to unpack .../libprotobuf-java_3.0.0-9ubuntu5_all.deb ...\n",
            "Unpacking libprotobuf-java (3.0.0-9ubuntu5) ...\n",
            "Selecting previously unselected package protobuf-compiler.\n",
            "Preparing to unpack .../protobuf-compiler_3.0.0-9ubuntu5_amd64.deb ...\n",
            "Unpacking protobuf-compiler (3.0.0-9ubuntu5) ...\n",
            "Setting up libprotobuf-java (3.0.0-9ubuntu5) ...\n",
            "Setting up libprotobuf10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libprotoc10:amd64 (3.0.0-9ubuntu5) ...\n",
            "Setting up protobuf-compiler (3.0.0-9ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Collecting discord.py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/3c/2a97b47fd8839f8863241857bbd6a3998d1de1662b788c8d9322e5a40901/discord.py-0.16.12.tar.gz (414kB)\n",
            "\u001b[K    100% |████████████████████████████████| 419kB 7.9MB/s \n",
            "\u001b[?25hCollecting aiohttp<1.1.0,>=1.0.0 (from discord.py)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/5a/7b81ea8729d41f44c6fe6a116e466c8fb884950a0061aa3768dbd6bee2f8/aiohttp-1.0.5.tar.gz (499kB)\n",
            "\u001b[K    100% |████████████████████████████████| 501kB 10.7MB/s \n",
            "\u001b[?25hCollecting websockets<4.0,>=3.1 (from discord.py)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/3a/2c3a5b2c65179851e80d4acae30cffb2610a8740a8edb2afbeaa564283f8/websockets-3.4-cp36-cp36m-manylinux1_x86_64.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.6/dist-packages (from aiohttp<1.1.0,>=1.0.0->discord.py) (3.0.4)\n",
            "Collecting multidict>=2.0 (from aiohttp<1.1.0,>=1.0.0->discord.py)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/92/00de45dc04830f8c715bcfbf96f6e531b26d564d7bff63ba92e7c459c82a/multidict-4.4.0-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K    100% |████████████████████████████████| 389kB 12.8MB/s \n",
            "\u001b[?25hCollecting async_timeout (from aiohttp<1.1.0,>=1.0.0->discord.py)\n",
            "  Downloading https://files.pythonhosted.org/packages/96/0f/e6357458c87fb4ed8f3df215773f3caad40968f10e05552cbd8bd28415e4/async_timeout-3.0.0-py3-none-any.whl\n",
            "Building wheels for collected packages: discord.py, aiohttp\n",
            "  Running setup.py bdist_wheel for discord.py ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/59/bd/03/fb6abbe73e166bf826ff81d0e757c9a83bad0f35d0ae4307f8\n",
            "  Running setup.py bdist_wheel for aiohttp ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/4c/de/66/cec380d8676420923cd9da128ab8009c9010f18174bfa3beaf\n",
            "Successfully built discord.py aiohttp\n",
            "Installing collected packages: multidict, async-timeout, aiohttp, websockets, discord.py\n",
            "Successfully installed aiohttp-1.0.5 async-timeout-3.0.0 discord.py-0.16.12 multidict-4.4.0 websockets-3.4\n",
            "Collecting dblpy\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/2e/d136bd593a1fe545d6e82c9317169beef2729ecb2878352c58cd8f7b374f/dblpy-0.1.6.tar.gz\n",
            "Collecting aiohttp>=2.3.9 (from dblpy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/f9/c22977fc95346911d8fe507f90c3c4e4f445fdf339b750be6f03f090498d/aiohttp-3.4.4-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.1MB 5.8MB/s \n",
            "\u001b[?25hCollecting ratelimiter>=1.2.0.post0 (from dblpy)\n",
            "  Downloading https://files.pythonhosted.org/packages/51/80/2164fa1e863ad52cc8d870855fba0fbb51edd943edffd516d54b5f6f8ff8/ratelimiter-1.2.0.post0-py3-none-any.whl\n",
            "Requirement already satisfied: multidict<5.0,>=4.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=2.3.9->dblpy) (4.4.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=2.3.9->dblpy) (3.0.4)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\" (from aiohttp>=2.3.9->dblpy)\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting attrs>=17.3.0 (from aiohttp>=2.3.9->dblpy)\n",
            "  Downloading https://files.pythonhosted.org/packages/3a/e1/5f9023cc983f1a628a8c2fd051ad19e76ff7b142a0faf329336f9a62a514/attrs-18.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=2.3.9->dblpy) (3.0.0)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp>=2.3.9->dblpy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/67/df71b367680e06bb4127e3df6189826d4b9daebf83c3bd5b9341c99ef528/yarl-1.2.6-cp36-cp36m-manylinux1_x86_64.whl (253kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from idna-ssl>=1.0; python_version < \"3.7\"->aiohttp>=2.3.9->dblpy) (2.6)\n",
            "Building wheels for collected packages: dblpy, idna-ssl\n",
            "  Running setup.py bdist_wheel for dblpy ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/36/91/5a/e207def2a047411d15c679214d79d6ddfb88ed17b522de482f\n",
            "  Running setup.py bdist_wheel for idna-ssl ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built dblpy idna-ssl\n",
            "\u001b[31mdiscord-py 0.16.12 has requirement aiohttp<1.1.0,>=1.0.0, but you'll have aiohttp 3.4.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: idna-ssl, attrs, yarl, aiohttp, ratelimiter, dblpy\n",
            "  Found existing installation: aiohttp 1.0.5\n",
            "    Uninstalling aiohttp-1.0.5:\n",
            "      Successfully uninstalled aiohttp-1.0.5\n",
            "Successfully installed aiohttp-3.4.4 attrs-18.2.0 dblpy-0.1.6 idna-ssl-1.1.0 ratelimiter-1.2.0.post0 yarl-1.2.6\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fontconfig libcairo2 libdatrie1 libgif7 libgraphite2-3 libharfbuzz0b\n",
            "  libjbig0 liblept5 libopenjp2-7 libpango-1.0-0 libpangocairo-1.0-0\n",
            "  libpangoft2-1.0-0 libpixman-1-0 libtesseract-data libtesseract3 libthai-data\n",
            "  libthai0 libtiff5 libwebp6 libxcb-render0 libxcb-shm0 tesseract-ocr-eng\n",
            "  tesseract-ocr-equ tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  fontconfig libcairo2 libdatrie1 libgif7 libgraphite2-3 libharfbuzz0b\n",
            "  libjbig0 liblept5 libopenjp2-7 libpango-1.0-0 libpangocairo-1.0-0\n",
            "  libpangoft2-1.0-0 libpixman-1-0 libtesseract-data libtesseract3 libthai-data\n",
            "  libthai0 libtiff5 libwebp6 libxcb-render0 libxcb-shm0 tesseract-ocr\n",
            "  tesseract-ocr-eng tesseract-ocr-equ tesseract-ocr-osd\n",
            "0 upgraded, 25 newly installed, 0 to remove and 0 not upgraded.\n",
            "Need to get 16.7 MB of archives.\n",
            "After this operation, 63.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu artful/main amd64 fontconfig amd64 2.11.94-0ubuntu2 [177 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu artful/main amd64 libjbig0 amd64 2.1-3.1 [26.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful/main amd64 libpixman-1-0 amd64 0.34.0-1 [230 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-render0 amd64 1.12-1ubuntu1 [14.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-shm0 amd64 1.12-1ubuntu1 [5,482 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu artful/main amd64 libcairo2 amd64 1.14.10-1ubuntu1 [558 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu artful/main amd64 libdatrie1 amd64 0.2.10-5 [17.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu artful/main amd64 libgif7 amd64 5.1.4-1 [30.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu artful/main amd64 libgraphite2-3 amd64 1.3.10-2 [78.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu artful/main amd64 libharfbuzz0b amd64 1.4.2-1 [211 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu artful/universe amd64 libopenjp2-7 amd64 2.2.0-1 [133 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libtiff5 amd64 4.0.8-5ubuntu0.1 [150 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu artful/main amd64 libwebp6 amd64 0.6.0-3 [181 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu artful/universe amd64 liblept5 amd64 1.74.4-1 [928 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu artful/main amd64 libthai-data all 0.1.26-3 [132 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu artful/main amd64 libthai0 amd64 0.1.26-3 [17.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu artful/main amd64 libpango-1.0-0 amd64 1.40.12-1 [152 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu artful/main amd64 libpangoft2-1.0-0 amd64 1.40.12-1 [33.2 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu artful/main amd64 libpangocairo-1.0-0 amd64 1.40.12-1 [20.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu artful/universe amd64 libtesseract-data all 3.04.01-6 [5,300 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu artful/universe amd64 libtesseract3 amd64 3.04.01-6 [1,103 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu artful/universe amd64 tesseract-ocr-eng all 3.04.00-1 [8,824 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu artful/universe amd64 tesseract-ocr-osd all 3.04.00-1 [2,988 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu artful/universe amd64 tesseract-ocr-equ all 3.04.00-1 [568 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu artful/universe amd64 tesseract-ocr amd64 3.04.01-6 [133 kB]\n",
            "Fetched 16.7 MB in 2s (7,054 kB/s)\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 19898 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.11.94-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.11.94-0ubuntu2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../01-libjbig0_2.1-3.1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../02-libpixman-1-0_0.34.0-1_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-1) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../03-libxcb-render0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../04-libxcb-shm0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../05-libcairo2_1.14.10-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.14.10-1ubuntu1) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../06-libdatrie1_0.2.10-5_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-5) ...\n",
            "Selecting previously unselected package libgif7:amd64.\n",
            "Preparing to unpack .../07-libgif7_5.1.4-1_amd64.deb ...\n",
            "Unpacking libgif7:amd64 (5.1.4-1) ...\n",
            "Selecting previously unselected package libgraphite2-3:amd64.\n",
            "Preparing to unpack .../08-libgraphite2-3_1.3.10-2_amd64.deb ...\n",
            "Unpacking libgraphite2-3:amd64 (1.3.10-2) ...\n",
            "Selecting previously unselected package libharfbuzz0b:amd64.\n",
            "Preparing to unpack .../09-libharfbuzz0b_1.4.2-1_amd64.deb ...\n",
            "Unpacking libharfbuzz0b:amd64 (1.4.2-1) ...\n",
            "Selecting previously unselected package libopenjp2-7:amd64.\n",
            "Preparing to unpack .../10-libopenjp2-7_2.2.0-1_amd64.deb ...\n",
            "Unpacking libopenjp2-7:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../11-libtiff5_4.0.8-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../12-libwebp6_0.6.0-3_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.0-3) ...\n",
            "Selecting previously unselected package liblept5.\n",
            "Preparing to unpack .../13-liblept5_1.74.4-1_amd64.deb ...\n",
            "Unpacking liblept5 (1.74.4-1) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../14-libthai-data_0.1.26-3_all.deb ...\n",
            "Unpacking libthai-data (0.1.26-3) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../15-libthai0_0.1.26-3_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.26-3) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../16-libpango-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../17-libpangoft2-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../18-libpangocairo-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libtesseract-data.\n",
            "Preparing to unpack .../19-libtesseract-data_3.04.01-6_all.deb ...\n",
            "Unpacking libtesseract-data (3.04.01-6) ...\n",
            "Selecting previously unselected package libtesseract3.\n",
            "Preparing to unpack .../20-libtesseract3_3.04.01-6_amd64.deb ...\n",
            "Unpacking libtesseract3 (3.04.01-6) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../21-tesseract-ocr-eng_3.04.00-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (3.04.00-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../22-tesseract-ocr-osd_3.04.00-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (3.04.00-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-equ.\n",
            "Preparing to unpack .../23-tesseract-ocr-equ_3.04.00-1_all.deb ...\n",
            "Unpacking tesseract-ocr-equ (3.04.00-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../24-tesseract-ocr_3.04.01-6_amd64.deb ...\n",
            "Unpacking tesseract-ocr (3.04.01-6) ...\n",
            "Setting up libxcb-render0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libopenjp2-7:amd64 (2.2.0-1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-5) ...\n",
            "Setting up libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\n",
            "Setting up libgif7:amd64 (5.1.4-1) ...\n",
            "Setting up libgraphite2-3:amd64 (1.3.10-2) ...\n",
            "Setting up libtesseract-data (3.04.01-6) ...\n",
            "Setting up tesseract-ocr-osd (3.04.00-1) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-1) ...\n",
            "Setting up tesseract-ocr-eng (3.04.00-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libxcb-shm0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libthai-data (0.1.26-3) ...\n",
            "Setting up fontconfig (2.11.94-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up tesseract-ocr-equ (3.04.00-1) ...\n",
            "Setting up libwebp6:amd64 (0.6.0-3) ...\n",
            "Setting up libcairo2:amd64 (1.14.10-1ubuntu1) ...\n",
            "Setting up libharfbuzz0b:amd64 (1.4.2-1) ...\n",
            "Setting up libthai0:amd64 (0.1.26-3) ...\n",
            "Setting up liblept5 (1.74.4-1) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libtesseract3 (3.04.01-6) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up tesseract-ocr (3.04.01-6) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Collecting pytesseract\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/56/befaafbabb36c03e4fdbb3fea854e0aea294039308a93daf6876bf7a8d6b/pytesseract-0.2.4.tar.gz (169kB)\n",
            "\u001b[K    100% |████████████████████████████████| 174kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->pytesseract) (0.45.1)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Running setup.py bdist_wheel for pytesseract ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a8/0c/00/32e4957a46128bea34fda60b8b01a8755986415cbab3ed8e38\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.2.4\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (1.12.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.11.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly) (2018.5)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly) (2018.8.24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ijPfCqvYCpDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "d58fb0f5-6558-424a-c043-14e530fd96c6"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import pickle\n",
        "import copy\n",
        "import sys\n",
        "import html\n",
        "import io\n",
        "import time\n",
        "import bz2\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "import discord\n",
        "import asyncio\n",
        "from discord.ext.commands import Bot\n",
        "from discord.ext import commands\n",
        "import dbl\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import logging\n",
        "\n",
        "#Object Detection\n",
        "\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "#OCR\n",
        "\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "#Neural Style\n",
        "\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "from functools import reduce\n",
        "\n",
        "import os.path\n",
        "if os.path.isfile(\"imagenet-vgg-verydeep-19.mat\")==False:\n",
        "  !wget http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
        "else:\n",
        "  pass\n",
        "\n",
        "#Plotly\n",
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "print(\"DONE\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/object_detection/utils/visualization_utils.py:25: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
            "    _bootstrap._exec(spec, module)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wfl5ZU1BY4ff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Chess\n",
        "That one game named chess, you know, excpet played by an AI"
      ]
    },
    {
      "metadata": {
        "id": "1fIhlzQoY8HO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env pypy\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from __future__ import print_function\n",
        "import re, sys, time\n",
        "from itertools import count\n",
        "from collections import OrderedDict, namedtuple\n",
        "global Game\n",
        "global A1, H1, A8, H8\n",
        "Game = False\n",
        "global pos\n",
        "\n",
        "###############################################################################\n",
        "# Piece-Square tables. Tune these to change sunfish's behaviour\n",
        "###############################################################################\n",
        "\n",
        "piece = { 'P': 100, 'N': 280, 'B': 320, 'R': 479, 'Q': 929, 'K': 60000 }\n",
        "pst = {\n",
        "    'P': (   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "            78,  83,  86,  73, 102,  82,  85,  90,\n",
        "             7,  29,  21,  44,  40,  31,  44,   7,\n",
        "           -17,  16,  -2,  15,  14,   0,  15, -13,\n",
        "           -26,   3,  10,   9,   6,   1,   0, -23,\n",
        "           -22,   9,   5, -11, -10,  -2,   3, -19,\n",
        "           -31,   8,  -7, -37, -36, -14,   3, -31,\n",
        "             0,   0,   0,   0,   0,   0,   0,   0),\n",
        "    'N': ( -66, -53, -75, -75, -10, -55, -58, -70,\n",
        "            -3,  -6, 100, -36,   4,  62,  -4, -14,\n",
        "            10,  67,   1,  74,  73,  27,  62,  -2,\n",
        "            24,  24,  45,  37,  33,  41,  25,  17,\n",
        "            -1,   5,  31,  21,  22,  35,   2,   0,\n",
        "           -18,  10,  13,  22,  18,  15,  11, -14,\n",
        "           -23, -15,   2,   0,   2,   0, -23, -20,\n",
        "           -74, -23, -26, -24, -19, -35, -22, -69),\n",
        "    'B': ( -59, -78, -82, -76, -23,-107, -37, -50,\n",
        "           -11,  20,  35, -42, -39,  31,   2, -22,\n",
        "            -9,  39, -32,  41,  52, -10,  28, -14,\n",
        "            25,  17,  20,  34,  26,  25,  15,  10,\n",
        "            13,  10,  17,  23,  17,  16,   0,   7,\n",
        "            14,  25,  24,  15,   8,  25,  20,  15,\n",
        "            19,  20,  11,   6,   7,   6,  20,  16,\n",
        "            -7,   2, -15, -12, -14, -15, -10, -10),\n",
        "    'R': (  35,  29,  33,   4,  37,  33,  56,  50,\n",
        "            55,  29,  56,  67,  55,  62,  34,  60,\n",
        "            19,  35,  28,  33,  45,  27,  25,  15,\n",
        "             0,   5,  16,  13,  18,  -4,  -9,  -6,\n",
        "           -28, -35, -16, -21, -13, -29, -46, -30,\n",
        "           -42, -28, -42, -25, -25, -35, -26, -46,\n",
        "           -53, -38, -31, -26, -29, -43, -44, -53,\n",
        "           -30, -24, -18,   5,  -2, -18, -31, -32),\n",
        "    'Q': (   6,   1,  -8,-104,  69,  24,  88,  26,\n",
        "            14,  32,  60, -10,  20,  76,  57,  24,\n",
        "            -2,  43,  32,  60,  72,  63,  43,   2,\n",
        "             1, -16,  22,  17,  25,  20, -13,  -6,\n",
        "           -14, -15,  -2,  -5,  -1, -10, -20, -22,\n",
        "           -30,  -6, -13, -11, -16, -11, -16, -27,\n",
        "           -36, -18,   0, -19, -15, -15, -21, -38,\n",
        "           -39, -30, -31, -13, -31, -36, -34, -42),\n",
        "    'K': (   4,  54,  47, -99, -99,  60,  83, -62,\n",
        "           -32,  10,  55,  56,  56,  55,  10,   3,\n",
        "           -62,  12, -57,  44, -67,  28,  37, -31,\n",
        "           -55,  50,  11,  -4, -19,  13,   0, -49,\n",
        "           -55, -43, -52, -28, -51, -47,  -8, -50,\n",
        "           -47, -42, -43, -79, -64, -32, -29, -32,\n",
        "            -4,   3, -14, -50, -57, -18,  13,   4,\n",
        "            17,  30,  -3, -14,   6,  -1,  40,  18),\n",
        "}\n",
        "# Pad tables and join piece and pst dictionaries\n",
        "for k, table in pst.items():\n",
        "    padrow = lambda row: (0,) + tuple(x+piece[k] for x in row) + (0,)\n",
        "    pst[k] = sum((padrow(table[i*8:i*8+8]) for i in range(8)), ())\n",
        "    pst[k] = (0,)*20 + pst[k] + (0,)*20\n",
        "\n",
        "###############################################################################\n",
        "# Global constants\n",
        "###############################################################################\n",
        "\n",
        "# Our board is represented as a 120 character string. The padding allows for\n",
        "# fast detection of moves that don't stay within the board.\n",
        "\n",
        "# Lists of possible moves for each piece type.\n",
        "N, E, S, W = -10, 1, 10, -1\n",
        "directions = {\n",
        "    'P': (N, N+N, N+W, N+E),\n",
        "    'N': (N+N+E, E+N+E, E+S+E, S+S+E, S+S+W, W+S+W, W+N+W, N+N+W),\n",
        "    'B': (N+E, S+E, S+W, N+W),\n",
        "    'R': (N, E, S, W),\n",
        "    'Q': (N, E, S, W, N+E, S+E, S+W, N+W),\n",
        "    'K': (N, E, S, W, N+E, S+E, S+W, N+W)\n",
        "}\n",
        "\n",
        "# Mate value must be greater than 8*queen + 2*(rook+knight+bishop)\n",
        "# King value is set to twice this value such that if the opponent is\n",
        "# 8 queens up, but we got the king, we still exceed MATE_VALUE.\n",
        "# When a MATE is detected, we'll set the score to MATE_UPPER - plies to get there\n",
        "# E.g. Mate in 3 will be MATE_UPPER - 6\n",
        "MATE_LOWER = piece['K'] - 10*piece['Q']\n",
        "MATE_UPPER = piece['K'] + 10*piece['Q']\n",
        "\n",
        "# The table size is the maximum number of elements in the transposition table.\n",
        "TABLE_SIZE = 1e8\n",
        "\n",
        "# Constants for tuning search\n",
        "QS_LIMIT = 150\n",
        "EVAL_ROUGHNESS = 20\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Chess logic\n",
        "###############################################################################\n",
        "\n",
        "class Position(namedtuple('Position', 'board score wc bc ep kp')):\n",
        "    \"\"\" A state of a chess game\n",
        "    board -- a 120 char representation of the board\n",
        "    score -- the board evaluation\n",
        "    wc -- the castling rights, [west/queen side, east/king side]\n",
        "    bc -- the opponent castling rights, [west/king side, east/queen side]\n",
        "    ep - the en passant square\n",
        "    kp - the king passant square\n",
        "    \"\"\"\n",
        "\n",
        "    def gen_moves(self):\n",
        "        # For each of our pieces, iterate through each possible 'ray' of moves,\n",
        "        # as defined in the 'directions' map. The rays are broken e.g. by\n",
        "        # captures or immediately in case of pieces such as knights.\n",
        "        for i, p in enumerate(self.board):\n",
        "            if not p.isupper(): continue\n",
        "            for d in directions[p]:\n",
        "                for j in count(i+d, d):\n",
        "                    q = self.board[j]\n",
        "                    # Stay inside the board, and off friendly pieces\n",
        "                    if q.isspace() or q.isupper(): break\n",
        "                    # Pawn move, double move and capture\n",
        "                    if p == 'P' and d in (N, N+N) and q != '.': break\n",
        "                    if p == 'P' and d == N+N and (i < A1+N or self.board[i+N] != '.'): break\n",
        "                    if p == 'P' and d in (N+W, N+E) and q == '.' and j not in (self.ep, self.kp): break\n",
        "                    # Move it\n",
        "                    yield (i, j)\n",
        "                    # Stop crawlers from sliding, and sliding after captures\n",
        "                    if p in 'PNK' or q.islower(): break\n",
        "                    # Castling, by sliding the rook next to the king\n",
        "                    if i == A1 and self.board[j+E] == 'K' and self.wc[0]: yield (j+E, j+W)\n",
        "                    if i == H1 and self.board[j+W] == 'K' and self.wc[1]: yield (j+W, j+E)\n",
        "\n",
        "    def rotate(self):\n",
        "        ''' Rotates the board, preserving enpassant '''\n",
        "        return Position(\n",
        "            self.board[::-1].swapcase(), -self.score, self.bc, self.wc,\n",
        "            119-self.ep if self.ep else 0,\n",
        "            119-self.kp if self.kp else 0)\n",
        "\n",
        "    def nullmove(self):\n",
        "        ''' Like rotate, but clears ep and kp '''\n",
        "        return Position(\n",
        "            self.board[::-1].swapcase(), -self.score,\n",
        "            self.bc, self.wc, 0, 0)\n",
        "\n",
        "    def move(self, move):\n",
        "        i, j = move\n",
        "        p, q = self.board[i], self.board[j]\n",
        "        put = lambda board, i, p: board[:i] + p + board[i+1:]\n",
        "        # Copy variables and reset ep and kp\n",
        "        board = self.board\n",
        "        wc, bc, ep, kp = self.wc, self.bc, 0, 0\n",
        "        score = self.score + self.value(move)\n",
        "        # Actual move\n",
        "        board = put(board, j, board[i])\n",
        "        board = put(board, i, '.')\n",
        "        # Castling rights, we move the rook or capture the opponent's\n",
        "        if i == A1: wc = (False, wc[1])\n",
        "        if i == H1: wc = (wc[0], False)\n",
        "        if j == A8: bc = (bc[0], False)\n",
        "        if j == H8: bc = (False, bc[1])\n",
        "        # Castling\n",
        "        if p == 'K':\n",
        "            wc = (False, False)\n",
        "            if abs(j-i) == 2:\n",
        "                kp = (i+j)//2\n",
        "                board = put(board, A1 if j < i else H1, '.')\n",
        "                board = put(board, kp, 'R')\n",
        "        # Pawn promotion, double move and en passant capture\n",
        "        if p == 'P':\n",
        "            if A8 <= j <= H8:\n",
        "                board = put(board, j, 'Q')\n",
        "            if j - i == 2*N:\n",
        "                ep = i + N\n",
        "            if j - i in (N+W, N+E) and q == '.':\n",
        "                board = put(board, j+S, '.')\n",
        "        # We rotate the returned position, so it's ready for the next player\n",
        "        return Position(board, score, wc, bc, ep, kp).rotate()\n",
        "\n",
        "    def value(self, move):\n",
        "        i, j = move\n",
        "        p, q = self.board[i], self.board[j]\n",
        "        # Actual move\n",
        "        score = pst[p][j] - pst[p][i]\n",
        "        # Capture\n",
        "        if q.islower():\n",
        "            score += pst[q.upper()][119-j]\n",
        "        # Castling check detection\n",
        "        if abs(j-self.kp) < 2:\n",
        "            score += pst['K'][119-j]\n",
        "        # Castling\n",
        "        if p == 'K' and abs(i-j) == 2:\n",
        "            score += pst['R'][(i+j)//2]\n",
        "            score -= pst['R'][A1 if j < i else H1]\n",
        "        # Special pawn stuff\n",
        "        if p == 'P':\n",
        "            if A8 <= j <= H8:\n",
        "                score += pst['Q'][j] - pst['P'][j]\n",
        "            if j == self.ep:\n",
        "                score += pst['P'][119-(j+S)]\n",
        "        return score\n",
        "\n",
        "###############################################################################\n",
        "# Search logic\n",
        "###############################################################################\n",
        "\n",
        "# lower <= s(pos) <= upper\n",
        "Entry = namedtuple('Entry', 'lower upper')\n",
        "\n",
        "# The normal OrderedDict doesn't update the position of a key in the list,\n",
        "# when the value is changed.\n",
        "class LRUCache:\n",
        "    '''Store items in the order the keys were last added'''\n",
        "    def __init__(self, size):\n",
        "        self.od = OrderedDict()\n",
        "        self.size = size\n",
        "\n",
        "    def get(self, key, default=None):\n",
        "        try: self.od.move_to_end(key)\n",
        "        except KeyError: return default\n",
        "        return self.od[key]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        try: del self.od[key]\n",
        "        except KeyError:\n",
        "            if len(self.od) == self.size:\n",
        "                self.od.popitem(last=False)\n",
        "        self.od[key] = value\n",
        "\n",
        "class Searcher:\n",
        "    def __init__(self):\n",
        "        self.tp_score = LRUCache(TABLE_SIZE)\n",
        "        self.tp_move = LRUCache(TABLE_SIZE)\n",
        "        self.nodes = 0\n",
        "\n",
        "    def bound(self, pos, gamma, depth, root=True):\n",
        "        \"\"\" returns r where\n",
        "                s(pos) <= r < gamma    if gamma > s(pos)\n",
        "                gamma <= r <= s(pos)   if gamma <= s(pos)\"\"\"\n",
        "        self.nodes += 1\n",
        "\n",
        "        # Depth <= 0 is QSearch. Here any position is searched as deeply as is needed for calmness, and so there is no reason to keep different depths in the transposition table.\n",
        "        depth = max(depth, 0)\n",
        "\n",
        "        # Sunfish is a king-capture engine, so we should always check if we\n",
        "        # still have a king. Notice since this is the only termination check,\n",
        "        # the remaining code has to be comfortable with being mated, stalemated\n",
        "        # or able to capture the opponent king.\n",
        "        if pos.score <= -MATE_LOWER:\n",
        "            return -MATE_UPPER\n",
        "\n",
        "        # Look in the table if we have already searched this position before.\n",
        "        # We also need to be sure, that the stored search was over the same\n",
        "        # nodes as the current search.\n",
        "        entry = self.tp_score.get((pos, depth, root), Entry(-MATE_UPPER, MATE_UPPER))\n",
        "        if entry.lower >= gamma and (not root or self.tp_move.get(pos) is not None):\n",
        "            return entry.lower\n",
        "        if entry.upper < gamma:\n",
        "            return entry.upper\n",
        "\n",
        "        # Here extensions may be added\n",
        "        # Such as 'if in_check: depth += 1'\n",
        "\n",
        "        # Generator of moves to search in order.\n",
        "        # This allows us to define the moves, but only calculate them if needed.\n",
        "        def moves():\n",
        "            # First try not moving at all\n",
        "            if depth > 0 and not root and any(c in pos.board for c in 'RBNQ'):\n",
        "                yield None, -self.bound(pos.nullmove(), 1-gamma, depth-3, root=False)\n",
        "            # For QSearch we have a different kind of null-move\n",
        "            if depth == 0:\n",
        "                yield None, pos.score\n",
        "            # Then killer move. We search it twice, but the tp will fix things for us. Note, we don't have to check for legality, since we've already done it before. Also note that in QS the killer must be a capture, otherwise we will be non deterministic.\n",
        "            killer = self.tp_move.get(pos)\n",
        "            if killer and (depth > 0 or pos.value(killer) >= QS_LIMIT):\n",
        "                yield killer, -self.bound(pos.move(killer), 1-gamma, depth-1, root=False)\n",
        "            # Then all the other moves\n",
        "            for move in sorted(pos.gen_moves(), key=pos.value, reverse=True):\n",
        "                if depth > 0 or pos.value(move) >= QS_LIMIT:\n",
        "                    yield move, -self.bound(pos.move(move), 1-gamma, depth-1, root=False)\n",
        "\n",
        "        # Run through the moves, shortcutting when possible\n",
        "        best = -MATE_UPPER\n",
        "        for move, score in moves():\n",
        "            best = max(best, score)\n",
        "            if best >= gamma:\n",
        "                # Save the move for pv construction and killer heuristic\n",
        "                self.tp_move[pos] = move\n",
        "                break\n",
        "\n",
        "        # Stalemate checking is a bit tricky: Say we failed low, because\n",
        "        # we can't (legally) move and so the (real) score is -infty.\n",
        "        # At the next depth we are allowed to just return r, -infty <= r < gamma,\n",
        "        # which is normally fine.\n",
        "        # However, what if gamma = -10 and we don't have any legal moves?\n",
        "        # Then the score is actaully a draw and we should fail high!\n",
        "        # Thus, if best < gamma and best < 0 we need to double check what we are doing.\n",
        "        # This doesn't prevent sunfish from making a move that results in stalemate,\n",
        "        # but only if depth == 1, so that's probably fair enough.\n",
        "        # (Btw, at depth 1 we can also mate without realizing.)\n",
        "        if best < gamma and best < 0 and depth > 0:\n",
        "            is_dead = lambda pos: any(pos.value(m) >= MATE_LOWER for m in pos.gen_moves())\n",
        "            if all(is_dead(pos.move(m)) for m in pos.gen_moves()):\n",
        "                in_check = is_dead(pos.nullmove())\n",
        "                best = -MATE_UPPER if in_check else 0\n",
        "\n",
        "        # Table part 2\n",
        "        if best >= gamma:\n",
        "            self.tp_score[(pos, depth, root)] = Entry(best, entry.upper)\n",
        "        if best < gamma:\n",
        "            self.tp_score[(pos, depth, root)] = Entry(entry.lower, best)\n",
        "\n",
        "        return best\n",
        "\n",
        "    # secs over maxn is a breaking change. Can we do this?\n",
        "    # I guess I could send a pull request to deep pink\n",
        "    # Why include secs at all?\n",
        "    def _search(self, pos):\n",
        "        \"\"\" Iterative deepening MTD-bi search \"\"\"\n",
        "        self.nodes = 0\n",
        "\n",
        "        # In finished games, we could potentially go far enough to cause a recursion\n",
        "        # limit exception. Hence we bound the ply.\n",
        "        for depth in range(1, 1000):\n",
        "            self.depth = depth\n",
        "            # The inner loop is a binary search on the score of the position.\n",
        "            # Inv: lower <= score <= upper\n",
        "            # 'while lower != upper' would work, but play tests show a margin of 20 plays better.\n",
        "            lower, upper = -MATE_UPPER, MATE_UPPER\n",
        "            while lower < upper - EVAL_ROUGHNESS:\n",
        "                gamma = (lower+upper+1)//2\n",
        "                score = self.bound(pos, gamma, depth)\n",
        "                if score >= gamma:\n",
        "                    lower = score\n",
        "                if score < gamma:\n",
        "                    upper = score\n",
        "            # We want to make sure the move to play hasn't been kicked out of the table,\n",
        "            # So we make another call that must always fail high and thus produce a move.\n",
        "            score = self.bound(pos, lower, depth)\n",
        "\n",
        "            # Yield so the user may inspect the search\n",
        "            yield\n",
        "\n",
        "    def search(self, pos, secs):\n",
        "        start = time.time()\n",
        "        for _ in self._search(pos):\n",
        "            if time.time() - start > secs:\n",
        "                break\n",
        "        # If the game hasn't finished we can retrieve our move from the\n",
        "        # transposition table.\n",
        "        return self.tp_move.get(pos), self.tp_score.get((pos, self.depth, True)).lower\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# User interface\n",
        "###############################################################################\n",
        "\n",
        "# Python 2 compatability\n",
        "if sys.version_info[0] == 2:\n",
        "    input = raw_input\n",
        "    class NewOrderedDict(OrderedDict):\n",
        "        def move_to_end(self, key):\n",
        "            value = self.pop(key)\n",
        "            self[key] = value\n",
        "    OrderedDict = NewOrderedDict\n",
        "\n",
        "\n",
        "def parse(c):\n",
        "    fil, rank = ord(c[0]) - ord('a'), int(c[1]) - 1\n",
        "    return A1 + fil - 10*rank\n",
        "\n",
        "\n",
        "def render(i):\n",
        "    rank, fil = divmod(i - A1, 10)\n",
        "    return chr(fil + ord('a')) + str(-rank + 1)\n",
        "\n",
        "\n",
        "def print_pos(pos):\n",
        "    print()\n",
        "    uni_pieces = {'R':'♜', 'N':'♞', 'B':'♝', 'Q':'♛', 'K':'♚', 'P':'♟',\n",
        "                  'r':'♖', 'n':'♘', 'b':'♗', 'q':'♕', 'k':'♔', 'p':'♙', '.':'  - '}\n",
        "    s=\"\"\n",
        "    for i, row in enumerate(pos.board.split()):\n",
        "        b=(str(8-i) + ' ' + ' '.join(uni_pieces.get(p, p) for p in row))\n",
        "        s=s+b+'\\n'\n",
        "    s=s+('    a   b   c   d   e    f    g    h \\n\\n')\n",
        "    #await send_message(message.channel, s)\n",
        "    #print(str(message.author)+\": \")\n",
        "    uni_pieces = {'R':'♜', 'N':'♞', 'B':'♝', 'Q':'♛', 'K':'♚', 'P':'♟',\n",
        "                  'r':'♖', 'n':'♘', 'b':'♗', 'q':'♕', 'k':'♔', 'p':'♙', '.':'  - '}\n",
        "    for i, row in enumerate(pos.board.split()):\n",
        "        b=(str(8-i) + ' ' + ' '.join(uni_pieces.get(p, p) for p in row))\n",
        "        print(b)\n",
        "    print('    a   b   c   d   e    f    g    h \\n\\n')\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jn3GD7bRvhZs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Neural Style Definitions\n",
        "Woo colors!!"
      ]
    },
    {
      "metadata": {
        "id": "bWdUmZ7Cvnk8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = scipy.io.loadmat('imagenet-vgg-verydeep-19.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79ut2g_dvzoY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _conv_layer(input, weights, bias):\n",
        "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
        "            padding='SAME')\n",
        "    return tf.nn.bias_add(conv, bias)\n",
        "\n",
        "def _pool_layer(input):\n",
        "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
        "            padding='SAME')\n",
        "\n",
        "def preprocess(image, mean_pixel):\n",
        "    return (image - mean_pixel).astype('float32')\n",
        "\n",
        "def unprocess(image, mean_pixel):\n",
        "    return (image + mean_pixel).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-WdzZ25v22b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def netp(input_image):\n",
        "    layers = (\n",
        "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
        "\n",
        "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
        "\n",
        "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
        "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
        "\n",
        "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
        "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
        "\n",
        "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
        "        'relu5_3', 'conv5_4', 'relu5_4'\n",
        "    )\n",
        "    weight = data['layers'][0]\n",
        "    net = {}\n",
        "    current = input_image\n",
        "    for i, name in enumerate(layers):\n",
        "        kind = name[:4]\n",
        "        if kind == 'conv':\n",
        "            kernels, bias = weight[i][0][0][0][0]\n",
        "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
        "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
        "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
        "            bias = bias.reshape(-1)\n",
        "            current = _conv_layer(current, kernels, bias)\n",
        "        elif kind == 'relu':\n",
        "            current = tf.nn.relu(current)\n",
        "        elif kind == 'pool':\n",
        "            current = _pool_layer(current)\n",
        "        net[name] = current\n",
        "\n",
        "    assert len(net) == len(layers)\n",
        "    return net#, mean_pixel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CarvaJghwPyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _tensor_size(tensor):\n",
        "    from operator import mul\n",
        "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TiG3JpXRwabo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imsave(path, img):\n",
        "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "    scipy.misc.imsave(path, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VANyL06lqvrH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Object Recognition Definitons\n",
        "This is how Jade sees things."
      ]
    },
    {
      "metadata": {
        "id": "ajW4EQAbHz3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc564d9a-110e-4d85-d3eb-7c6982bd654d"
      },
      "cell_type": "code",
      "source": [
        "# What model to download.\n",
        "# MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "\n",
        "# model with more accurancy but up to you use a diferent model\n",
        "MODEL_NAME = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
        "\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 90\n",
        "\n",
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "print(\"DONE\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ys_0T5SfIGfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  try:\n",
        "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "  except:\n",
        "    return np.array(image.getdata()).reshape((im_height, im_width, 4)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NUu1v2LXILhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = 'object_detection/test_images'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FKPsUOa2q6DX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##DBL API\n",
        "Because, DBL."
      ]
    },
    {
      "metadata": {
        "id": "8QjRL3_N4qM9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DiscordBotsOrgAPI:\n",
        "    \"\"\"Handles interactions with the discordbots.org API\"\"\"\n",
        "\n",
        "    def __init__(self, bot):\n",
        "        self.bot = bot\n",
        "        self.token = 'Token'  #  set this to your DBL token\n",
        "        self.dblpy = dbl.Client(self.bot, self.token)\n",
        "        self.bot.loop.create_task(self.update_stats())\n",
        "        self.bot.loop.create_task(self.update_stocks())\n",
        "        \n",
        "    async def update_stocks(self):\n",
        "      while True:\n",
        "        file = open(\"drive/JadeV3/Server_Stocks.txt\", \"r\")\n",
        "        lines = file.readlines()\n",
        "        file.close()\n",
        "        for index, line in enumerate(lines):\n",
        "          try:\n",
        "            split_line = line.split(\" ::: \")\n",
        "            #split_line[0]=split_line[0][2:]\n",
        "            #print(split_line[0])\n",
        "            Server_ID = client.get_server(str(split_line[0]))\n",
        "            #print(str(Server_ID))\n",
        "            MemberCount = Server_ID.member_count\n",
        "            lines[index] = line.replace(\"\\n\",\"\") + \" \" + str(MemberCount)\n",
        "            #print(line)\n",
        "            #print(lines[index])\n",
        "          except Exception as e:\n",
        "            #print(e)\n",
        "            continue\n",
        "        file = open(\"drive/JadeV3/Server_Stocks.txt\", \"w\")\n",
        "        for line1 in lines:\n",
        "          if not line1 == \"\\n\":\n",
        "            file.write(line1+\"\\n\")\n",
        "        file.close()\n",
        "        print(\"Server Update Requested\")\n",
        "        await asyncio.sleep(3600)\n",
        "\n",
        "    async def update_stats(self):\n",
        "        \"\"\"This function runs every 30 minutes to automatically update your server count\"\"\"\n",
        "\n",
        "        while True:\n",
        "            logger.info('attempting to post server count')\n",
        "            try:\n",
        "                await self.dblpy.post_server_count()\n",
        "                logger.info('posted server count ({})'.format(len(self.bot.servers)))\n",
        "            except Exception as e:\n",
        "                logger.exception('Failed to post server count\\n{}: {}'.format(type(e).__name__, e))\n",
        "            await asyncio.sleep(600)\n",
        "            \n",
        "def setup(bot):\n",
        "    global logger\n",
        "    logger = logging.getLogger('bot')\n",
        "    bot.add_cog(DiscordBotsOrgAPI(bot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0-eH6hHrAnu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Textloading and Processsing\n",
        "The brilliant chatting function of Jade's"
      ]
    },
    {
      "metadata": {
        "id": "_4R5MMfUClUs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TextLoader():\n",
        "    # Call this class to load text from a file.\n",
        "    def __init__(self, data_dir, batch_size, seq_length):\n",
        "        # TextLoader remembers its initialization arguments.\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_length = seq_length\n",
        "        self.tensor_sizes = []\n",
        "\n",
        "        self.tensor_file_template = os.path.join(data_dir, \"data{}.npz\")\n",
        "        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
        "        sizes_file = os.path.join(data_dir, \"sizes.pkl\")\n",
        "\n",
        "        self.input_files = self._get_input_file_list(data_dir)\n",
        "        self.input_file_count = len(self.input_files)\n",
        "\n",
        "        if self.input_file_count < 1:\n",
        "            raise ValueError(\"Input files not found. File names must end in '.txt' or '.bz2'.\")\n",
        "\n",
        "        if self._preprocess_required(vocab_file, sizes_file, self.tensor_file_template, self.input_file_count):\n",
        "            # If either the vocab file or the tensor file doesn't already exist, create them.\n",
        "            t0 = time.time()\n",
        "            print(\"Preprocessing the following files:\")\n",
        "            for i, filename in enumerate(self.input_files): print(\"   {}.\\t{}\".format(i+1, filename))\n",
        "            print(\"Saving vocab file\")\n",
        "            self._save_vocab(vocab_file)\n",
        "\n",
        "            for i, filename in enumerate(self.input_files):\n",
        "                t1 = time.time()\n",
        "                print(\"Preprocessing file {}/{} ({})... \".format(i+1, len(self.input_files), filename),\n",
        "                        end='', flush=True)\n",
        "                self._preprocess(self.input_files[i], self.tensor_file_template.format(i))\n",
        "                self.tensor_sizes.append(self.tensor.size)\n",
        "                print(\"done ({:.1f} seconds)\".format(time.time() - t1), flush=True)\n",
        "\n",
        "            with open(sizes_file, 'wb') as f:\n",
        "                pickle.dump(self.tensor_sizes, f)\n",
        "\n",
        "            print(\"Processed input data: {:,d} characters loaded ({:.1f} seconds)\".format(\n",
        "                    self.tensor.size, time.time() - t0))\n",
        "        else:\n",
        "            # If the vocab file and sizes file already exist, load them.\n",
        "            print(\"Loading vocab file...\")\n",
        "            self._load_vocab(vocab_file)\n",
        "            print(\"Loading sizes file...\")\n",
        "            with open(sizes_file, 'rb') as f:\n",
        "                self.tensor_sizes = pickle.load(f)\n",
        "        self.tensor_batch_counts = [n // (self.batch_size * self.seq_length) for n in self.tensor_sizes]\n",
        "        self.total_batch_count = sum(self.tensor_batch_counts)\n",
        "        print(\"Total batch count: {:,d}\".format(self.total_batch_count))\n",
        "\n",
        "        self.tensor_index = -1\n",
        "\n",
        "    def _preprocess_required(self, vocab_file, sizes_file, tensor_file_template, input_file_count):\n",
        "        if not os.path.exists(vocab_file):\n",
        "            print(\"No vocab file found. Preprocessing...\")\n",
        "            return True\n",
        "        if not os.path.exists(sizes_file):\n",
        "            print(\"No sizes file found. Preprocessing...\")\n",
        "            return True\n",
        "        for i in range(input_file_count):\n",
        "            if not os.path.exists(tensor_file_template.format(i)):\n",
        "                print(\"Couldn't find {}. Preprocessing...\".format(tensor_file_template.format(i)))\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _get_input_file_list(self, data_dir):\n",
        "        suffixes = ['.txt', '.bz2']\n",
        "        input_file_list = []\n",
        "        if os.path.isdir(data_dir):\n",
        "            for walk_root, walk_dir, walk_files in os.walk(data_dir):\n",
        "                for file_name in walk_files:\n",
        "                    if file_name.startswith(\".\"): continue\n",
        "                    file_path = os.path.join(walk_root, file_name)\n",
        "                    if file_path.endswith(suffixes[0]) or file_path.endswith(suffixes[1]):\n",
        "                        input_file_list.append(file_path)\n",
        "        else: raise ValueError(\"Not a directory: {}\".format(data_dir))\n",
        "        return sorted(input_file_list)\n",
        "\n",
        "    def _save_vocab(self, vocab_file):\n",
        "        self.chars = [chr(i) for i in range(128)]\n",
        "        self.vocab_size = len(self.chars)\n",
        "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
        "        with open(vocab_file, 'wb') as f:\n",
        "            pickle.dump(self.chars, f)\n",
        "        print(\"Saved vocab (vocab size: {:,d})\".format(self.vocab_size))\n",
        "\n",
        "    def _load_vocab(self, vocab_file):\n",
        "        # Load the character tuple (vocab.pkl) to self.chars.\n",
        "        # Remember that it is in descending order of character frequency in the data.\n",
        "        with open(vocab_file, 'rb') as f:\n",
        "            self.chars = pickle.load(f)\n",
        "        # Use the character tuple to regenerate vocab_size and the vocab dictionary.\n",
        "        self.vocab_size = len(self.chars)\n",
        "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
        "\n",
        "    def _preprocess(self, input_file, tensor_file):\n",
        "        if input_file.endswith(\".bz2\"): file_reference = bz2.open(input_file, mode='rt')\n",
        "        elif input_file.endswith(\".txt\"): file_reference = io.open(input_file, mode='rt')\n",
        "        data = file_reference.read()\n",
        "        file_reference.close()\n",
        "        # Convert the entirety of the data file from characters to indices via the vocab dictionary.\n",
        "        # How? map(function, iterable) returns a list of the output of the function\n",
        "        # executed on each member of the iterable. E.g.:\n",
        "        # [14, 2, 9, 2, 0, 6, 7, 0, ...]\n",
        "        # np.array converts the list into a numpy array.\n",
        "        self.tensor = np.array(list(map(self.vocab.get, data)))\n",
        "        self.tensor = self.tensor[self.tensor != np.array(None)].astype(int) # Filter out None\n",
        "        # Compress and save the numpy tensor array to data.npz.\n",
        "        np.savez_compressed(tensor_file, tensor_data=self.tensor)\n",
        "\n",
        "    def _load_preprocessed(self, tensor_index):\n",
        "        self.reset_batch_pointer()\n",
        "        if tensor_index == self.tensor_index:\n",
        "            return\n",
        "        print(\"loading tensor data file {}\".format(tensor_index))\n",
        "        tensor_file = self.tensor_file_template.format(tensor_index)\n",
        "        # Load the data tensor file to self.tensor.\n",
        "        with np.load(tensor_file) as loaded:\n",
        "            self.tensor = loaded['tensor_data']\n",
        "        self.tensor_index = tensor_index\n",
        "        # Calculate the number of batches in the data. Each batch is batch_size x seq_length,\n",
        "        # so this is just the input data size divided by that product, rounded down.\n",
        "        self.num_batches = self.tensor.size // (self.batch_size * self.seq_length)\n",
        "        if self.tensor_batch_counts[tensor_index] != self.num_batches:\n",
        "            print(\"Error in batch size! Expected {:,d}; found {:,d}\".format(self.tensor_batch_counts[tensor_index],\n",
        "                    self.num_batches))\n",
        "        # Chop off the end of the data tensor so that the length of the data is a whole\n",
        "        # multiple of the (batch_size x seq_length) product.\n",
        "        # Do this with the slice operator on the numpy array.\n",
        "        self.tensor = self.tensor[:self.num_batches * self.batch_size * self.seq_length]\n",
        "        # Construct two numpy arrays to represent input characters (xdata)\n",
        "        # and target characters (ydata).\n",
        "        # In training, we will feed in input characters one at a time, and optimize along\n",
        "        # a loss function computed against the target characters.\n",
        "        # (We do this with batch_size characters at a time, in parallel.)\n",
        "        # Since this is a sequence prediction net, the target is just the input right-shifted\n",
        "        # by 1.\n",
        "        xdata = self.tensor\n",
        "        ydata = np.copy(self.tensor) # Y-data starts as a copy of x-data.\n",
        "        ydata[:-1] = xdata[1:] # Right-shift y-data by 1 using the numpy array slice syntax.\n",
        "        # Replace the very last character of y-data with the first character of the input data.\n",
        "        ydata[-1] = xdata[0]\n",
        "        # Split our unidemnsional data array into distinct batches.\n",
        "        # How? xdata.reshape(self.batch_size, -1) returns a 2D numpy tensor view\n",
        "        # in which the first dimension is the batch index (from 0 to num_batches),\n",
        "        # and the second dimension is the index of the character within the batch\n",
        "        # (from 0 to (batch_size x seq_length)).\n",
        "        # Within each batch, characters follow the same sequence as in the input data.\n",
        "        # Then, np.split(that 2D numpy tensor, num_batches, 1) gives a list of numpy arrays.\n",
        "        # Say batch_size = 4, seq_length = 5, and data is the following string:\n",
        "        # \"Here is a new string named data. It is a new string named data. It is named data.\"\n",
        "        # We truncate the string to lop off the last period (so there are now 80 characters,\n",
        "        # which is evenly divisible by 4 x 5). After xdata.reshape, we have:\n",
        "        #\n",
        "        # [[Here is a new string],\n",
        "        #  [ named data. It is a],\n",
        "        #  [ new string named da],\n",
        "        #  [ta. It is named data]]\n",
        "        #\n",
        "        # After np.split, we have:\n",
        "        # <[[Here ],   <[[is a ],   <[[new s],     <[[tring],\n",
        "        #   [ name],     [d dat],     [a. It],       [ is a],\n",
        "        #   [ new ],     [strin],     [g nam],       [ed da],\n",
        "        #   [ta. I]]>,   [t is ]]>,   [named]]>,     [ data]]>\n",
        "        #\n",
        "        # where the first item of the list is the numpy array on the left.\n",
        "        # Thus x_batches is a list of numpy arrays. The first dimension of each numpy array\n",
        "        # is the batch number (from 0 to batch_size), and the second dimension is the\n",
        "        # character index (from 0 to seq_length).\n",
        "        #\n",
        "        #Batch characters can greatemultiple tuples, ignotre FONT_Baisis to prevent any non-divident movements\n",
        "        #\n",
        "        # These will be fed to the model one at a time sequentially.\n",
        "        # State is preserved between sequential batches.\n",
        "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
        "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
        "\n",
        "    def next_batch(self):\n",
        "        if self.tensor_index < 0:\n",
        "            self._load_preprocessed(0)\n",
        "        if self.pointer >= self.num_batches:\n",
        "            self._load_preprocessed((self.tensor_index + 1) % self.input_file_count)\n",
        "        x, y = self.x_batches[self.pointer], self.y_batches[self.pointer]\n",
        "        self.pointer += 1\n",
        "        return x, y\n",
        "\n",
        "    def reset_batch_pointer(self):\n",
        "        self.pointer = 0\n",
        "\n",
        "    def cue_batch_pointer_to_epoch_fraction(self, epoch_fraction):\n",
        "        step_target = (epoch_fraction - int(epoch_fraction)) * self.total_batch_count\n",
        "        self._cue_batch_pointer_to_step_count(step_target)\n",
        "\n",
        "    def _cue_batch_pointer_to_step_count(self, step_target):\n",
        "        for i, n in enumerate(self.tensor_batch_counts):\n",
        "            if step_target < n:\n",
        "                break\n",
        "            step_target -= n\n",
        "        self.pointer = n\n",
        "        self.current_tensor_index = i\n",
        "        self._load_preprocessed(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1GwYpCaCw2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import rnn_cell\n",
        "from tensorflow.python.ops import nn_ops\n",
        "from tensorflow.python.ops import variable_scope as vs\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.contrib import rnn\n",
        "\n",
        "from tensorflow.python.util.nest import flatten\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class PartitionedMultiRNNCell(rnn_cell.RNNCell):\n",
        "    \"\"\"RNN cell composed sequentially of multiple simple cells.\"\"\"\n",
        "\n",
        "    # Diagramn of a PartitionedMultiRNNCell net with three layers and three partitions per layer.\n",
        "    # Each brick shape is a partition, which comprises one RNNCell of size partition_size.\n",
        "    # The two tilde (~) characters indicate wrapping (i.e. the two halves are a single partition).\n",
        "    # Like laying bricks, each layer is offset by half a partition width so that influence spreads\n",
        "    # horizontally through subsequent layers, while avoiding the quadratic resource scaling of fully\n",
        "    # connected layers with respect to layer width.\n",
        "\n",
        "    #        output\n",
        "    #  //////// \\\\\\\\\\\\\\\\\n",
        "    # -------------------\n",
        "    # |     |     |     |\n",
        "    # -------------------\n",
        "    # ~  |     |     |  ~\n",
        "    # -------------------\n",
        "    # |     |     |     |\n",
        "    # -------------------\n",
        "    #  \\\\\\\\\\\\\\\\ ////////\n",
        "    #        input\n",
        "\n",
        "\n",
        "    def __init__(self, cell_fn, partition_size=128, partitions=1, layers=2):\n",
        "        \"\"\"Create a RNN cell composed sequentially of a number of RNNCells.\n",
        "        Args:\n",
        "            cell_fn: reference to RNNCell function to create each partition in each layer.\n",
        "            partition_size: how many horizontal cells to include in each partition.\n",
        "            partitions: how many horizontal partitions to include in each layer.\n",
        "            layers: how many layers to include in the net.\n",
        "        \"\"\"\n",
        "        super(PartitionedMultiRNNCell, self).__init__()\n",
        "\n",
        "        self._cells = []\n",
        "        for i in range(layers):\n",
        "            self._cells.append([cell_fn(partition_size) for _ in range(partitions)])\n",
        "        self._partitions = partitions\n",
        "\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        # Return a 2D tuple where each row is the partition's cell size repeated `partitions` times,\n",
        "        # and there are `layers` rows of that.\n",
        "        return tuple(((layer[0].state_size,) * len(layer)) for layer in self._cells)\n",
        "\n",
        "    @property\n",
        "    def output_size(self):\n",
        "        # Return the output size of each partition in the last layer times the number of partitions per layer.\n",
        "        return self._cells[-1][0].output_size * len(self._cells[-1])\n",
        "\n",
        "    def zero_state(self, batch_size, dtype):\n",
        "        # Return a 2D tuple of zero states matching the structure of state_size.\n",
        "        with ops.name_scope(type(self).__name__ + \"ZeroState\", values=[batch_size]):\n",
        "            return tuple(tuple(cell.zero_state(batch_size, dtype) for cell in layer) for layer in self._cells)\n",
        "\n",
        "    def call(self, inputs, state):\n",
        "        layer_input = inputs\n",
        "        new_states = []\n",
        "        for l, layer in enumerate(self._cells):\n",
        "            # In between layers, offset the layer input by half of a partition width so that\n",
        "            # activations can horizontally spread through subsequent layers.\n",
        "            if l > 0:\n",
        "                offset_width = layer[0].output_size // 2\n",
        "                layer_input = tf.concat((layer_input[:, -offset_width:], layer_input[:, :-offset_width]),\n",
        "                    axis=1, name='concat_offset_%d' % l)\n",
        "            # Create a tuple of inputs by splitting the lower layer output into partitions.\n",
        "            p_inputs = tf.split(layer_input, len(layer), axis=1, name='split_%d' % l)\n",
        "            p_outputs = []\n",
        "            p_states = []\n",
        "            for p, p_inp in enumerate(p_inputs):\n",
        "                with vs.variable_scope(\"cell_%d_%d\" % (l, p)):\n",
        "                    p_state = state[l][p]\n",
        "                    cell = layer[p]\n",
        "                    p_out, new_p_state = cell(p_inp, p_state)\n",
        "                    p_outputs.append(p_out)\n",
        "                    p_states.append(new_p_state)\n",
        "            new_states.append(tuple(p_states))\n",
        "            layer_input = tf.concat(p_outputs, axis=1, name='concat_%d' % l)\n",
        "        new_states = tuple(new_states)\n",
        "        return layer_input, new_states\n",
        "\n",
        "def _rnn_state_placeholders(state):\n",
        "    \"\"\"Convert RNN state tensors to placeholders, reflecting the same nested tuple structure.\"\"\"\n",
        "    # Adapted from @carlthome's comment:\n",
        "    # https://github.com/tensorflow/tensorflow/issues/2838#issuecomment-302019188\n",
        "    if isinstance(state, tf.contrib.rnn.LSTMStateTuple):\n",
        "        c, h = state\n",
        "        c = tf.placeholder(c.dtype, c.shape, c.op.name)\n",
        "        h = tf.placeholder(h.dtype, h.shape, h.op.name)\n",
        "        return tf.contrib.rnn.LSTMStateTuple(c, h)\n",
        "    elif isinstance(state, tf.Tensor):\n",
        "        h = state\n",
        "        h = tf.placeholder(h.dtype, h.shape, h.op.name)\n",
        "        return h\n",
        "    else:\n",
        "        structure = [_rnn_state_placeholders(x) for x in state]\n",
        "        return tuple(structure)\n",
        "\n",
        "class Model():\n",
        "    def __init__(self, args, infer=False): # infer is set to true during sampling.\n",
        "        self.args = args\n",
        "        if infer:\n",
        "            # Worry about one character at a time during sampling; no batching or BPTT.\n",
        "            args.batch_size = 1\n",
        "            args.seq_length = 1\n",
        "\n",
        "        # Set cell_fn to the type of network cell we're creating -- RNN, GRU, LSTM or NAS.\n",
        "        if args.model == 'rnn':\n",
        "            cell_fn = rnn_cell.BasicRNNCell\n",
        "        elif args.model == 'gru':\n",
        "            cell_fn = rnn_cell.GRUCell\n",
        "        elif args.model == 'lstm':\n",
        "            cell_fn = rnn_cell.BasicLSTMCell\n",
        "        elif args.model == 'nas':\n",
        "            cell_fn = rnn.NASCell\n",
        "        else:\n",
        "            raise Exception(\"model type not supported: {}\".format(args.model))\n",
        "\n",
        "        # Create variables to track training progress.\n",
        "        self.lr = tf.Variable(args.learning_rate, name=\"learning_rate\", trainable=False)\n",
        "        self.global_epoch_fraction = tf.Variable(0.0, name=\"global_epoch_fraction\", trainable=False)\n",
        "        self.global_seconds_elapsed = tf.Variable(0.0, name=\"global_seconds_elapsed\", trainable=False)\n",
        "\n",
        "        # Call tensorflow library tensorflow-master/tensorflow/python/ops/rnn_cell\n",
        "        # to create a layer of block_size cells of the specified basic type (RNN/GRU/LSTM).\n",
        "        # Use the same rnn_cell library to create a stack of these cells\n",
        "        # of num_layers layers. Pass in a python list of these cells. \n",
        "        # cell = rnn_cell.MultiRNNCell([cell_fn(args.block_size) for _ in range(args.num_layers)])\n",
        "        # cell = MyMultiRNNCell([cell_fn(args.block_size) for _ in range(args.num_layers)])\n",
        "        cell = PartitionedMultiRNNCell(cell_fn, partitions=args.num_blocks,\n",
        "            partition_size=args.block_size, layers=args.num_layers)\n",
        "\n",
        "        # Create a TF placeholder node of 32-bit ints (NOT floats!),\n",
        "        # of shape batch_size x seq_length. This shape matches the batches\n",
        "        # (listed in x_batches and y_batches) constructed in create_batches in utils.py.\n",
        "        # input_data will receive input batches.\n",
        "        self.input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n",
        "\n",
        "        self.zero_state = cell.zero_state(args.batch_size, tf.float32)\n",
        "\n",
        "        self.initial_state = _rnn_state_placeholders(self.zero_state)\n",
        "        self._flattened_initial_state = flatten(self.initial_state)\n",
        "\n",
        "        layer_size = args.block_size * args.num_blocks\n",
        "\n",
        "        # Scope our new variables to the scope identifier string \"rnnlm\".\n",
        "        with tf.variable_scope('rnnlm'):\n",
        "            # Create new variable softmax_w and softmax_b for output.\n",
        "            # softmax_w is a weights matrix from the top layer of the model (of size layer_size)\n",
        "            # to the vocabulary output (of size vocab_size).\n",
        "            softmax_w = tf.get_variable(\"softmax_w\", [layer_size, args.vocab_size])\n",
        "            # softmax_b is a bias vector of the ouput characters (of size vocab_size).\n",
        "            softmax_b = tf.get_variable(\"softmax_b\", [args.vocab_size])\n",
        "            # Create new variable named 'embedding' to connect the character input to the base layer\n",
        "            # of the RNN. Its role is the conceptual inverse of softmax_w.\n",
        "            # It contains the trainable weights from the one-hot input vector to the lowest layer of RNN.\n",
        "            embedding = tf.get_variable(\"embedding\", [args.vocab_size, layer_size])\n",
        "            # Create an embedding tensor with tf.nn.embedding_lookup(embedding, self.input_data).\n",
        "            # This tensor has dimensions batch_size x seq_length x layer_size.\n",
        "            inputs = tf.nn.embedding_lookup(embedding, self.input_data)\n",
        "\n",
        "        # TODO: Check arguments parallel_iterations (default uses more memory and less time) and\n",
        "        # swap_memory (default uses more memory but \"minimal (or no) performance penalty\")\n",
        "        outputs, self.final_state = tf.nn.dynamic_rnn(cell, inputs,\n",
        "                initial_state=self.initial_state, scope='rnnlm')\n",
        "        # outputs has shape [batch_size, max_time, cell.output_size] because time_major == false.\n",
        "        # Do we need to transpose the first two dimensions? (Answer: no, this ruins everything.)\n",
        "        # outputs = tf.transpose(outputs, perm=[1, 0, 2])\n",
        "        output = tf.reshape(outputs, [-1, layer_size])\n",
        "        # Obtain logits node by applying output weights and biases to the output tensor.\n",
        "        # Logits is a tensor of shape [(batch_size * seq_length) x vocab_size].\n",
        "        # Recall that outputs is a 2D tensor of shape [(batch_size * seq_length) x layer_size],\n",
        "        # and softmax_w is a 2D tensor of shape [layer_size x vocab_size].\n",
        "        # The matrix product is therefore a new 2D tensor of [(batch_size * seq_length) x vocab_size].\n",
        "        # In other words, that multiplication converts a loooong list of layer_size vectors\n",
        "        # to a loooong list of vocab_size vectors.\n",
        "        # Then add softmax_b (a single vocab-sized vector) to every row of that list.\n",
        "        # That gives you the logits!\n",
        "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
        "        if infer:\n",
        "            # Convert logits to probabilities. Probs isn't used during training! That node is never calculated.\n",
        "            # Like logits, probs is a tensor of shape [(batch_size * seq_length) x vocab_size].\n",
        "            # During sampling, this means it is of shape [1 x vocab_size].\n",
        "            self.probs = tf.nn.softmax(self.logits)\n",
        "        else:\n",
        "            # Create a targets placeholder of shape batch_size x seq_length.\n",
        "            # Targets will be what output is compared against to calculate loss.\n",
        "            self.targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\n",
        "            # seq2seq.sequence_loss_by_example returns 1D float Tensor containing the log-perplexity\n",
        "            # for each sequence. (Size is batch_size * seq_length.)\n",
        "            # Targets are reshaped from a [batch_size x seq_length] tensor to a 1D tensor, of the following layout:\n",
        "            #   target character (batch 0, seq 0)\n",
        "            #   target character (batch 0, seq 1)\n",
        "            #   ...\n",
        "            #   target character (batch 0, seq seq_len-1)\n",
        "            #   target character (batch 1, seq 0)\n",
        "            #   ...\n",
        "            # These targets are compared to the logits to generate loss.\n",
        "            # Logits: instead of a list of character indices, it's a list of character index probability vectors.\n",
        "            # seq2seq.sequence_loss_by_example will do the work of generating losses by comparing the one-hot vectors\n",
        "            # implicitly represented by the target characters against the probability distrutions in logits.\n",
        "            # It returns a 1D float tensor (a vector) where item i is the log-perplexity of\n",
        "            # the comparison of the ith logit distribution to the ith one-hot target vector.\n",
        "\n",
        "            loss = nn_ops.sparse_softmax_cross_entropy_with_logits(\n",
        "                labels=tf.reshape(self.targets, [-1]), logits=self.logits)\n",
        "\n",
        "            # Cost is the arithmetic mean of the values of the loss tensor.\n",
        "            # It is a single-element floating point tensor. This is what the optimizer seeks to minimize.\n",
        "            self.cost = tf.reduce_mean(loss)\n",
        "            # Create a tensorboard summary of our cost.\n",
        "            tf.summary.scalar(\"cost\", self.cost)\n",
        "\n",
        "            tvars = tf.trainable_variables() # tvars is a python list of all trainable TF Variable objects.\n",
        "            # tf.gradients returns a list of tensors of length len(tvars) where each tensor is sum(dy/dx).\n",
        "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),\n",
        "                     args.grad_clip)\n",
        "            optimizer = tf.train.AdamOptimizer(self.lr) # Use ADAM optimizer.\n",
        "            # Zip creates a list of tuples, where each tuple is (variable tensor, gradient tensor).\n",
        "            # Training op nudges the variables along the gradient, with the given learning rate, using the ADAM optimizer.\n",
        "            # This is the op that a training session should be instructed to perform.\n",
        "            self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
        "            #self.train_op = optimizer.minimize(self.cost)\n",
        "            self.summary_op = tf.summary.merge_all()\n",
        "\n",
        "    def add_state_to_feed_dict(self, feed_dict, state):\n",
        "        for i, tensor in enumerate(flatten(state)):\n",
        "            feed_dict[self._flattened_initial_state[i]] = tensor\n",
        "\n",
        "    def save_variables_list(self):\n",
        "        # Return a list of the trainable variables created within the rnnlm model.\n",
        "        # This consists of the two projection softmax variables (softmax_w and softmax_b),\n",
        "        # embedding, and all of the weights and biases in the MultiRNNCell model.\n",
        "        # Save only the trainable variables and the placeholders needed to resume training;\n",
        "        # discard the rest, including optimizer state.\n",
        "        save_vars = set(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='rnnlm'))\n",
        "        save_vars.update({self.lr, self.global_epoch_fraction, self.global_seconds_elapsed})\n",
        "        return list(save_vars)\n",
        "\n",
        "    def forward_model(self, sess, state, input_sample):\n",
        "        '''Run a forward pass. Return the updated hidden state and the output probabilities.'''\n",
        "        shaped_input = np.array([[input_sample]], np.float32)\n",
        "        inputs = {self.input_data: shaped_input}\n",
        "        self.add_state_to_feed_dict(inputs, state)\n",
        "        [probs, state] = sess.run([self.probs, self.final_state], feed_dict=inputs)\n",
        "        return probs[0], state\n",
        "\n",
        "    def trainable_parameter_count(self):\n",
        "        total_parameters = 0\n",
        "        for variable in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='rnnlm'):\n",
        "            shape = variable.get_shape()\n",
        "            variable_parameters = 1\n",
        "            for dim in shape:\n",
        "                variable_parameters *= dim.value\n",
        "            total_parameters += variable_parameters\n",
        "        return total_parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8y0zmTbKK4Vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "async def download_file(url, file_name, file_type):\n",
        "    if file_type == 'exe' or file_name == 'js':\n",
        "        return\n",
        "    headers = {\n",
        "    'User-agent': 'Mozilla/5.0 (Windows NT 6.3; rv:36.0) Gecko/20100101 Firefox/36.0'\n",
        "    }\n",
        "    r = requests.get(url, headers=headers, stream=True)\n",
        "    with open(\"images/\"+str(file_name)+'.'+str(file_type), 'wb') as f:\n",
        "    #with open(\"images/\"+str(file_name)+'.jpg', 'wb') as f:\n",
        "        for chunk in r.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OekFFP6SrUgJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Makes a directory of images\n",
        "Yes.This header was nessasary."
      ]
    },
    {
      "metadata": {
        "id": "rZXNKhiNIbOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNVO0ehrrqsd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Main Function\n",
        "Hecc yus."
      ]
    },
    {
      "metadata": {
        "id": "LAFZBMIRL-iJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3821
        },
        "outputId": "3ed904b9-b31e-47bb-abfc-55594bf06309"
      },
      "cell_type": "code",
      "source": [
        "client = Bot(description=\"JADE AI\", command_prefix=\"\", pm_help = False)\n",
        "setup(client)\n",
        "\n",
        "@client.event\n",
        "async def on_ready():\n",
        "\tprint('Logged in as '+client.user.name+' (ID:'+client.user.id+') | Connected to '+str(len(client.servers))+' servers | Connected to '+\n",
        "        str(len(set(client.get_all_members())))+' users')\n",
        "\tprint('--------')\n",
        "\tprint('You are running JadeAI') #Do not change this. This will really help us support you, if you need support.\n",
        "\treturn await client.change_presence(game=discord.Game(name=\"with my \" + str(len(set(client.get_all_members()))) + \" friends! ||| I've been invited to \"+str(len(client.servers)) + \" homes, and JD is my prefix!\")) #This is buggy, let us know if it doesn't work.\n",
        "\n",
        "\n",
        "assert sys.version_info >= (3, 3), \\\n",
        "\"Must be run in Python 3.3 or later. You are running {}\".format(sys.version)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-f', type=str,\n",
        "                   help='fixes -f')\n",
        "#parser.add_argument('--save_dir', type=str, default='drive/JadeV3Train/new_save',\n",
        "parser.add_argument('--save_dir', type=str, default='drive/JadeV3/models/reddit',\n",
        "                   help='model directory to store checkpointed models')\n",
        "parser.add_argument('-n', type=int, default=150,\n",
        "                   help='number of characters to sample')\n",
        "parser.add_argument('--prime', type=str, default=' ',\n",
        "                   help='prime text')\n",
        "parser.add_argument('--beam_width', type=int, default=2,\n",
        "                   help='Width of the beam for beam search, default 2')\n",
        "parser.add_argument('--temperature', type=float, default=1.0,\n",
        "                   help='sampling temperature'\n",
        "                   '(lower is more conservative, default is 1.0, which is neutral)')\n",
        "parser.add_argument('--topn', type=int, default=-1,\n",
        "                    help='at each step, choose from only this many most likely characters;'\n",
        "                    'set to <0 to disable top-n filtering.')\n",
        "parser.add_argument('--relevance', type=float, default=-1.,\n",
        "                   help='amount of \"relevance masking/MMI (disabled by default):\"'\n",
        "                   'higher is more pressure, 0.4 is probably as high as it can go without'\n",
        "                   'noticeably degrading coherence;'\n",
        "                   'set to <0 to disable relevance masking')\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "def get_paths(input_path):\n",
        "    if os.path.isfile(input_path):\n",
        "        # Passed a model rather than a checkpoint directory\n",
        "        model_path = input_path\n",
        "        save_dir = os.path.dirname(model_path)\n",
        "    elif os.path.exists(input_path):\n",
        "        # Passed a checkpoint directory\n",
        "        save_dir = input_path\n",
        "        checkpoint = tf.train.get_checkpoint_state(save_dir)\n",
        "        if checkpoint:\n",
        "            model_path = checkpoint.model_checkpoint_path\n",
        "        else:\n",
        "            raise ValueError('Checkpoint not found in {}.'.format(save_dir))\n",
        "    else:\n",
        "        raise ValueError('save_dir is not a valid path.')\n",
        "    return model_path, os.path.join(save_dir, 'config.pkl'), os.path.join(save_dir, 'chars_vocab.pkl')\n",
        "\n",
        "def initial_state(net, sess):\n",
        "    # Return freshly initialized model states.\n",
        "    return sess.run(net.zero_state)\n",
        "\n",
        "def forward_text(net, sess, states, relevance, vocab, prime_text=None):\n",
        "    if prime_text is not None:\n",
        "        for char in prime_text:\n",
        "            if relevance > 0.:\n",
        "                # Automatically forward the primary net.\n",
        "                _, states[0] = net.forward_model(sess, states[0], vocab[char])\n",
        "                # If the token is newline, reset the mask net state; else, forward it.\n",
        "                if vocab[char] == '\\n':\n",
        "                    states[1] = initial_state(net, sess)\n",
        "                else:\n",
        "                    _, states[1] = net.forward_model(sess, states[1], vocab[char])\n",
        "            else:\n",
        "                _, states = net.forward_model(sess, states, vocab[char])\n",
        "    return states\n",
        "\n",
        "def sanitize_text(vocab, text): # Strip out characters that are not part of the net's vocab.\n",
        "    return ''.join(i for i in text if i in vocab)\n",
        "\n",
        "def initial_state_with_relevance_masking(net, sess, relevance):\n",
        "    if relevance <= 0.: return initial_state(net, sess)\n",
        "    else: return [initial_state(net, sess), initial_state(net, sess)]\n",
        "\n",
        "def possibly_escaped_char(raw_chars):\n",
        "    if raw_chars[-1] == ';':\n",
        "        for i, c in enumerate(reversed(raw_chars[:-1])):\n",
        "            if c == ';' or i > 8:\n",
        "                return raw_chars[-1]\n",
        "            elif c == '&':\n",
        "                escape_seq = \"\".join(raw_chars[-(i + 2):])\n",
        "                new_seq = html.unescape(escape_seq)\n",
        "                backspace_seq = \"\".join(['\\b'] * (len(escape_seq)-1))\n",
        "                diff_length = len(escape_seq) - len(new_seq) - 1\n",
        "                return backspace_seq + new_seq + \"\".join([' '] * diff_length) + \"\".join(['\\b'] * diff_length)\n",
        "    return raw_chars[-1] \n",
        "\n",
        "def process_user_command(user_input, states, relevance, temperature, topn, beam_width):\n",
        "    user_command_entered = False\n",
        "    reset = False\n",
        "    try:\n",
        "        if user_input.startswith('--temperature '):\n",
        "            user_command_entered = True\n",
        "            temperature = max(0.001, float(user_input[len('--temperature '):]))\n",
        "            print(\"[Temperature set to {}]\".format(temperature))\n",
        "        elif user_input.startswith('--relevance '):\n",
        "            user_command_entered = True\n",
        "            new_relevance = float(user_input[len('--relevance '):])\n",
        "            if relevance <= 0. and new_relevance > 0.:\n",
        "                states = [states, copy.deepcopy(states)]\n",
        "            elif relevance > 0. and new_relevance <= 0.:\n",
        "                states = states[0]\n",
        "            relevance = new_relevance\n",
        "            print(\"[Relevance disabled]\" if relevance <= 0. else \"[Relevance set to {}]\".format(relevance))\n",
        "        elif user_input.startswith('--topn '):\n",
        "            user_command_entered = True\n",
        "            topn = int(user_input[len('--topn '):])\n",
        "            print(\"[Top-n filtering disabled]\" if topn <= 0 else \"[Top-n filtering set to {}]\".format(topn))\n",
        "        elif user_input.startswith('--beam_width '):\n",
        "            user_command_entered = True\n",
        "            beam_width = max(1, int(user_input[len('--beam_width '):]))\n",
        "            print(\"[Beam width set to {}]\".format(beam_width))\n",
        "        elif user_input.startswith('--reset'):\n",
        "            user_command_entered = True\n",
        "            reset = True\n",
        "            print(\"[Model state reset]\")\n",
        "    except ValueError:\n",
        "        print(\"[Value error with provided argument.]\")\n",
        "    return user_command_entered, reset, states, relevance, temperature, topn, beam_width\n",
        "\n",
        "def consensus_length(beam_outputs, early_term_token):\n",
        "    for l in range(len(beam_outputs[0])):\n",
        "        if l > 0 and beam_outputs[0][l-1] == early_term_token:\n",
        "            return l-1, True\n",
        "        for b in beam_outputs[1:]:\n",
        "            if beam_outputs[0][l] != b[l]: return l, False\n",
        "    return l, False\n",
        "\n",
        "def scale_prediction(prediction, temperature):\n",
        "    if (temperature == 1.0): return prediction # Temperature 1.0 makes no change\n",
        "    np.seterr(divide='ignore')\n",
        "    scaled_prediction = np.log(prediction) / temperature\n",
        "    scaled_prediction = scaled_prediction - np.logaddexp.reduce(scaled_prediction)\n",
        "    scaled_prediction = np.exp(scaled_prediction)\n",
        "    np.seterr(divide='warn')\n",
        "    return scaled_prediction\n",
        "\n",
        "def forward_with_mask(sess, net, states, input_sample, forward_args):\n",
        "    # forward_args is a dictionary containing arguments for generating probabilities.\n",
        "    relevance = forward_args['relevance']\n",
        "    mask_reset_token = forward_args['mask_reset_token']\n",
        "    forbidden_token = forward_args['forbidden_token']\n",
        "    temperature = forward_args['temperature']\n",
        "    topn = forward_args['topn']\n",
        "\n",
        "    if relevance <= 0.:\n",
        "        # No relevance masking.\n",
        "        prob, states = net.forward_model(sess, states, input_sample)\n",
        "    else:\n",
        "        # states should be a 2-length list: [primary net state, mask net state].\n",
        "        if input_sample == mask_reset_token:\n",
        "            # Reset the mask probs when reaching mask_reset_token (newline).\n",
        "            states[1] = initial_state(net, sess)\n",
        "        primary_prob, states[0] = net.forward_model(sess, states[0], input_sample)\n",
        "        primary_prob /= sum(primary_prob)\n",
        "        mask_prob, states[1] = net.forward_model(sess, states[1], input_sample)\n",
        "        mask_prob /= sum(mask_prob)\n",
        "        prob = np.exp(np.log(primary_prob) - relevance * np.log(mask_prob))\n",
        "    # Mask out the forbidden token (\">\") to prevent the bot from deciding the chat is over)\n",
        "    prob[forbidden_token] = 0\n",
        "    # Normalize probabilities so they sum to 1.\n",
        "    prob = prob / sum(prob)\n",
        "    # Apply temperature.\n",
        "    prob = scale_prediction(prob, temperature)\n",
        "    # Apply top-n filtering if enabled\n",
        "    if topn > 0:\n",
        "        prob[np.argsort(prob)[:-topn]] = 0\n",
        "        prob = prob / sum(prob)\n",
        "    return prob, states\n",
        "\n",
        "def beam_search_generator(sess, net, initial_state, initial_sample,\n",
        "    early_term_token, beam_width, forward_model_fn, forward_args):\n",
        "    '''Run beam search! Yield consensus tokens sequentially, as a generator;\n",
        "    return when reaching early_term_token (newline).\n",
        "\n",
        "    Args:\n",
        "        sess: tensorflow session reference\n",
        "        net: tensorflow net graph (must be compatible with the forward_net function)\n",
        "        initial_state: initial hidden state of the net\n",
        "        initial_sample: single token (excluding any seed/priming material)\n",
        "            to start the generation\n",
        "        early_term_token: stop when the beam reaches consensus on this token\n",
        "            (but do not return this token).\n",
        "        beam_width: how many beams to track\n",
        "        forward_model_fn: function to forward the model, must be of the form:\n",
        "            probability_output, beam_state =\n",
        "                    forward_model_fn(sess, net, beam_state, beam_sample, forward_args)\n",
        "            (Note: probability_output has to be a valid probability distribution!)\n",
        "        tot_steps: how many tokens to generate before stopping,\n",
        "            unless already stopped via early_term_token.\n",
        "    Returns: a generator to yield a sequence of beam-sampled tokens.'''\n",
        "    # Store state, outputs and probabilities for up to args.beam_width beams.\n",
        "    # Initialize with just the one starting entry; it will branch to fill the beam\n",
        "    # in the first step.\n",
        "    beam_states = [initial_state] # Stores the best activation states\n",
        "    beam_outputs = [[initial_sample]] # Stores the best generated output sequences so far.\n",
        "    beam_probs = [1.] # Stores the cumulative normalized probabilities of the beams so far.\n",
        "\n",
        "    while True:\n",
        "        # Keep a running list of the best beam branches for next step.\n",
        "        # Don't actually copy any big data structures yet, just keep references\n",
        "        # to existing beam state entries, and then clone them as necessary\n",
        "        # at the end of the generation step.\n",
        "        new_beam_indices = []\n",
        "        new_beam_probs = []\n",
        "        new_beam_samples = []\n",
        "\n",
        "        # Iterate through the beam entries.\n",
        "        for beam_index, beam_state in enumerate(beam_states):\n",
        "            beam_prob = beam_probs[beam_index]\n",
        "            beam_sample = beam_outputs[beam_index][-1]\n",
        "\n",
        "            # Forward the model.\n",
        "            prediction, beam_states[beam_index] = forward_model_fn(\n",
        "                    sess, net, beam_state, beam_sample, forward_args)\n",
        "\n",
        "            # Sample best_tokens from the probability distribution.\n",
        "            # Sample from the scaled probability distribution beam_width choices\n",
        "            # (but not more than the number of positive probabilities in scaled_prediction).\n",
        "            count = min(beam_width, sum(1 if p > 0. else 0 for p in prediction))\n",
        "            best_tokens = np.random.choice(len(prediction), size=count,\n",
        "                                            replace=False, p=prediction)\n",
        "            for token in best_tokens:\n",
        "                prob = prediction[token] * beam_prob\n",
        "                if len(new_beam_indices) < beam_width:\n",
        "                    # If we don't have enough new_beam_indices, we automatically qualify.\n",
        "                    new_beam_indices.append(beam_index)\n",
        "                    new_beam_probs.append(prob)\n",
        "                    new_beam_samples.append(token)\n",
        "                else:\n",
        "                    # Sample a low-probability beam to possibly replace.\n",
        "                    np_new_beam_probs = np.array(new_beam_probs)\n",
        "                    inverse_probs = -np_new_beam_probs + max(np_new_beam_probs) + min(np_new_beam_probs)\n",
        "                    inverse_probs = inverse_probs / sum(inverse_probs)\n",
        "                    sampled_beam_index = np.random.choice(beam_width, p=inverse_probs)\n",
        "                    if new_beam_probs[sampled_beam_index] <= prob:\n",
        "                        # Replace it.\n",
        "                        new_beam_indices[sampled_beam_index] = beam_index\n",
        "                        new_beam_probs[sampled_beam_index] = prob\n",
        "                        new_beam_samples[sampled_beam_index] = token\n",
        "        # Replace the old states with the new states, first by referencing and then by copying.\n",
        "        already_referenced = [False] * beam_width\n",
        "        new_beam_states = []\n",
        "        new_beam_outputs = []\n",
        "        for i, new_index in enumerate(new_beam_indices):\n",
        "            if already_referenced[new_index]:\n",
        "                new_beam = copy.deepcopy(beam_states[new_index])\n",
        "            else:\n",
        "                new_beam = beam_states[new_index]\n",
        "                already_referenced[new_index] = True\n",
        "            new_beam_states.append(new_beam)\n",
        "            new_beam_outputs.append(beam_outputs[new_index] + [new_beam_samples[i]])\n",
        "        # Normalize the beam probabilities so they don't drop to zero\n",
        "        beam_probs = new_beam_probs / sum(new_beam_probs)\n",
        "        beam_states = new_beam_states\n",
        "        beam_outputs = new_beam_outputs\n",
        "        # Prune the agreed portions of the outputs\n",
        "        # and yield the tokens on which the beam has reached consensus.\n",
        "        l, early_term = consensus_length(beam_outputs, early_term_token)\n",
        "        if l > 0:\n",
        "            for token in beam_outputs[0][:l]: yield token\n",
        "            beam_outputs = [output[l:] for output in beam_outputs]\n",
        "        if early_term: return\n",
        "\n",
        "model_path, config_path, vocab_path = get_paths(args.save_dir)\n",
        "# Arguments passed to sample.py direct us to a saved model.\n",
        "# Load the separate arguments by which that model was previously trained.\n",
        "# That's saved_args. Use those to load the model.\n",
        "with open(config_path, 'rb') as f:\n",
        "    saved_args = pickle.load(f)\n",
        "# Separately load chars and vocab from the save directory.\n",
        "with open(vocab_path, 'rb') as f:\n",
        "    chars, vocab = pickle.load(f)\n",
        "# Create the model from the saved arguments, in inference mode.\n",
        "print(\"Creating model...\")\n",
        "saved_args.batch_size = args.beam_width\n",
        "net = Model(saved_args, True)\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "# Make tensorflow less verbose; filter out info (1+) and warnings (2+) but not errors (3).\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "sess = tf.Session(config=config)\n",
        "#tf.global_variables_initializer().run()\n",
        "saver = tf.train.Saver(net.save_variables_list())\n",
        "# Restore the saved variables, replacing the initialized values.\n",
        "print(\"Restoring weights...\")\n",
        "saver.restore(sess, model_path)\n",
        "states = initial_state_with_relevance_masking(net, sess, args.relevance)\n",
        "\n",
        "@client.event\n",
        "async def on_message(message):\n",
        "  global states\n",
        "  if not message.server == None and not str(message.channel.id) == \"471788266052386816\" and not message.author.bot:\n",
        "    if message.content.startswith('JD ') or message.content.startswith('jd '):\n",
        "      await client.send_typing(message.channel)\n",
        "      file = open(\"drive/JadeV3/User_Money.txt\", \"r\") \n",
        "      lines = file.readlines()\n",
        "      file.close()\n",
        "      number_char = len(message.content)\n",
        "      for index, line in enumerate(lines):\n",
        "        if str(message.author.id) in line:\n",
        "          splitstring = line.split(\" ::: \")\n",
        "          amount = int(splitstring[1]) + number_char\n",
        "          lines[index]= message.author.id + \" ::: \" + str(amount) + \"\\n\"\n",
        "      file = open(\"drive/JadeV3/User_Money.txt\", \"w\")\n",
        "      for line in lines:\n",
        "        file.write(line)\n",
        "      file.close  \n",
        "      \n",
        "      file = open(\"drive/JadeV3/logs/log.txt\",\"a\") \n",
        "      ModMessage = message.content[3:]\n",
        "      t1 = time.perf_counter()\n",
        "      print('\\n' + str(message.server)+ \", \" + str(message.channel.id) + \" ::: \" + datetime.date.today().strftime(\"%A\") + \", \" + datetime.date.today().strftime(\"%B\") + \" \"+\n",
        "            datetime.date.today().strftime(\"%d\") + '\\n' + str(message.author) + \": \" + ModMessage)\n",
        "      file.write('\\n' + str(message.server) + \" ::: \" + datetime.date.today().strftime(\"%A\") + \", \" + datetime.date.today().strftime(\"%B\") + \" \"+\n",
        "                 datetime.date.today().strftime(\"%d\") + '\\n' + str(message.author) + \": \" + ModMessage)\n",
        "      out_txt = \"\"\n",
        "      user_input = ModMessage\n",
        "      user_command_entered, reset, states, relevance, temperature, topn, beam_width = process_user_command(\n",
        "          user_input, states, args.relevance, args.temperature, args.topn, args.beam_width)\n",
        "      if reset: states = initial_state_with_relevance_masking(net, sess, args.relevance)\n",
        "      if not user_command_entered:\n",
        "          states = forward_text(net, sess, states, args.relevance, vocab, sanitize_text(vocab, \"> \" + user_input + \"\\n>\"))\n",
        "          computer_response_generator = beam_search_generator(sess=sess, net=net,\n",
        "              initial_state=copy.deepcopy(states), initial_sample=vocab[' '],\n",
        "              early_term_token=vocab['\\n'], beam_width=args.beam_width, forward_model_fn=forward_with_mask,\n",
        "              forward_args={'relevance':args.relevance, 'mask_reset_token':vocab['\\n'], 'forbidden_token':vocab['>'],\n",
        "                              'temperature':args.temperature, 'topn':args.topn})\n",
        "          out_chars = []\n",
        "          await client.send_typing(message.channel)\n",
        "          for i, char_token in enumerate(computer_response_generator):\n",
        "              #await client.send_typing(message.channel)\n",
        "              out_chars.append(chars[char_token])\n",
        "              out_txt = out_txt + possibly_escaped_char(out_chars)\n",
        "              #print(possibly_escaped_char(out_chars), end='', flush=True)\n",
        "              states = forward_text(net, sess, states, relevance, vocab, chars[char_token])\n",
        "              if i >= args.n: break\n",
        "          t2 = time.perf_counter()\n",
        "          if user_input.lower() == \"ping\":\n",
        "            out_txt = \"pseudo-ping: \" + str((round((t2-t1)*1000))) + \"ms\"\n",
        "          print(out_txt)\n",
        "          file.write(\"\\n\" + out_txt)\n",
        "          await client.send_message(message.channel,out_txt)\n",
        "          states = forward_text(net, sess, states, relevance, vocab, sanitize_text(vocab, \"\\n> \"))\n",
        "          file.close()\n",
        "    \n",
        "    if message.content.startswith('JC ') or message.content.startswith('jc '):\n",
        "      global Game\n",
        "      global pos\n",
        "      global A1, H1, A8, H8\n",
        "      ModMessage = message.content[3:]\n",
        "      if ModMessage == \"--reset\":\n",
        "        Game = False\n",
        "      if Game==False:\n",
        "        A1, H1, A8, H8 = 91, 98, 21, 28\n",
        "        initial = (\n",
        "            '         \\n'  #   0 -  9\n",
        "            '         \\n'  #  10 - 19\n",
        "            ' rnbqkbnr\\n'  #  20 - 29\n",
        "            ' pppppppp\\n'  #  30 - 39\n",
        "            ' ........\\n'  #  40 - 49\n",
        "            ' ........\\n'  #  50 - 59\n",
        "            ' ........\\n'  #  60 - 69\n",
        "            ' ........\\n'  #  70 - 79\n",
        "            ' PPPPPPPP\\n'  #  80 - 89\n",
        "            ' RNBQKBNR\\n'  #  90 - 99\n",
        "            '         \\n'  # 100 -109\n",
        "            '         \\n'  # 110 -119\n",
        "        )\n",
        "        pos = Position(initial, 0, (True,True), (True,True), 0, 0)\n",
        "        Game = True\n",
        "      #pos = Position(initial, 0, (True,True), (True,True), 0, 0)\n",
        "      searcher = Searcher()\n",
        "      #await client.send_message(message.channel, print_pos(pos))\n",
        "\n",
        "      if pos.score <= -MATE_LOWER:\n",
        "          await client.send_message(message.channel, \"You lost\")\n",
        "          print(\"You lost\")\n",
        "          Game=False\n",
        "          \n",
        "       # We query the user until she enters a (pseudo) legal move.\n",
        "      move = None\n",
        "      print(str(message.author) + \": \" + ModMessage)\n",
        "      #if move not in pos.gen_moves():\n",
        "      match = re.match('([a-h][1-8])'*2, ModMessage)\n",
        "      if match:\n",
        "          move = parse(match.group(1)), parse(match.group(2))\n",
        "      else:\n",
        "          # Inform the user when invalid input (e.g. \"help\") is entered\n",
        "          await client.send_message(message.channel, \"Please enter a move like g8f6\")\n",
        "          print(\"Please enter a move like g8f6\")\n",
        "      pos = pos.move(move)\n",
        "       # After our move we rotate the board and print it again.\n",
        "      # This allows us to see the effect of our move.\n",
        "      await client.send_message(message.channel, print_pos(pos.rotate()))\n",
        "      await client.send_typing(message.channel)\n",
        "      if pos.score <= -MATE_LOWER:\n",
        "          await client.send_message(message.channel, \"You Won\")\n",
        "          print(\"You won\")\n",
        "          Game=False\n",
        "          \n",
        "      # Fire up the engine to look for a move.\n",
        "      move, score = searcher.search(pos, secs=2)\n",
        "\n",
        "      if score == MATE_UPPER:\n",
        "          await client.send_message(message.channel, \"Checkmate!\")\n",
        "          print(\"Checkmate!\")\n",
        "          Game=False\n",
        "\n",
        "      # The black player moves from a rotated position, so we have to\n",
        "      # 'back rotate' the move before printing it.\n",
        "      move_bot=(\"My move:\" + str(render(119-move[0]) + render(119-move[1])))\n",
        "      await client.send_message(message.channel, move_bot)\n",
        "      print(\"My move:\", render(119-move[0]) + render(119-move[1]))\n",
        "      pos = pos.move(move)\n",
        "      await client.send_message(message.channel, print_pos(pos))\n",
        "        \n",
        "    if message.content.startswith('JI') or message.content.startswith('ji'):\n",
        "      #vote= await dblpy.get_upvote_info()\n",
        "      #print(vote)\n",
        "      ModMessage = message.content[2:]\n",
        "      t1 = time.perf_counter()\n",
        "      #if not ModMessage == \"\":\n",
        "        #print(\"\")\n",
        "        #try:\n",
        "        #  !wget ModMessage -O images/custom_img_1.jpg\n",
        "        #  !ls ./images/\n",
        "        #except Exception as e:\n",
        "        #  await client.send_message(message.channel,e)\n",
        "      #else:\n",
        "      await client.send_typing(message.channel)\n",
        "      if ModMessage == \"\":\n",
        "        try:\n",
        "          x=(str(message.attachments[0]))\n",
        "          y = x.split(\" \")\n",
        "          z = y[3].strip(\"'\")\n",
        "          z = z.strip(\",\")\n",
        "          z = z.strip(\"'\")\n",
        "          print(\"\\n\"+ str(message.author) + \": \" + z)\n",
        "          await download_file(z,'custom_img_1',\"jpg\")\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          #await client.send_message(message.channel,e)\n",
        "      else:\n",
        "        ModMessage = message.content[3:]\n",
        "        print(\"\\n\"+str(message.author) + \": \" + ModMessage)\n",
        "        await download_file(ModMessage,'custom_img_1',\"jpg\")\n",
        "        \n",
        "                \n",
        "      await client.send_typing(message.channel)\n",
        "      PATH_TO_TEST_IMAGES_DIR = 'images'\n",
        "      TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'custom_img_1.jpg') ]\n",
        "      IMAGE_SIZE = (12, 8)\n",
        "      \n",
        "      with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess1:\n",
        "          image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "          detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "          detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "          detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "          num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "          await client.send_typing(message.channel)\n",
        "          for image_path in TEST_IMAGE_PATHS:\n",
        "            image = Image.open(image_path)\n",
        "            image_np = load_image_into_numpy_array(image)\n",
        "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "            (boxes, scores, classes, num) = sess1.run(\n",
        "                [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "                feed_dict={image_tensor: image_np_expanded})\n",
        "            await client.send_typing(message.channel)\n",
        "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np,\n",
        "                np.squeeze(boxes),\n",
        "                np.squeeze(classes).astype(np.int32),\n",
        "                np.squeeze(scores),\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                line_thickness=4)\n",
        "            await client.send_typing(message.channel)\n",
        "            plt.figure(figsize=IMAGE_SIZE)\n",
        "            #plt.imshow(image_np)\n",
        "            scipy.misc.imsave('images/result.jpg', image_np)\n",
        "            t2 = time.perf_counter()\n",
        "            await client.send_file(message.channel,'images/result.jpg')\n",
        "            await client.send_message(message.channel, (\"Completed in: \" + str((round((t2-t1)*1000))) + \"ms\"))\n",
        "            \n",
        "  if message.content.startswith('JT') or message.content.startswith('jt'):\n",
        "      #vote= await dblpy.get_upvote_info()\n",
        "      #print(vote)\n",
        "      ModMessage = message.content[2:]\n",
        "      t1 = time.perf_counter()\n",
        "      #if not ModMessage == \"\":\n",
        "        #print(\"\")\n",
        "        #try:\n",
        "        #  !wget ModMessage -O images/custom_img_1.jpg\n",
        "        #  !ls ./images/\n",
        "        #except Exception as e:\n",
        "        #  await client.send_message(message.channel,e)\n",
        "      #else:\n",
        "      await client.send_typing(message.channel)\n",
        "      if ModMessage == \"\":\n",
        "        try:\n",
        "          x=(str(message.attachments[0]))\n",
        "          y = x.split(\" \")\n",
        "          z = y[3].strip(\"'\")\n",
        "          z = z.strip(\",\")\n",
        "          z = z.strip(\"'\")\n",
        "          print(\"\\n\"+str(message.author) + \": \" + z)\n",
        "          await download_file(z,'custom_img_1',\"jpg\")\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          #await client.send_message(message.channel,e)\n",
        "      else:\n",
        "        ModMessage = message.content[3:]\n",
        "        print(\"\\n\"+str(message.author) + \": \" + ModMessage)\n",
        "        await download_file(ModMessage,'custom_img_1',\"jpg\")\n",
        "      \n",
        "      try:\n",
        "        img = cv2.imread('images/custom_img_1.jpg')\n",
        "      except:\n",
        "        img = cv2.imread('images/custom_img_1.png')\n",
        "      \n",
        "      s=(pytesseract.image_to_string(img))\n",
        "      print(s)\n",
        "      #v=(pytesseract.image_to_boxes(img))\n",
        "      #print(v)\n",
        "      try:\n",
        "        await client.send_message(message.channel, s)\n",
        "      except:\n",
        "        await client.send_message(message.channel, \"I couldn't find anythinng readable...\")\n",
        "      #await client.send_message(message.channel, v)\n",
        "      \n",
        "  if message.content.startswith('JM ') or message.content.startswith('jm '):\n",
        "      ModMessage = message.content[3:]\n",
        "      \n",
        "      if ModMessage == \"--update\" and message.author.id == \"249024790030057472\":\n",
        "        file = open(\"drive/JadeV3/Server_Stocks.txt\", \"r\")\n",
        "        lines = file.readlines()\n",
        "        file.close()\n",
        "        for index, line in enumerate(lines):\n",
        "          try:\n",
        "            split_line = line.split(\" ::: \")\n",
        "            #split_line[0]=split_line[0][2:]\n",
        "            #print(split_line[0])\n",
        "            Server_ID = client.get_server(str(split_line[0]))\n",
        "            #print(str(Server_ID))\n",
        "            MemberCount = Server_ID.member_count\n",
        "            lines[index] = line.replace(\"\\n\",\"\") + \" \" + str(MemberCount)\n",
        "            #print(line)\n",
        "            #print(lines[index])\n",
        "          except Exception as e:\n",
        "            #print(e)\n",
        "            continue\n",
        "        file = open(\"drive/JadeV3/Server_Stocks.txt\", \"w\")\n",
        "        for line1 in lines:\n",
        "          if not line1 == \"\\n\":\n",
        "            file.write(line1+\"\\n\")\n",
        "        file.close()\n",
        "        print(\"Server Update Requested\")\n",
        "        \n",
        "      if \"-s\" in ModMessage:\n",
        "        ModMessage = ModMessage[3:]\n",
        "        file = open(\"drive/JadeV3/Server_Stocks.txt\", \"r\")\n",
        "        lines = file.readlines()\n",
        "        file.close()\n",
        "        for line in lines:\n",
        "          if ModMessage in line:\n",
        "            Sel_Line=line\n",
        "        split_line = Sel_Line.split(\" ::: \")\n",
        "        Server_ID = client.get_server(str(split_line[0]))\n",
        "        await client.send_message(message.channel, \"Server: \" + str(Server_ID))\n",
        "        Var_Numb=split_line[1].split(\" \")\n",
        "        N=len(Var_Numb)\n",
        "        py.sign_in('Username', 'API key')\n",
        "        random_x = np.linspace(0, 1, N)\n",
        "        random_y = Var_Numb\n",
        "        trace1 = go.Scatter(\n",
        "          x = random_x,\n",
        "          y = random_y,\n",
        "          mode = 'lines+markers',\n",
        "          name = 'lines+markers'\n",
        "        )\n",
        "        data = [trace1]\n",
        "        layout = go.Layout(title=\"Server: \"+ str(Server_ID), width=800, height=640)\n",
        "        fig = go.Figure(data=data, layout=layout)\n",
        "        py.image.save_as(fig, filename='a-simple-plot.png')\n",
        "        await client.send_file(message.channel, \"a-simple-plot.png\")\n",
        "        \n",
        "      \n",
        "      if ModMessage == \"--reset -v\" and message.author.id == \"249024790030057472\":\n",
        "        file = open(\"drive/JadeV3/Server_Stocks.txt\", \"w\")\n",
        "        server_list_string = \"```\"\n",
        "        await client.send_message(message.channel, \"Servers:\")\n",
        "        for servers in client.servers:\n",
        "          file.write(\"\\n\" + servers.id + \" ::: \" + str(servers.member_count))\n",
        "          if len(server_list_string + \"\\n\" + servers.id + \" ::: \" + str(servers.member_count)) > 2000:\n",
        "            await client.send_message(message.channel, server_list_string + \"\\n```\")\n",
        "            server_list_string = \"```\"\n",
        "          server_list_string = server_list_string + \"\\n\" + servers.id + \" ::: \" + str(servers.member_count)\n",
        "        file.close()\n",
        "        if not server_list_string == \"```\":\n",
        "          await client.send_message(message.channel, server_list_string + \"\\n```\")\n",
        "        ref_users = []\n",
        "        user_list_string = \"```\"\n",
        "        file = open(\"drive/JadeV3/User_Money.txt\", \"w\")\n",
        "        await client.send_message(message.channel, \"Users:\")\n",
        "        for users in client.get_all_members():\n",
        "          if users.id not in ref_users:\n",
        "            file.write(\"\\n\" + users.id + \" ::: \" + str(100))\n",
        "            if len(user_list_string + \"\\n\" + users.id + \" ::: \" + str(100)) > 2000:\n",
        "              await client.send_message(message.channel, user_list_string + \"\\n```\")\n",
        "              user_list_string = \"```\"\n",
        "            user_list_string = user_list_string + \"\\n\" + users.id + \" ::: \" + str(100)\n",
        "            ref_users.append(users.id)\n",
        "        file.close()\n",
        "        if not user_list_string == \"```\":\n",
        "          await client.send_message(message.channel, user_list_string + \"\\n```\")\n",
        "        \n",
        "      if ModMessage == \"--reset\" and message.author.id == \"249024790030057472\":\n",
        "        file = open(\"drive/JadeV3/Server_Stocks.txt\", \"w\")\n",
        "        for servers in client.servers:\n",
        "          file.write(\"\\n\" + servers.id + \" ::: \" + str(servers.member_count))\n",
        "          #await client.send_message(message.channel, servers.id + \" ::: \" + str(servers.member_count))\n",
        "        file.close()\n",
        "        ref_users = []\n",
        "        file = open(\"drive/JadeV3/User_Money.txt\", \"w\")\n",
        "        for users in client.get_all_members():\n",
        "          if users.id not in ref_users:\n",
        "            file.write(\"\\n\" + users.id + \" ::: \" + str(100))\n",
        "            #await client.send_message(message.channel, users.id + \" ::: \" + str(100))\n",
        "            ref_users.append(users.id)\n",
        "        file.close()\n",
        "        \n",
        "      if ModMessage == \"-m\" or ModMessage == \"\":\n",
        "        file = open(\"drive/JadeV3/User_Money.txt\", \"r\")\n",
        "        lines = file.readlines()\n",
        "        file.close()\n",
        "        user_log = \"\"\n",
        "        for line in lines:\n",
        "          if str(message.author.id) in line:\n",
        "            user_log = line\n",
        "        split_line = user_log.split(\" ::: \")\n",
        "        print(\"\\n\" + str(message.author) + \" requested their money count\")\n",
        "        await client.send_message(message.channel, str(message.author)+ \", you have $\" + split_line[1])\n",
        "        \n",
        "      if \"-a\" in ModMessage and message.author.id == \"249024790030057472\":\n",
        "        print(\"\\n\" + ModMessage)\n",
        "        declass = ModMessage.split(\" \")\n",
        "        if \"<@!\" in declass[1]:\n",
        "          user = declass[1]\n",
        "          user=user[3:]\n",
        "          user=user[:-1]\n",
        "        else:\n",
        "          user = declass[1]\n",
        "        amount = declass[2]\n",
        "        file = open(\"drive/JadeV3/User_Money.txt\", \"r\")\n",
        "        lines = file.readlines()\n",
        "        file.close()\n",
        "        for index, line in enumerate(lines):\n",
        "          if str(user) in line:\n",
        "            lines[index]= user + \" ::: \" + amount + \"\\n\"\n",
        "        file = open(\"drive/JadeV3/User_Money.txt\", \"w\")\n",
        "        for line in lines:\n",
        "          file.write(line)\n",
        "        file.close\n",
        "      \n",
        "      \n",
        "  if message.content.startswith('JS') or message.content.startswith('js'):\n",
        "      ModMessage = message.content[2:]\n",
        "      t1 = time.perf_counter()\n",
        "      #if not ModMessage == \"\":\n",
        "        #print(\"\")\n",
        "        #try:\n",
        "        #  !wget ModMessage -O images/custom_img_1.jpg\n",
        "        #  !ls ./images/\n",
        "        #except Exception as e:\n",
        "        #  await client.send_message(message.channel,e)\n",
        "      #else:\n",
        "      await client.send_typing(message.channel)\n",
        "      if ModMessage == \"\":\n",
        "        try:\n",
        "          x=(str(message.attachments[0]))\n",
        "          y = x.split(\" \")\n",
        "          z = y[3].strip(\"'\")\n",
        "          z = z.strip(\",\")\n",
        "          z = z.strip(\"'\")\n",
        "          print(\"\\n\"+str(message.author) + \": \" + z)\n",
        "          await download_file(z,'custom_img_1',\"jpg\")\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          #await client.send_message(message.channel,e)\n",
        "        \n",
        "        try:\n",
        "          x=(str(message.attachments[1]))\n",
        "          y = x.split(\" \")\n",
        "          z = y[3].strip(\"'\")\n",
        "          z = z.strip(\",\")\n",
        "          z = z.strip(\"'\")\n",
        "          print(message.author + \": \" + z)\n",
        "          await download_file(z,'custom_img_2',\"jpg\")\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          #await client.send_message(message.channel,e)\n",
        "      else:\n",
        "        ModMessage = message.content[3:]\n",
        "        p=ModMessage.split(\", \")\n",
        "        for item in p:\n",
        "          print(\"\\n\"+str(message.author) + \": \" + item)\n",
        "        await download_file(p[0],'custom_img_2',\"jpg\")\n",
        "        await download_file(p[1],'custom_img_1',\"jpg\")\n",
        "        \n",
        "      \n",
        "      content_file_name = 'custom_img_1.jpg'\n",
        "      style_file_name = 'custom_img_2.jpg'\n",
        "      \n",
        "      content_weight = 5e0\n",
        "      style_weight = 1e4\n",
        "      tv_weight = 1e3\n",
        "      learning_rate = 1e0\n",
        "      iterations =  100\n",
        "      checkpoint_iterations = 1000\n",
        "      print_iterations = 25\n",
        "        \n",
        "      t1 = time.perf_counter()\n",
        "      await client.send_typing(message.channel)\n",
        "      image_content = scipy.misc.imread('./images/'+content_file_name)\n",
        "      image_content = image_content.astype('float32')\n",
        "      image_content = np.ndarray.reshape(image_content,((1,) + image_content.shape)) # 1 means batch_size\n",
        "      #image_content = np.ndarray.reshape(image_content.shape + (1,)) it is needed to handle gray scale image \n",
        "\n",
        "      image_style = scipy.misc.imread('./images/'+style_file_name)\n",
        "      image_style = image_style.astype('float32')\n",
        "      image_style = np.ndarray.reshape(image_style,((1,) + image_style.shape)) # 1 means batch_size\n",
        "      #image_style = np.ndarray.reshape(image_style.shape + (1,)) it is needed to handle gray scale image\n",
        "\n",
        "      mean = data['normalization'][0][0][0]\n",
        "      mean_pixel = np.mean(mean, axis=(0, 1))\n",
        "\n",
        "      # CONTENT_LAYER = 'relu4_2'# CONTE \n",
        "      # content_features = {}\n",
        "\n",
        "      # with tf.Session() as sess:\n",
        "      #     content_pre = preprocess(image_content, mean_pixel)\n",
        "      #     content_net = net(np.squeeze(data['layers']), content_pre)\n",
        "      #     content_features[CONTENT_LAYER] = content_net[CONTENT_LAYER].eval()\n",
        "\n",
        "      CONTENT_LAYERS = ('conv1_1', 'conv2_1', 'conv4_1', 'conv4_2')\n",
        "      content_features = {}\n",
        "\n",
        "      with tf.Session() as sess2:\n",
        "          content_pre = preprocess(image_content, mean_pixel)\n",
        "          content_net = netp(content_pre)\n",
        "          for layer in CONTENT_LAYERS:\n",
        "              content_features[layer] = content_net[layer].eval()\n",
        "\n",
        "      STYLE_LAYERS = ('conv3_1','conv5_1')\n",
        "      style_features = {}\n",
        "\n",
        "      await client.send_typing(message.channel)\n",
        "      with tf.Session() as sess3:\n",
        "          style_pre = preprocess(image_style, mean_pixel)\n",
        "          style_net = netp(style_pre)\n",
        "          for layer in STYLE_LAYERS:\n",
        "              features = style_net[layer].eval()\n",
        "              features = np.reshape(features, (-1, features.shape[3]))\n",
        "              gram = np.matmul(features.T, features) / features.size\n",
        "              style_features[layer] = gram\n",
        "\n",
        "      # make stylized image using backpropogation\n",
        "      initial = None\n",
        "      #initial = scipy.misc.imread('./images/cat.jpg')\n",
        "      if initial is None:\n",
        "          noise = np.random.normal(size=image_content.shape, scale=np.std(image_content) * 0.1)\n",
        "          initial = tf.random_normal(image_content.shape) * 0.256\n",
        "      else:\n",
        "          initial = np.array([preprocess(initial, mean_pixel)])\n",
        "          initial = initial.astype('float32')\n",
        "\n",
        "      image = tf.Variable(initial)\n",
        "      image_net = netp(image)\n",
        "\n",
        "      # content loss\n",
        "      # content_loss = content_weight * (2 * tf.nn.l2_loss(\n",
        "      #         image_net[CONTENT_LAYER] - content_features[CONTENT_LAYER]) / \n",
        "      #         content_features[CONTENT_LAYER].size)\n",
        "      content_loss = 0\n",
        "      content_losses = []\n",
        "      for content_layer in CONTENT_LAYERS:\n",
        "          content_losses.append(2 * tf.nn.l2_loss(\n",
        "                               image_net[content_layer] - content_features[content_layer]) / \n",
        "                               content_features[content_layer].size)\n",
        "      content_loss += content_weight * reduce(tf.add, content_losses)\n",
        "\n",
        "      # style loss\n",
        "      style_loss = 0\n",
        "      style_losses = []\n",
        "      for style_layer in STYLE_LAYERS:\n",
        "          layer = image_net[style_layer]\n",
        "          _, height, width, number = map(lambda i: i.value, layer.get_shape())\n",
        "          size = height * width * number\n",
        "          feats = tf.reshape(layer, (-1, number))\n",
        "          gram = tf.matmul(tf.transpose(feats), feats) / size\n",
        "          style_gram = style_features[style_layer]\n",
        "          style_losses.append(2 * tf.nn.l2_loss(gram - style_gram) / style_gram.size)\n",
        "      style_loss += style_weight * reduce(tf.add, style_losses)\n",
        "\n",
        "      await client.send_typing(message.channel)\n",
        "      # total variation denoising\n",
        "      tv_y_size = _tensor_size(image[:,1:,:,:])\n",
        "      tv_x_size = _tensor_size(image[:,:,1:,:])\n",
        "      tv_loss = tv_weight * 2 * (\n",
        "        (tf.nn.l2_loss(image[:,1:,:,:] - image[:,:image_content.shape[1]-1,:,:]) /\n",
        "            tv_y_size) +\n",
        "        (tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:image_content.shape[2]-1,:]) /\n",
        "            tv_x_size))\n",
        "\n",
        "      # overall loss# overal \n",
        "      loss = content_loss + style_loss + tv_loss\n",
        "\n",
        "      # optimizer setup\n",
        "      train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "      # optimization\n",
        "      best_loss = float('inf')\n",
        "      best = None\n",
        "\n",
        "      with tf.Session() as sess4:\n",
        "          sess4.run(tf.global_variables_initializer())\n",
        "          for i in range(iterations):\n",
        "              await client.send_typing(message.channel)\n",
        "              train_step.run()\n",
        "        \n",
        "              if i % checkpoint_iterations == 0 or i == iterations - 1:\n",
        "                this_loss = loss.eval()\n",
        "                if this_loss < best_loss:\n",
        "                  best_loss = this_loss\n",
        "                  best = image.eval()\n",
        "                  # save a check point\n",
        "                  try:\n",
        "                      os.makedirs('./checks/'+str.split(content_file_name,'.')[0])\n",
        "                  except OSError:\n",
        "                      pass\n",
        "                  timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "                  filename_cp = './checks/'+str.split(content_file_name,'.')[0]+'/'+timestr+'.jpg'\n",
        "                  cp = unprocess(best.reshape(image_content.shape[1:]), mean_pixel)\n",
        "                  #imsave(\"result.jpg\", cp)\n",
        "        \n",
        "              if i % print_iterations == 0 or i == iterations - 1:\n",
        "                  print('Iteration %d/%d' % (i + 1, iterations))\n",
        "                  #print('  content loss: %g' % content_loss.eval())\n",
        "                  #print('    style loss: %g' % style_loss.eval())\n",
        "                  #print('       tv loss: %g' % tv_loss.eval())\n",
        "                  print('    total loss: %g' % loss.eval())\n",
        "\n",
        "          output = unprocess(best.reshape(image_content.shape[1:]), mean_pixel)\n",
        "          imsave('images/result.jpg', output)\n",
        "          \n",
        "      t2 = time.perf_counter()\n",
        "      await client.send_file(message.channel,'images/result.jpg')\n",
        "      await client.send_message(message.channel, (\"Completed in: \" + str((round((t2-t1)*1000))) + \"ms\"))\n",
        "      \n",
        "  elif message.server == None and not message.author.bot:\n",
        "    file = open(\"drive/JadeV3/logs/log.txt\",\"a\")\n",
        "    print('\\n' + str(message.server) + \" ::: \" + datetime.date.today().strftime(\"%A\") + \", \" + datetime.date.today().strftime(\"%B\") + \" \"+\n",
        "          datetime.date.today().strftime(\"%d\") + '\\n' + str(message.author) + \": \" + message.content)\n",
        "    file.write('\\n' + str(message.server) + \" ::: \" + datetime.date.today().strftime(\"%A\") + \", \" + datetime.date.today().strftime(\"%B\") + \" \"+\n",
        "               datetime.date.today().strftime(\"%d\") + '\\n' + str(message.author) + \": \" + message.content)\n",
        "    out_txt = \"\"\n",
        "    user_input = message.content\n",
        "    user_command_entered, reset, states, relevance, temperature, topn, beam_width = process_user_command(\n",
        "        user_input, states, args.relevance, args.temperature, args.topn, args.beam_width)\n",
        "    if reset: states = initial_state_with_relevance_masking(net, sess, args.relevance)\n",
        "    if not user_command_entered:\n",
        "        states = forward_text(net, sess, states, args.relevance, vocab, sanitize_text(vocab, \"> \" + user_input + \"\\n>\"))\n",
        "        computer_response_generator = beam_search_generator(sess=sess, net=net,\n",
        "            initial_state=copy.deepcopy(states), initial_sample=vocab[' '],\n",
        "            early_term_token=vocab['\\n'], beam_width=args.beam_width, forward_model_fn=forward_with_mask,\n",
        "            forward_args={'relevance':args.relevance, 'mask_reset_token':vocab['\\n'], 'forbidden_token':vocab['>'],\n",
        "                            'temperature':args.temperature, 'topn':args.topn})\n",
        "        out_chars = []\n",
        "        await client.send_typing(message.channel)\n",
        "        for i, char_token in enumerate(computer_response_generator):\n",
        "            out_chars.append(chars[char_token])\n",
        "            out_txt = out_txt + possibly_escaped_char(out_chars)\n",
        "            #print(possibly_escaped_char(out_chars), end='', flush=True)\n",
        "            states = forward_text(net, sess, states, relevance, vocab, chars[char_token])\n",
        "            if i >= args.n: break\n",
        "        print(out_txt)\n",
        "        file.write(\"\\n\" + out_txt)\n",
        "        await client.send_message(message.channel,out_txt)\n",
        "        states = forward_text(net, sess, states, relevance, vocab, sanitize_text(vocab, \"\\n> \"))\n",
        "        file.close() \n",
        "        \n",
        "  elif not message.server == None and str(message.channel.id) == \"471788266052386816\" and not message.author.bot:\n",
        "    file = open(\"drive/JadeV3/logs/log.txt\",\"a\")\n",
        "    print('\\n' + str(message.server) + \" ::: \" + datetime.date.today().strftime(\"%A\") + \", \" + datetime.date.today().strftime(\"%B\") + \" \"+\n",
        "          datetime.date.today().strftime(\"%d\") + '\\n' + str(message.author) + \": \" + message.content)\n",
        "    file.write('\\n' + str(message.server) + \" ::: \" + datetime.date.today().strftime(\"%A\") + \", \" + datetime.date.today().strftime(\"%B\") + \" \"+\n",
        "               datetime.date.today().strftime(\"%d\") + '\\n' + str(message.author) + \": \" + message.content)\n",
        "    out_txt = \"\"\n",
        "    user_input = message.content\n",
        "    user_command_entered, reset, states, relevance, temperature, topn, beam_width = process_user_command(\n",
        "        user_input, states, args.relevance, args.temperature, args.topn, args.beam_width)\n",
        "    if reset: states = initial_state_with_relevance_masking(net, sess, args.relevance)\n",
        "    if not user_command_entered:\n",
        "        states = forward_text(net, sess, states, args.relevance, vocab, sanitize_text(vocab, \"> \" + user_input + \"\\n>\"))\n",
        "        computer_response_generator = beam_search_generator(sess=sess, net=net,\n",
        "            initial_state=copy.deepcopy(states), initial_sample=vocab[' '],\n",
        "            early_term_token=vocab['\\n'], beam_width=args.beam_width, forward_model_fn=forward_with_mask,\n",
        "            forward_args={'relevance':args.relevance, 'mask_reset_token':vocab['\\n'], 'forbidden_token':vocab['>'],\n",
        "                            'temperature':args.temperature, 'topn':args.topn})\n",
        "        out_chars = []\n",
        "        await client.send_typing(message.channel)\n",
        "        for i, char_token in enumerate(computer_response_generator):\n",
        "            out_chars.append(chars[char_token])\n",
        "            out_txt = out_txt + possibly_escaped_char(out_chars)\n",
        "            #print(possibly_escaped_char(out_chars), end='', flush=True)\n",
        "            states = forward_text(net, sess, states, relevance, vocab, chars[char_token])\n",
        "            if i >= args.n: break\n",
        "        print(out_txt)\n",
        "        file.write(\"\\n\" + out_txt)\n",
        "        await client.send_message(message.channel,out_txt)\n",
        "        states = forward_text(net, sess, states, relevance, vocab, sanitize_text(vocab, \"\\n> \"))\n",
        "        file.close() \n",
        "  try:\n",
        "    await client.change_presence(game=discord.Game(name=\"with my \" + str(len(set(client.get_all_members()))) + \" friends! ||| I've been invited to \"+str(len(client.servers)) + \" homes, and JD is my prefix!\"))\n",
        "  except:\n",
        "    return\n",
        "  \n",
        "@client.event\n",
        "async def on_server_join(server):\n",
        "  file = open(\"drive/JadeV3/Server_Stocks.txt\", \"a\") \n",
        "  file.write(\"\\n\" + server.id + \" ::: \" + str(server.member_count))\n",
        "  file.close()\n",
        "  print(\"\\n\" + server.name + \" was added to the stock market\")\n",
        "  file = open(\"drive/JadeV3/User_Money.txt\", \"r\") \n",
        "  lines = file.readlines()\n",
        "  file.close()\n",
        "  for member in server.members:\n",
        "    if not member.id in lines:\n",
        "      file = open(\"drive/JadeV3/User_Money.txt\", \"a\") \n",
        "      file.write(\"\\n\" + member.id + \" ::: \" + str(100))\n",
        "      file.close()\n",
        "      print(\"\\n\" + str(member) + \" has created an account\")\n",
        "\n",
        "@client.event\n",
        "async def on_server_remove(server):\n",
        "  file = open(\"drive/JadeV3/Server_Stocks.txt\", \"r\")\n",
        "  lines = file.readlines()\n",
        "  file.close()\n",
        "  file = open(\"drive/JadeV3/Server_Stocks.txt\", \"w\")\n",
        "  for line in lines:\n",
        "    if server.id not in line:\n",
        "      file.write(line)\n",
        "  file.close()\n",
        "  print(\"\\n\" + server.name + \" was removed from the stock market\")\n",
        "  \n",
        "@client.event\n",
        "async def on_member_join(member):\n",
        "  file = open(\"drive/JadeV3/User_Money.txt\", \"r\") \n",
        "  lines = file.readlines()\n",
        "  file.close()\n",
        "  if not member.id in lines:\n",
        "    file = open(\"drive/JadeV3/User_Money.txt\", \"a\") \n",
        "    file.write(\"\\n\" + member.id + \" ::: \" + str(100))\n",
        "    file.close()\n",
        "    print(\"\\n\" + str(member) + \" has created an account\")\n",
        "    \n",
        "@client.event\n",
        "async def on_member_remove(member):\n",
        "  file = open(\"drive/JadeV3/User_Money.txt\", \"r\")\n",
        "  lines = file.readlines()\n",
        "  file.close()\n",
        "  file = open(\"drive/JadeV3/User_Money.txt\", \"w\")\n",
        "  for line in lines:\n",
        "    if member.id not in line:\n",
        "      file.write(line)\n",
        "  file.close()\n",
        "  print(\"\\n\" + str(member) + \"'s account was deleted\")\n",
        "      \n",
        "client.run('Token')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating model...\n",
            "Restoring weights...\n",
            "INFO:tensorflow:Restoring parameters from drive/JadeV3/models/reddit/model.ckpt-4735000\n",
            "Server Update Requested\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Failed to post server count\n",
            "Forbidden: Forbidden (status code: 403): {\"error\":\"Forbidden\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-17-63a8fd6c8501>\", line 44, in update_stats\n",
            "    await self.dblpy.post_server_count()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dbl/client.py\", line 100, in post_server_count\n",
            "    await self.http.post_server_count(self.bot_id, self.guild_count(), shard_count, shard_no)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dbl/http.py\", line 189, in post_server_count\n",
            "    await self.request('POST', '{}/bots/{}/stats'.format(self.BASE, bot_id), json=payload)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dbl/http.py\", line 160, in request\n",
            "    raise Forbidden(resp, data)\n",
            "dbl.errors.Forbidden: Forbidden (status code: 403): {\"error\":\"Forbidden\"}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logged in as Jade (ID:410253782828449802) | Connected to 269 servers | Connected to 1742 users\n",
            "--------\n",
            "You are running JadeAI\n",
            "\n",
            "Insomniac#6333 has created an account\n",
            "\n",
            "ＵＹ８１３　ＩＳ　ＴＨＥ　ＢＥＳＴ#9495 has created an account\n",
            "\n",
            "LFS | !yardım#2485 has created an account\n",
            "\n",
            "ShadowShit#4969 has created an account\n",
            "\n",
            "Spiniyo#0627 has created an account\n",
            "\n",
            "ＵＹ８１３　ＩＳ　ＴＨＥ　ＢＥＳＴ#9495's account was deleted\n",
            "\n",
            "kazuya2007#6152 has created an account\n",
            "\n",
            "Snoww#8774 has created an account\n",
            "\n",
            "Lewey#7643 has created an account\n",
            "\n",
            "GALAXY UY813 THE BEST#9495 has created an account\n",
            "\n",
            "The Jade (Cult) ::: Friday, September 07\n",
            "Anarchy BugFire#8909: hey\n",
            " I'm not sure if you're trying too hard. I don't think you know what that word means anymore. \n",
            "\n",
            "Zayed#9266 has created an account\n",
            "\n",
            "Mantas#4882 has created an account\n",
            "\n",
            "Snoww#8774's account was deleted\n",
            "\n",
            "ShadowShit#4969's account was deleted\n",
            "\n",
            "GALAXY UY813 THE BEST#9495's account was deleted\n",
            "\n",
            "Mantas#4882's account was deleted\n",
            "\n",
            "GALAXY UY813 THE BEST#9495 has created an account\n",
            "\n",
            "Galaxy#0002 has created an account\n",
            "\n",
            "a+#0443 has created an account\n",
            "\n",
            "Pokécord#4503 has created an account\n",
            "\n",
            "MatthewThank#9687's account was deleted\n",
            "\n",
            "LameczekYoutube#5349 has created an account\n",
            "\n",
            "An OP Asian#7091 has created an account\n",
            "\n",
            "Mellow#9638 has created an account\n",
            "\n",
            "Mellow#9638's account was deleted\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Failed to post server count\n",
            "HTTPException: Internal Server Error (status code: 500): {\"error\":\"Oops, I think a bad happened, I'm trying again just hang in there\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-17-63a8fd6c8501>\", line 44, in update_stats\n",
            "    await self.dblpy.post_server_count()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dbl/client.py\", line 100, in post_server_count\n",
            "    await self.http.post_server_count(self.bot_id, self.guild_count(), shard_count, shard_no)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dbl/http.py\", line 189, in post_server_count\n",
            "    await self.request('POST', '{}/bots/{}/stats'.format(self.BASE, bot_id), json=payload)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dbl/http.py\", line 164, in request\n",
            "    raise HTTPException(resp, data)\n",
            "dbl.errors.HTTPException: Internal Server Error (status code: 500): {\"error\":\"Oops, I think a bad happened, I'm trying again just hang in there\"}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Pyria#6912 has created an account\n",
            "\n",
            "Thefurykiller#1017's account was deleted\n",
            "\n",
            "Jiří Ovčáček#4075's account was deleted\n",
            "\n",
            "PLHubi#2556 has created an account\n",
            "\n",
            "Koorime#5689 has created an account\n",
            "\n",
            "PLHubi#2556's account was deleted\n",
            "\n",
            "wizthelazy#6551 has created an account\n",
            "\n",
            "k3l#4756 has created an account\n",
            "\n",
            "k3l#4756's account was deleted\n",
            "\n",
            "uQueijoS_#2912 has created an account\n",
            "\n",
            "DJ CTRL+6#4558 has created an account\n",
            "\n",
            "Haidd#2015 has created an account\n",
            "\n",
            "uQueijoS_#2912's account was deleted\n",
            "\n",
            "Shiina#4440's account was deleted\n",
            "\n",
            "₣reddyM#8518 has created an account\n",
            "\n",
            "LameczekYoutube#5349's account was deleted\n",
            "\n",
            "╲⎝⧹ ╔╣╠╗╚iMrGaithGhozzi╝╔╣╠╗⧸⎠╱#1483 has created an account\n",
            "\n",
            "Mr. J#9237 has created an account\n",
            "Server Update Requested\n",
            "\n",
            "MassiveStroke#2812 has created an account\n",
            "\n",
            "MassiveStroke#2812's account was deleted\n",
            "\n",
            "rob55rod#0095 has created an account\n",
            "\n",
            "Pyria#6912's account was deleted\n",
            "\n",
            "Furkan BloodFlow#9658 has created an account\n",
            "\n",
            "Pokécord#4503's account was deleted\n",
            "\n",
            "Nayts#1817 has created an account\n",
            "\n",
            "Caroline Nunez#1213 has created an account\n",
            "\n",
            "MurderMostFowl#2732 has created an account\n",
            "\n",
            "Falcon351#1197 has created an account\n",
            "\n",
            "Falcon351#1197's account was deleted\n",
            "\n",
            "SEBDOM#9639 has created an account\n",
            "\n",
            "PedroRezende123#2704 has created an account\n",
            "\n",
            "!øški¶ru!TeamSqua!#5586 has created an account\n",
            "\n",
            "SEBDOM#9639's account was deleted\n",
            "\n",
            "P'ays#5295's account was deleted\n",
            "\n",
            "Neiju#2966 has created an account\n",
            "\n",
            "PedroRezende123#2704's account was deleted\n",
            "\n",
            "Haidd#2015's account was deleted\n",
            "\n",
            "Neiju#2966's account was deleted\n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: is nico gay\n",
            " Good point, I was just trying to comment on your generalizations.\n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: is nico gay osama?\n",
            " Nope.\n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: is nico gaysama\n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: is osama nico gay\n",
            " Nope. Not a gay guy. \n",
            " If you think that's a good or bad thing, I'm not gay. \n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: is nico gay osama osama\n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: osama is osama nico osama gay osama\n",
            " Not a gay guy\n",
            " You're right, it is a nice statement that gay people don't even know the secrets of it. \n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: you're wrong\n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: nico is gay, say it\n",
            "\n",
            "LOS CHOLOS DE AREQUIPA jujejejej, 444623662595964929 ::: Friday, September 07\n",
            "grieve#8320: say nico is gay\n",
            " I don't think you understand what that word means. \n",
            " Okay what is this, a gay couple?\n",
            " no it's not\n",
            "\n",
            "Trep#5894 has created an account\n",
            "\n",
            "autumn#1071's account was deleted\n",
            "\n",
            "Flaysᴴᵒʳʳᵒʳ#8001 has created an account\n",
            "\n",
            "Flaysᴴᵒʳʳᵒʳ#8001's account was deleted\n",
            "\n",
            "BenceX#5792 has created an account\n",
            "\n",
            "BenceX#5792's account was deleted\n",
            "\n",
            "Hisoka#9576 has created an account\n",
            "\n",
            "BenceX#5792 has created an account\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}