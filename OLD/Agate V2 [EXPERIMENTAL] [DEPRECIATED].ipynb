{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AgateV2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "UqYce_ouHZpK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOdcE7SMHb9c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ewNXuUdzHeoY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-jhhYf2iHglu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print('Files in Drive:')\n",
        "!ls drive/\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q15imSDGHkoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "!pip install discord.py\n",
        "import discord\n",
        "import asyncio\n",
        "from discord.ext.commands import Bot\n",
        "from discord.ext import commands\n",
        "!pip install dblpy\n",
        "import dbl\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import logging\n",
        "\n",
        "import resource\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBH-lL3gDy4B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DiscordBotsOrgAPI:\n",
        "    \"\"\"Handles interactions with the discordbots.org API\"\"\"\n",
        "\n",
        "    def __init__(self, bot):\n",
        "        self.bot = bot\n",
        "        self.token = 'Token'  #  set this to your DBL token\n",
        "        self.dblpy = dbl.Client(self.bot, self.token)\n",
        "        self.bot.loop.create_task(self.update_stats())\n",
        "\n",
        "    async def update_stats(self):\n",
        "        \"\"\"This function runs every 30 minutes to automatically update your server count\"\"\"\n",
        "\n",
        "        while True:\n",
        "            logger.info('attempting to post server count')\n",
        "            try:\n",
        "                await self.dblpy.post_server_count()\n",
        "                logger.info('posted server count ({})'.format(len(self.bot.servers)))\n",
        "            except Exception as e:\n",
        "                logger.exception('Failed to post server count\\n{}: {}'.format(type(e).__name__, e))\n",
        "            await asyncio.sleep(1800)\n",
        "            \n",
        "def setup(bot):\n",
        "    global logger\n",
        "    logger = logging.getLogger('bot')\n",
        "    bot.add_cog(DiscordBotsOrgAPI(bot))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WLdaYMFw8QNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Board(object):\n",
        "    \"\"\"board for the game\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.width = int(kwargs.get('width', 8))\n",
        "        self.height = int(kwargs.get('height', 8))\n",
        "        # board states stored as a dict,\n",
        "        # key: move as location on the board,\n",
        "        # value: player as pieces type\n",
        "        self.states = {}\n",
        "        # need how many pieces in a row to win\n",
        "        self.n_in_row = int(kwargs.get('n_in_row', 5))\n",
        "        self.players = [1, 2]  # player1 and player2\n",
        "\n",
        "    def init_board(self, start_player=0):\n",
        "        if self.width < self.n_in_row or self.height < self.n_in_row:\n",
        "            raise Exception('board width and height can not be '\n",
        "                            'less than {}'.format(self.n_in_row))\n",
        "        self.current_player = self.players[start_player]  # start player\n",
        "        # keep available moves in a list\n",
        "        self.availables = list(range(self.width * self.height))\n",
        "        self.states = {}\n",
        "        self.last_move = -1\n",
        "\n",
        "    def move_to_location(self, move):\n",
        "        \"\"\"\n",
        "        3*3 board's moves like:\n",
        "        6 7 8\n",
        "        3 4 5\n",
        "        0 1 2\n",
        "        and move 5's location is (1,2)\n",
        "        \"\"\"\n",
        "        h = move // self.width\n",
        "        w = move % self.width\n",
        "        return [h, w]\n",
        "\n",
        "    def location_to_move(self, location):\n",
        "        if len(location) != 2:\n",
        "            return -1\n",
        "        h = location[0]\n",
        "        w = location[1]\n",
        "        move = h * self.width + w\n",
        "        if move not in range(self.width * self.height):\n",
        "            return -1\n",
        "        return move\n",
        "\n",
        "    def current_state(self):\n",
        "        \"\"\"return the board state from the perspective of the current player.\n",
        "        state shape: 4*width*height\n",
        "        \"\"\"\n",
        "\n",
        "        square_state = np.zeros((4, self.width, self.height))\n",
        "        if self.states:\n",
        "            moves, players = np.array(list(zip(*self.states.items())))\n",
        "            move_curr = moves[players == self.current_player]\n",
        "            move_oppo = moves[players != self.current_player]\n",
        "            square_state[0][move_curr // self.width,\n",
        "                            move_curr % self.height] = 1.0\n",
        "            square_state[1][move_oppo // self.width,\n",
        "                            move_oppo % self.height] = 1.0\n",
        "            # indicate the last move location\n",
        "            square_state[2][self.last_move // self.width,\n",
        "                            self.last_move % self.height] = 1.0\n",
        "        if len(self.states) % 2 == 0:\n",
        "            square_state[3][:, :] = 1.0  # indicate the colour to play\n",
        "        return square_state[:, ::-1, :]\n",
        "\n",
        "    def do_move(self, move):\n",
        "        self.states[move] = self.current_player\n",
        "        self.availables.remove(move)\n",
        "        self.current_player = (\n",
        "            self.players[0] if self.current_player == self.players[1]\n",
        "            else self.players[1]\n",
        "        )\n",
        "        self.last_move = move\n",
        "\n",
        "    def has_a_winner(self):\n",
        "        width = self.width\n",
        "        height = self.height\n",
        "        states = self.states\n",
        "        n = self.n_in_row\n",
        "\n",
        "        moved = list(set(range(width * height)) - set(self.availables))\n",
        "        if len(moved) < self.n_in_row + 2:\n",
        "            return False, -1\n",
        "\n",
        "        for m in moved:\n",
        "            h = m // width\n",
        "            w = m % width\n",
        "            player = states[m]\n",
        "\n",
        "            if (w in range(width - n + 1) and\n",
        "                    len(set(states.get(i, -1) for i in range(m, m + n))) == 1):\n",
        "                return True, player\n",
        "\n",
        "            if (h in range(height - n + 1) and\n",
        "                    len(set(states.get(i, -1) for i in range(m, m + n * width, width))) == 1):\n",
        "                return True, player\n",
        "\n",
        "            if (w in range(width - n + 1) and h in range(height - n + 1) and\n",
        "                    len(set(states.get(i, -1) for i in range(m, m + n * (width + 1), width + 1))) == 1):\n",
        "                return True, player\n",
        "\n",
        "            if (w in range(n - 1, width) and h in range(height - n + 1) and\n",
        "                    len(set(states.get(i, -1) for i in range(m, m + n * (width - 1), width - 1))) == 1):\n",
        "                return True, player\n",
        "\n",
        "        return False, -1\n",
        "\n",
        "    def game_end(self):\n",
        "        \"\"\"Check whether the game is ended or not\"\"\"\n",
        "        win, winner = self.has_a_winner()\n",
        "        if win:\n",
        "            return True, winner\n",
        "        elif not len(self.availables):\n",
        "            return True, -1\n",
        "        return False, -1\n",
        "\n",
        "    def get_current_player(self):\n",
        "        return self.current_player\n",
        "\n",
        "\n",
        "class Game(object):\n",
        "    \"\"\"game server\"\"\"\n",
        "\n",
        "    def __init__(self, board, **kwargs):\n",
        "        self.board = board\n",
        "\n",
        "    async def graphic(self, board, player1, player2, Message_LOC2):\n",
        "        \"\"\"Draw the board and show game info\"\"\"\n",
        "        width = board.width\n",
        "        height = board.height\n",
        "\n",
        "        #await client.send_message(Message_LOC2, \"Player\" + player1 + \"with X\")\n",
        "        #await client.send_message(Message_LOC2, \"Player\" + player2 + \"with O\")\n",
        "        print()\n",
        "        for x in range(width):\n",
        "            await client.send_message(Message_LOC2, \"{0:8}\".format(x))\n",
        "        print('\\r\\n')\n",
        "        for i in range(height - 1, -1, -1):\n",
        "            await client.send_message(Message_LOC2, \"{0:4d}\".format(i))\n",
        "            for j in range(width):\n",
        "                loc = i * width + j\n",
        "                p = board.states.get(loc, -1)\n",
        "                if p == player1:\n",
        "                    await client.send_message(Message_LOC2, 'X'.center(8))\n",
        "                elif p == player2:\n",
        "                    await client.send_message(Message_LOC2, 'O'.center(8))\n",
        "                else:\n",
        "                    await client.send_message(Message_LOC2, '_'.center(8))\n",
        "            await client.send_message(Message_LOC2, '\\r\\n\\r\\n')\n",
        "\n",
        "    async def start_play(self, player1, player2, Message_LOC1, start_player=0, is_shown=1):\n",
        "        \"\"\"start a game between two players\"\"\"\n",
        "        if start_player not in (0, 1):\n",
        "            raise Exception('start_player should be either 0 (player1 first) '\n",
        "                            'or 1 (player2 first)')\n",
        "        self.board.init_board(start_player)\n",
        "        p1, p2 = self.board.players\n",
        "        player1.set_player_ind(p1)\n",
        "        player2.set_player_ind(p2)\n",
        "        players = {p1: player1, p2: player2}\n",
        "        if is_shown:\n",
        "            await self.graphic(self.board, player1.player, player2.player, Message_LOC1)\n",
        "        while True:\n",
        "            current_player = self.board.get_current_player()\n",
        "            player_in_turn = players[current_player]\n",
        "            move = player_in_turn.get_action(self.board)\n",
        "            self.board.do_move(move)\n",
        "            if is_shown:\n",
        "                await self.graphic(self.board, player1.player, player2.player, Message_LOC1)\n",
        "            end, winner = self.board.game_end()\n",
        "            if end:\n",
        "                if is_shown:\n",
        "                    if winner != -1:\n",
        "                        await client.send_message(Message_LOC1, \"Game end. Winner is\", players[winner])\n",
        "                    else:\n",
        "                        await client.send_message(Message_LOC1, \"Game end. Tie\")\n",
        "                return winner\n",
        "\n",
        "    def start_self_play(self, player, is_shown=0, temp=1e-3):\n",
        "        \"\"\" start a self-play game using a MCTS player, reuse the search tree,\n",
        "        and store the self-play data: (state, mcts_probs, z) for training\n",
        "        \"\"\"\n",
        "        self.board.init_board()\n",
        "        p1, p2 = self.board.players\n",
        "        states, mcts_probs, current_players = [], [], []\n",
        "        while True:\n",
        "            move, move_probs = player.get_action(self.board,\n",
        "                                                 temp=temp,\n",
        "                                                 return_prob=1)\n",
        "            # store the data\n",
        "            states.append(self.board.current_state())\n",
        "            mcts_probs.append(move_probs)\n",
        "            current_players.append(self.board.current_player)\n",
        "            # perform a move\n",
        "            self.board.do_move(move)\n",
        "            if is_shown:\n",
        "                self.graphic(self.board, p1, p2)\n",
        "            end, winner = self.board.game_end()\n",
        "            if end:\n",
        "                # winner from the perspective of the current player of each state\n",
        "                winners_z = np.zeros(len(current_players))\n",
        "                if winner != -1:\n",
        "                    winners_z[np.array(current_players) == winner] = 1.0\n",
        "                    winners_z[np.array(current_players) != winner] = -1.0\n",
        "                # reset MCTS root node\n",
        "                player.reset_player()\n",
        "                if is_shown:\n",
        "                    if winner != -1:\n",
        "                        print(\"Game end. Winner is player:\", winner)\n",
        "                    else:\n",
        "                        print(\"Game end. Tie\")\n",
        "                return winner, zip(states, mcts_probs, winners_z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNBPx5xy8iMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    probs = np.exp(x - np.max(x))\n",
        "    probs /= np.sum(probs)\n",
        "    return probs\n",
        "\n",
        "\n",
        "class TreeNode(object):\n",
        "    \"\"\"A node in the MCTS tree.\n",
        "\n",
        "    Each node keeps track of its own value Q, prior probability P, and\n",
        "    its visit-count-adjusted prior score u.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, prior_p):\n",
        "        self._parent = parent\n",
        "        self._children = {}  # a map from action to TreeNode\n",
        "        self._n_visits = 0\n",
        "        self._Q = 0\n",
        "        self._u = 0\n",
        "        self._P = prior_p\n",
        "\n",
        "    def expand(self, action_priors):\n",
        "        \"\"\"Expand tree by creating new children.\n",
        "        action_priors: a list of tuples of actions and their prior probability\n",
        "            according to the policy function.\n",
        "        \"\"\"\n",
        "        for action, prob in action_priors:\n",
        "            if action not in self._children:\n",
        "                self._children[action] = TreeNode(self, prob)\n",
        "\n",
        "    def select(self, c_puct):\n",
        "        \"\"\"Select action among children that gives maximum action value Q\n",
        "        plus bonus u(P).\n",
        "        Return: A tuple of (action, next_node)\n",
        "        \"\"\"\n",
        "        return max(self._children.items(),\n",
        "                   key=lambda act_node: act_node[1].get_value(c_puct))\n",
        "\n",
        "    def update(self, leaf_value):\n",
        "        \"\"\"Update node values from leaf evaluation.\n",
        "        leaf_value: the value of subtree evaluation from the current player's\n",
        "            perspective.\n",
        "        \"\"\"\n",
        "        # Count visit.\n",
        "        self._n_visits += 1\n",
        "        # Update Q, a running average of values for all visits.\n",
        "        self._Q += 1.0*(leaf_value - self._Q) / self._n_visits\n",
        "\n",
        "    def update_recursive(self, leaf_value):\n",
        "        \"\"\"Like a call to update(), but applied recursively for all ancestors.\n",
        "        \"\"\"\n",
        "        # If it is not root, this node's parent should be updated first.\n",
        "        if self._parent:\n",
        "            self._parent.update_recursive(-leaf_value)\n",
        "        self.update(leaf_value)\n",
        "\n",
        "    def get_value(self, c_puct):\n",
        "        \"\"\"Calculate and return the value for this node.\n",
        "        It is a combination of leaf evaluations Q, and this node's prior\n",
        "        adjusted for its visit count, u.\n",
        "        c_puct: a number in (0, inf) controlling the relative impact of\n",
        "            value Q, and prior probability P, on this node's score.\n",
        "        \"\"\"\n",
        "        self._u = (c_puct * self._P *\n",
        "                   np.sqrt(self._parent._n_visits) / (1 + self._n_visits))\n",
        "        return self._Q + self._u\n",
        "\n",
        "    def is_leaf(self):\n",
        "        \"\"\"Check if leaf node (i.e. no nodes below this have been expanded).\"\"\"\n",
        "        return self._children == {}\n",
        "\n",
        "    def is_root(self):\n",
        "        return self._parent is None\n",
        "\n",
        "\n",
        "class MCTS(object):\n",
        "    \"\"\"An implementation of Monte Carlo Tree Search.\"\"\"\n",
        "\n",
        "    def __init__(self, policy_value_fn, c_puct=5, n_playout=10000):\n",
        "        \"\"\"\n",
        "        policy_value_fn: a function that takes in a board state and outputs\n",
        "            a list of (action, probability) tuples and also a score in [-1, 1]\n",
        "            (i.e. the expected value of the end game score from the current\n",
        "            player's perspective) for the current player.\n",
        "        c_puct: a number in (0, inf) that controls how quickly exploration\n",
        "            converges to the maximum-value policy. A higher value means\n",
        "            relying on the prior more.\n",
        "        \"\"\"\n",
        "        self._root = TreeNode(None, 1.0)\n",
        "        self._policy = policy_value_fn\n",
        "        self._c_puct = c_puct\n",
        "        self._n_playout = n_playout\n",
        "\n",
        "    def _playout(self, state):\n",
        "        \"\"\"Run a single playout from the root to the leaf, getting a value at\n",
        "        the leaf and propagating it back through its parents.\n",
        "        State is modified in-place, so a copy must be provided.\n",
        "        \"\"\"\n",
        "        node = self._root\n",
        "        while(1):\n",
        "            if node.is_leaf():\n",
        "                break\n",
        "            # Greedily select next move.\n",
        "            action, node = node.select(self._c_puct)\n",
        "            state.do_move(action)\n",
        "\n",
        "        # Evaluate the leaf using a network which outputs a list of\n",
        "        # (action, probability) tuples p and also a score v in [-1, 1]\n",
        "        # for the current player.\n",
        "        action_probs, leaf_value = self._policy(state)\n",
        "        # Check for end of game.\n",
        "        end, winner = state.game_end()\n",
        "        if not end:\n",
        "            node.expand(action_probs)\n",
        "        else:\n",
        "            # for end state，return the \"true\" leaf_value\n",
        "            if winner == -1:  # tie\n",
        "                leaf_value = 0.0\n",
        "            else:\n",
        "                leaf_value = (\n",
        "                    1.0 if winner == state.get_current_player() else -1.0\n",
        "                )\n",
        "\n",
        "        # Update value and visit count of nodes in this traversal.\n",
        "        node.update_recursive(-leaf_value)\n",
        "\n",
        "    def get_move_probs(self, state, temp=1e-3):\n",
        "        \"\"\"Run all playouts sequentially and return the available actions and\n",
        "        their corresponding probabilities.\n",
        "        state: the current game state\n",
        "        temp: temperature parameter in (0, 1] controls the level of exploration\n",
        "        \"\"\"\n",
        "        for n in range(self._n_playout):\n",
        "            state_copy = copy.deepcopy(state)\n",
        "            self._playout(state_copy)\n",
        "\n",
        "        # calc the move probabilities based on visit counts at the root node\n",
        "        act_visits = [(act, node._n_visits)\n",
        "                      for act, node in self._root._children.items()]\n",
        "        acts, visits = zip(*act_visits)\n",
        "        act_probs = softmax(1.0/temp * np.log(np.array(visits) + 1e-10))\n",
        "\n",
        "        return acts, act_probs\n",
        "\n",
        "    def update_with_move(self, last_move):\n",
        "        \"\"\"Step forward in the tree, keeping everything we already know\n",
        "        about the subtree.\n",
        "        \"\"\"\n",
        "        if last_move in self._root._children:\n",
        "            self._root = self._root._children[last_move]\n",
        "            self._root._parent = None\n",
        "        else:\n",
        "            self._root = TreeNode(None, 1.0)\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"MCTS\"\n",
        "\n",
        "\n",
        "class MCTSPlayer(object):\n",
        "    \"\"\"AI player based on MCTS\"\"\"\n",
        "\n",
        "    def __init__(self, policy_value_function,\n",
        "                 c_puct=5, n_playout=2000, is_selfplay=0):\n",
        "        self.mcts = MCTS(policy_value_function, c_puct, n_playout)\n",
        "        self._is_selfplay = is_selfplay\n",
        "\n",
        "    def set_player_ind(self, p):\n",
        "        self.player = p\n",
        "\n",
        "    def reset_player(self):\n",
        "        self.mcts.update_with_move(-1)\n",
        "\n",
        "    def get_action(self, board, temp=1e-3, return_prob=0):\n",
        "        sensible_moves = board.availables\n",
        "        # the pi vector returned by MCTS as in the alphaGo Zero paper\n",
        "        move_probs = np.zeros(board.width*board.height)\n",
        "        if len(sensible_moves) > 0:\n",
        "            acts, probs = self.mcts.get_move_probs(board, temp)\n",
        "            move_probs[list(acts)] = probs\n",
        "            if self._is_selfplay:\n",
        "                # add Dirichlet Noise for exploration (needed for\n",
        "                # self-play training)\n",
        "                move = np.random.choice(\n",
        "                    acts,\n",
        "                    p=0.75*probs + 0.25*np.random.dirichlet(0.3*np.ones(len(probs)))\n",
        "                )\n",
        "                # update the root node and reuse the search tree\n",
        "                self.mcts.update_with_move(move)\n",
        "            else:\n",
        "                # with the default temp=1e-3, it is almost equivalent\n",
        "                # to choosing the move with the highest prob\n",
        "                move = np.random.choice(acts, p=probs)\n",
        "                # reset the root node\n",
        "                self.mcts.update_with_move(-1)\n",
        "#                location = board.move_to_location(move)\n",
        "#                print(\"AI move: %d,%d\\n\" % (location[0], location[1]))\n",
        "\n",
        "            if return_prob:\n",
        "                return move, move_probs\n",
        "            else:\n",
        "                return move\n",
        "        else:\n",
        "            print(\"WARNING: the board is full\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"MCTS {}\".format(self.player)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uREvTgOe9Aln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# some utility functions\n",
        "def softmax(x):\n",
        "    probs = np.exp(x - np.max(x))\n",
        "    probs /= np.sum(probs)\n",
        "    return probs\n",
        "\n",
        "\n",
        "def relu(X):\n",
        "    out = np.maximum(X, 0)\n",
        "    return out\n",
        "\n",
        "\n",
        "def conv_forward(X, W, b, stride=1, padding=1):\n",
        "    n_filters, d_filter, h_filter, w_filter = W.shape\n",
        "    # theano conv2d flips the filters (rotate 180 degree) first\n",
        "    # while doing the calculation\n",
        "    W = W[:, :, ::-1, ::-1]\n",
        "    n_x, d_x, h_x, w_x = X.shape\n",
        "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
        "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
        "    h_out, w_out = int(h_out), int(w_out)\n",
        "    X_col = im2col_indices(X, h_filter, w_filter,\n",
        "                           padding=padding, stride=stride)\n",
        "    W_col = W.reshape(n_filters, -1)\n",
        "    out = (np.dot(W_col, X_col).T + b).T\n",
        "    out = out.reshape(n_filters, h_out, w_out, n_x)\n",
        "    out = out.transpose(3, 0, 1, 2)\n",
        "    return out\n",
        "\n",
        "\n",
        "def fc_forward(X, W, b):\n",
        "    out = np.dot(X, W) + b\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_im2col_indices(x_shape, field_height,\n",
        "                       field_width, padding=1, stride=1):\n",
        "    # First figure out what the size of the output should be\n",
        "    N, C, H, W = x_shape\n",
        "    assert (H + 2 * padding - field_height) % stride == 0\n",
        "    assert (W + 2 * padding - field_height) % stride == 0\n",
        "    out_height = int((H + 2 * padding - field_height) / stride + 1)\n",
        "    out_width = int((W + 2 * padding - field_width) / stride + 1)\n",
        "\n",
        "    i0 = np.repeat(np.arange(field_height), field_width)\n",
        "    i0 = np.tile(i0, C)\n",
        "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
        "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
        "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
        "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
        "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
        "\n",
        "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
        "\n",
        "    return (k.astype(int), i.astype(int), j.astype(int))\n",
        "\n",
        "\n",
        "def im2col_indices(x, field_height, field_width, padding=1, stride=1):\n",
        "    \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
        "    # Zero-pad the input\n",
        "    p = padding\n",
        "    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
        "\n",
        "    k, i, j = get_im2col_indices(x.shape, field_height,\n",
        "                                 field_width, padding, stride)\n",
        "\n",
        "    cols = x_padded[:, k, i, j]\n",
        "    C = x.shape[1]\n",
        "    cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)\n",
        "    return cols\n",
        "\n",
        "\n",
        "class PolicyValueNetNumpy():\n",
        "    \"\"\"policy-value network in numpy \"\"\"\n",
        "    def __init__(self, board_width, board_height, net_params):\n",
        "        self.board_width = board_width\n",
        "        self.board_height = board_height\n",
        "        self.params = net_params\n",
        "\n",
        "    def policy_value_fn(self, board):\n",
        "        \"\"\"\n",
        "        input: board\n",
        "        output: a list of (action, probability) tuples for each available\n",
        "        action and the score of the board state\n",
        "        \"\"\"\n",
        "        legal_positions = board.availables\n",
        "        current_state = board.current_state()\n",
        "\n",
        "        X = current_state.reshape(-1, 4, self.board_width, self.board_height)\n",
        "        # first 3 conv layers with ReLu nonlinearity\n",
        "        for i in [0, 2, 4]:\n",
        "            X = relu(conv_forward(X, self.params[i], self.params[i+1]))\n",
        "        # policy head\n",
        "        X_p = relu(conv_forward(X, self.params[6], self.params[7], padding=0))\n",
        "        X_p = fc_forward(X_p.flatten(), self.params[8], self.params[9])\n",
        "        act_probs = softmax(X_p)\n",
        "        # value head\n",
        "        X_v = relu(conv_forward(X, self.params[10],\n",
        "                                self.params[11], padding=0))\n",
        "        X_v = relu(fc_forward(X_v.flatten(), self.params[12], self.params[13]))\n",
        "        value = np.tanh(fc_forward(X_v, self.params[14], self.params[15]))[0]\n",
        "        act_probs = zip(legal_positions, act_probs.flatten()[legal_positions])\n",
        "        return act_probs, value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naM3dpLmBNbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class PolicyValueNet():\n",
        "    def __init__(self, board_width, board_height, model_file=None):\n",
        "        self.board_width = board_width\n",
        "        self.board_height = board_height\n",
        "\n",
        "        # Define the tensorflow neural network\n",
        "        # 1. Input:\n",
        "        self.input_states = tf.placeholder(\n",
        "                tf.float32, shape=[None, 4, board_height, board_width])\n",
        "        self.input_state = tf.transpose(self.input_states, [0, 2, 3, 1])\n",
        "        # 2. Common Networks Layers\n",
        "        self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
        "                                      filters=32, kernel_size=[3, 3],\n",
        "                                      padding=\"same\", data_format=\"channels_last\",\n",
        "                                      activation=tf.nn.relu)\n",
        "        self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
        "                                      kernel_size=[3, 3], padding=\"same\",\n",
        "                                      data_format=\"channels_last\",\n",
        "                                      activation=tf.nn.relu)\n",
        "        self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
        "                                      kernel_size=[3, 3], padding=\"same\",\n",
        "                                      data_format=\"channels_last\",\n",
        "                                      activation=tf.nn.relu)\n",
        "        # 3-1 Action Networks\n",
        "        self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
        "                                            kernel_size=[1, 1], padding=\"same\",\n",
        "                                            data_format=\"channels_last\",\n",
        "                                            activation=tf.nn.relu)\n",
        "        # Flatten the tensor\n",
        "        self.action_conv_flat = tf.reshape(\n",
        "                self.action_conv, [-1, 4 * board_height * board_width])\n",
        "        # 3-2 Full connected layer, the output is the log probability of moves\n",
        "        # on each slot on the board\n",
        "        self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
        "                                         units=board_height * board_width,\n",
        "                                         activation=tf.nn.log_softmax)\n",
        "        # 4 Evaluation Networks\n",
        "        self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
        "                                                kernel_size=[1, 1],\n",
        "                                                padding=\"same\",\n",
        "                                                data_format=\"channels_last\",\n",
        "                                                activation=tf.nn.relu)\n",
        "        self.evaluation_conv_flat = tf.reshape(\n",
        "                self.evaluation_conv, [-1, 2 * board_height * board_width])\n",
        "        self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
        "                                              units=64, activation=tf.nn.relu)\n",
        "        # output the score of evaluation on current state\n",
        "        self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
        "                                              units=1, activation=tf.nn.tanh)\n",
        "\n",
        "        # Define the Loss function\n",
        "        # 1. Label: the array containing if the game wins or not for each state\n",
        "        self.labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "        # 2. Predictions: the array containing the evaluation score of each state\n",
        "        # which is self.evaluation_fc2\n",
        "        # 3-1. Value Loss function\n",
        "        self.value_loss = tf.losses.mean_squared_error(self.labels,\n",
        "                                                       self.evaluation_fc2)\n",
        "        # 3-2. Policy Loss function\n",
        "        self.mcts_probs = tf.placeholder(\n",
        "                tf.float32, shape=[None, board_height * board_width])\n",
        "        self.policy_loss = tf.negative(tf.reduce_mean(\n",
        "                tf.reduce_sum(tf.multiply(self.mcts_probs, self.action_fc), 1)))\n",
        "        # 3-3. L2 penalty (regularization)\n",
        "        l2_penalty_beta = 1e-4\n",
        "        vars = tf.trainable_variables()\n",
        "        l2_penalty = l2_penalty_beta * tf.add_n(\n",
        "            [tf.nn.l2_loss(v) for v in vars if 'bias' not in v.name.lower()])\n",
        "        # 3-4 Add up to be the Loss function\n",
        "        self.loss = self.value_loss + self.policy_loss + l2_penalty\n",
        "\n",
        "        # Define the optimizer we use for training\n",
        "        self.learning_rate = tf.placeholder(tf.float32)\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "                learning_rate=self.learning_rate).minimize(self.loss)\n",
        "\n",
        "        # Make a session\n",
        "        self.session = tf.Session()\n",
        "\n",
        "        # calc policy entropy, for monitoring only\n",
        "        self.entropy = tf.negative(tf.reduce_mean(\n",
        "                tf.reduce_sum(tf.exp(self.action_fc) * self.action_fc, 1)))\n",
        "\n",
        "        # Initialize variables\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.session.run(init)\n",
        "\n",
        "        # For saving and restoring\n",
        "        self.saver = tf.train.Saver()\n",
        "        if model_file is not None:\n",
        "            self.restore_model(model_file)\n",
        "\n",
        "    def policy_value(self, state_batch):\n",
        "        \"\"\"\n",
        "        input: a batch of states\n",
        "        output: a batch of action probabilities and state values\n",
        "        \"\"\"\n",
        "        log_act_probs, value = self.session.run(\n",
        "                [self.action_fc, self.evaluation_fc2],\n",
        "                feed_dict={self.input_states: state_batch}\n",
        "                )\n",
        "        act_probs = np.exp(log_act_probs)\n",
        "        return act_probs, value\n",
        "\n",
        "    def policy_value_fn(self, board):\n",
        "        \"\"\"\n",
        "        input: board\n",
        "        output: a list of (action, probability) tuples for each available\n",
        "        action and the score of the board state\n",
        "        \"\"\"\n",
        "        legal_positions = board.availables\n",
        "        current_state = np.ascontiguousarray(board.current_state().reshape(\n",
        "                -1, 4, self.board_width, self.board_height))\n",
        "        act_probs, value = self.policy_value(current_state)\n",
        "        act_probs = zip(legal_positions, act_probs[0][legal_positions])\n",
        "        return act_probs, value\n",
        "\n",
        "    def train_step(self, state_batch, mcts_probs, winner_batch, lr):\n",
        "        \"\"\"perform a training step\"\"\"\n",
        "        winner_batch = np.reshape(winner_batch, (-1, 1))\n",
        "        loss, entropy, _ = self.session.run(\n",
        "                [self.loss, self.entropy, self.optimizer],\n",
        "                feed_dict={self.input_states: state_batch,\n",
        "                           self.mcts_probs: mcts_probs,\n",
        "                           self.labels: winner_batch,\n",
        "                           self.learning_rate: lr})\n",
        "        return loss, entropy\n",
        "\n",
        "    def save_model(self, model_path):\n",
        "        self.saver.save(self.session, model_path)\n",
        "\n",
        "    def restore_model(self, model_path):\n",
        "        self.saver.restore(self.session, model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRywiCdX7zVM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import pickle\n",
        "#from mcts_pure import MCTSPlayer as MCTS_Pure\n",
        "# from policy_value_net import PolicyValueNet  # Theano and Lasagne\n",
        "# from policy_value_net_pytorch import PolicyValueNet  # Pytorch\n",
        "# from policy_value_net_tensorflow import PolicyValueNet # Tensorflow\n",
        "# from policy_value_net_keras import PolicyValueNet  # Keras\n",
        "\n",
        "\n",
        "class Human(object):\n",
        "    \"\"\"\n",
        "    human player\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.player = None\n",
        "\n",
        "    def set_player_ind(self, p):\n",
        "        self.player = p\n",
        "\n",
        "    def get_action(self, board):\n",
        "        try:\n",
        "            location = input(\"Your move: \")\n",
        "            if isinstance(location, str):  # for python3\n",
        "                location = [int(n, 10) for n in location.split(\",\")]\n",
        "            move = board.location_to_move(location)\n",
        "        except Exception as e:\n",
        "            move = -1\n",
        "        if move == -1 or move not in board.availables:\n",
        "            print(\"invalid move\")\n",
        "            move = self.get_action(board)\n",
        "        return move\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Human {}\".format(self.player)\n",
        "\n",
        "\n",
        "async def run(Message_LOC):\n",
        "    n = 5\n",
        "    width, height = 8, 8\n",
        "    model_file = 'drive/AgateV2/best_policy_8_8_5.model'\n",
        "    try:\n",
        "        board = Board(width=width, height=height, n_in_row=n)\n",
        "        game = Game(board)\n",
        "\n",
        "        # ############### human VS AI ###################\n",
        "        # load the trained policy_value_net in either Theano/Lasagne, PyTorch or TensorFlow\n",
        "\n",
        "        # best_policy = PolicyValueNet(width, height, model_file = model_file)\n",
        "        # mcts_player = MCTSPlayer(best_policy.policy_value_fn, c_puct=5, n_playout=400)\n",
        "\n",
        "        # load the provided model (trained in Theano/Lasagne) into a MCTS player written in pure numpy\n",
        "        try:\n",
        "            policy_param = pickle.load(open(model_file, 'rb'))\n",
        "        except:\n",
        "            policy_param = pickle.load(open(model_file, 'rb'),\n",
        "                                       encoding='bytes')  # To support python3\n",
        "        best_policy = PolicyValueNetNumpy(width, height, policy_param)\n",
        "        mcts_player = MCTSPlayer(best_policy.policy_value_fn,\n",
        "                                 c_puct=5,\n",
        "                                 n_playout=400)  # set larger n_playout for better performance\n",
        "\n",
        "        # uncomment the following line to play with pure MCTS (it's much weaker even with a larger n_playout)\n",
        "        # mcts_player = MCTS_Pure(c_puct=5, n_playout=1000)\n",
        "\n",
        "        # human player, input your move in the format: 2,3\n",
        "        human = Human()\n",
        "\n",
        "        # set start_player=0 for human first\n",
        "        await game.start_play(human, mcts_player, Message_LOC, start_player=0, is_shown=1)\n",
        "    except KeyboardInterrupt:\n",
        "        print('\\n\\rquit')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qz7T9tL6HtOd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "import codecs\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import namedtuple\n",
        "from tensorflow.python.ops import lookup_ops\n",
        "\n",
        "import codecs\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class HParams:\n",
        "    def __init__(self, model_dir):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_dir: Name of the folder storing the hparams.json file.\n",
        "        \"\"\"\n",
        "        self.hparams = self.load_hparams(model_dir)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_hparams(model_dir):\n",
        "        \"\"\"Load hparams from an existing directory.\"\"\"\n",
        "        hparams_file = os.path.join(model_dir, \"hparams.json\")\n",
        "        if tf.gfile.Exists(hparams_file):\n",
        "            print(\"# Loading hparams from {} ...\".format(hparams_file))\n",
        "            with codecs.getreader(\"utf-8\")(tf.gfile.GFile(hparams_file, \"rb\")) as f:\n",
        "                try:\n",
        "                    hparams_values = json.load(f)\n",
        "                    hparams = tf.contrib.training.HParams(**hparams_values)\n",
        "                except ValueError:\n",
        "                    print(\"Error loading hparams file.\")\n",
        "                    return None\n",
        "            return hparams\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "COMMENT_LINE_STT = \"#==\"\n",
        "CONVERSATION_SEP = \"===\"\n",
        "\n",
        "AUG0_FOLDER = \"Augment0\"\n",
        "AUG1_FOLDER = \"Augment1\"\n",
        "AUG2_FOLDER = \"Augment2\"\n",
        "\n",
        "MAX_LEN = 1000  # Assume no line in the training data is having more than this number of characters\n",
        "VOCAB_FILE = \"vocab.txt\"\n",
        "\n",
        "\n",
        "class TokenizedData:\n",
        "    def __init__(self, corpus_dir, hparams=None, training=True, buffer_size=8192):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            corpus_dir: Name of the folder storing corpus files for training.\n",
        "            hparams: The object containing the loaded hyper parameters. If None, it will be \n",
        "                    initialized here.\n",
        "            training: Whether to use this object for training.\n",
        "            buffer_size: The buffer size used for mapping process during data processing.\n",
        "        \"\"\"\n",
        "        if hparams is None:\n",
        "            self.hparams = HParams(corpus_dir).hparams\n",
        "        else:\n",
        "            self.hparams = hparams\n",
        "\n",
        "        self.src_max_len = self.hparams.src_max_len\n",
        "        self.tgt_max_len = self.hparams.tgt_max_len\n",
        "\n",
        "        self.training = training\n",
        "        self.text_set = None\n",
        "        self.id_set = None\n",
        "\n",
        "        vocab_file = os.path.join(corpus_dir, VOCAB_FILE)\n",
        "        self.vocab_size, _ = check_vocab(vocab_file)\n",
        "        self.vocab_table = lookup_ops.index_table_from_file(vocab_file,\n",
        "                                                            default_value=self.hparams.unk_id)\n",
        "        # print(\"vocab_size = {}\".format(self.vocab_size))\n",
        "\n",
        "        if training:\n",
        "            self.case_table = prepare_case_table()\n",
        "            self.reverse_vocab_table = None\n",
        "            self._load_corpus(corpus_dir)\n",
        "            self._convert_to_tokens(buffer_size)\n",
        "        else:\n",
        "            self.case_table = None\n",
        "            self.reverse_vocab_table = \\\n",
        "                lookup_ops.index_to_string_table_from_file(vocab_file,\n",
        "                                                           default_value=self.hparams.unk_token)\n",
        "\n",
        "    def get_training_batch(self, num_threads=4):\n",
        "        assert self.training\n",
        "\n",
        "        buffer_size = self.hparams.batch_size * 400\n",
        "\n",
        "        # Comment this line for debugging.\n",
        "        train_set = self.id_set.shuffle(buffer_size=buffer_size)\n",
        "\n",
        "        # Create a target input prefixed with BOS and a target output suffixed with EOS.\n",
        "        # After this mapping, each element in the train_set contains 3 columns/items.\n",
        "        train_set = train_set.map(lambda src, tgt:\n",
        "                                  (src, tf.concat(([self.hparams.bos_id], tgt), 0),\n",
        "                                   tf.concat((tgt, [self.hparams.eos_id]), 0)),\n",
        "                                  num_parallel_calls=num_threads).prefetch(buffer_size)\n",
        "\n",
        "        # Add in sequence lengths.\n",
        "        train_set = train_set.map(lambda src, tgt_in, tgt_out:\n",
        "                                  (src, tgt_in, tgt_out, tf.size(src), tf.size(tgt_in)),\n",
        "                                  num_parallel_calls=num_threads).prefetch(buffer_size)\n",
        "\n",
        "        def batching_func(x):\n",
        "            return x.padded_batch(\n",
        "                self.hparams.batch_size,\n",
        "                # The first three entries are the source and target line rows, these have unknown-length\n",
        "                # vectors. The last two entries are the source and target row sizes, which are scalars.\n",
        "                padded_shapes=(tf.TensorShape([None]),  # src\n",
        "                               tf.TensorShape([None]),  # tgt_input\n",
        "                               tf.TensorShape([None]),  # tgt_output\n",
        "                               tf.TensorShape([]),      # src_len\n",
        "                               tf.TensorShape([])),     # tgt_len\n",
        "                # Pad the source and target sequences with eos tokens. Though we don't generally need to\n",
        "                # do this since later on we will be masking out calculations past the true sequence.\n",
        "                padding_values=(self.hparams.eos_id,  # src\n",
        "                                self.hparams.eos_id,  # tgt_input\n",
        "                                self.hparams.eos_id,  # tgt_output\n",
        "                                0,       # src_len -- unused\n",
        "                                0))      # tgt_len -- unused\n",
        "\n",
        "        if self.hparams.num_buckets > 1:\n",
        "            bucket_width = (self.src_max_len + self.hparams.num_buckets - 1) // self.hparams.num_buckets\n",
        "\n",
        "            # Parameters match the columns in each element of the dataset.\n",
        "            def key_func(unused_1, unused_2, unused_3, src_len, tgt_len):\n",
        "                # Calculate bucket_width by maximum source sequence length. Pairs with length [0, bucket_width)\n",
        "                # go to bucket 0, length [bucket_width, 2 * bucket_width) go to bucket 1, etc. Pairs with\n",
        "                # length over ((num_bucket-1) * bucket_width) words all go into the last bucket.\n",
        "                # Bucket sentence pairs by the length of their source sentence and target sentence.\n",
        "                bucket_id = tf.maximum(src_len // bucket_width, tgt_len // bucket_width)\n",
        "                return tf.to_int64(tf.minimum(self.hparams.num_buckets, bucket_id))\n",
        "\n",
        "            # No key to filter the dataset. Therefore the key is unused.\n",
        "            def reduce_func(unused_key, windowed_data):\n",
        "                return batching_func(windowed_data)\n",
        "\n",
        "            batched_dataset = train_set.apply(\n",
        "                tf.contrib.data.group_by_window(key_func=key_func,\n",
        "                                                reduce_func=reduce_func,\n",
        "                                                window_size=self.hparams.batch_size))\n",
        "        else:\n",
        "            batched_dataset = batching_func(train_set)\n",
        "\n",
        "        batched_iter = batched_dataset.make_initializable_iterator()\n",
        "        (src_ids, tgt_input_ids, tgt_output_ids, src_seq_len, tgt_seq_len) = (batched_iter.get_next())\n",
        "\n",
        "        return BatchedInput(initializer=batched_iter.initializer,\n",
        "                            source=src_ids,\n",
        "                            target_input=tgt_input_ids,\n",
        "                            target_output=tgt_output_ids,\n",
        "                            source_sequence_length=src_seq_len,\n",
        "                            target_sequence_length=tgt_seq_len)\n",
        "\n",
        "    def get_inference_batch(self, src_dataset):\n",
        "        text_dataset = src_dataset.map(lambda src: tf.string_split([src]).values)\n",
        "\n",
        "        if self.hparams.src_max_len_infer:\n",
        "            text_dataset = text_dataset.map(lambda src: src[:self.hparams.src_max_len_infer])\n",
        "        # Convert the word strings to ids\n",
        "        id_dataset = text_dataset.map(lambda src: tf.cast(self.vocab_table.lookup(src),\n",
        "                                                          tf.int32))\n",
        "        if self.hparams.source_reverse:\n",
        "            id_dataset = id_dataset.map(lambda src: tf.reverse(src, axis=[0]))\n",
        "        # Add in the word counts.\n",
        "        id_dataset = id_dataset.map(lambda src: (src, tf.size(src)))\n",
        "\n",
        "        def batching_func(x):\n",
        "            return x.padded_batch(\n",
        "                self.hparams.batch_size_infer,\n",
        "                # The entry is the source line rows; this has unknown-length vectors.\n",
        "                # The last entry is the source row size; this is a scalar.\n",
        "                padded_shapes=(tf.TensorShape([None]),  # src\n",
        "                               tf.TensorShape([])),     # src_len\n",
        "                # Pad the source sequences with eos tokens. Though notice we don't generally need to\n",
        "                # do this since later on we will be masking out calculations past the true sequence.\n",
        "                padding_values=(self.hparams.eos_id,  # src\n",
        "                                0))                   # src_len -- unused\n",
        "\n",
        "        id_dataset = batching_func(id_dataset)\n",
        "\n",
        "        infer_iter = id_dataset.make_initializable_iterator()\n",
        "        (src_ids, src_seq_len) = infer_iter.get_next()\n",
        "\n",
        "        return BatchedInput(initializer=infer_iter.initializer,\n",
        "                            source=src_ids,\n",
        "                            target_input=None,\n",
        "                            target_output=None,\n",
        "                            source_sequence_length=src_seq_len,\n",
        "                            target_sequence_length=None)\n",
        "\n",
        "    def _load_corpus(self, corpus_dir):\n",
        "        for fd in range(2, -1, -1):\n",
        "            file_list = []\n",
        "            if fd == 0:\n",
        "                file_dir = os.path.join(corpus_dir, AUG0_FOLDER)\n",
        "            elif fd == 1:\n",
        "                file_dir = os.path.join(corpus_dir, AUG1_FOLDER)\n",
        "            else:\n",
        "                file_dir = os.path.join(corpus_dir, AUG2_FOLDER)\n",
        "\n",
        "            for data_file in sorted(os.listdir(file_dir)):\n",
        "                full_path_name = os.path.join(file_dir, data_file)\n",
        "                if os.path.isfile(full_path_name) and data_file.lower().endswith('.txt'):\n",
        "                    file_list.append(full_path_name)\n",
        "\n",
        "            assert len(file_list) > 0\n",
        "            dataset = tf.data.TextLineDataset(file_list)\n",
        "\n",
        "            src_dataset = dataset.filter(lambda line:\n",
        "                                         tf.logical_and(tf.size(line) > 0,\n",
        "                                                        tf.equal(tf.substr(line, 0, 2), tf.constant('Q:'))))\n",
        "            src_dataset = src_dataset.map(lambda line:\n",
        "                                          tf.substr(line, 2, MAX_LEN)).prefetch(4096)\n",
        "            tgt_dataset = dataset.filter(lambda line:\n",
        "                                         tf.logical_and(tf.size(line) > 0,\n",
        "                                                        tf.equal(tf.substr(line, 0, 2), tf.constant('A:'))))\n",
        "            tgt_dataset = tgt_dataset.map(lambda line:\n",
        "                                          tf.substr(line, 2, MAX_LEN)).prefetch(4096)\n",
        "\n",
        "            src_tgt_dataset = tf.data.Dataset.zip((src_dataset, tgt_dataset))\n",
        "            if fd == 1:\n",
        "                src_tgt_dataset = src_tgt_dataset.repeat(self.hparams.aug1_repeat_times)\n",
        "            elif fd == 2:\n",
        "                src_tgt_dataset = src_tgt_dataset.repeat(self.hparams.aug2_repeat_times)\n",
        "\n",
        "            if self.text_set is None:\n",
        "                self.text_set = src_tgt_dataset\n",
        "            else:\n",
        "                self.text_set = self.text_set.concatenate(src_tgt_dataset)\n",
        "\n",
        "    def _convert_to_tokens(self, buffer_size):\n",
        "        # The following 3 steps act as a python String lower() function\n",
        "        # Split to characters\n",
        "        self.text_set = self.text_set.map(lambda src, tgt:\n",
        "                                          (tf.string_split([src], delimiter='').values,\n",
        "                                           tf.string_split([tgt], delimiter='').values)\n",
        "                                          ).prefetch(buffer_size)\n",
        "        # Convert all upper case characters to lower case characters\n",
        "        self.text_set = self.text_set.map(lambda src, tgt:\n",
        "                                          (self.case_table.lookup(src), self.case_table.lookup(tgt))\n",
        "                                          ).prefetch(buffer_size)\n",
        "        # Join characters back to strings\n",
        "        self.text_set = self.text_set.map(lambda src, tgt:\n",
        "                                          (tf.reduce_join([src]), tf.reduce_join([tgt]))\n",
        "                                          ).prefetch(buffer_size)\n",
        "\n",
        "        # Split to word tokens\n",
        "        self.text_set = self.text_set.map(lambda src, tgt:\n",
        "                                          (tf.string_split([src]).values, tf.string_split([tgt]).values)\n",
        "                                          ).prefetch(buffer_size)\n",
        "        # Remove sentences longer than the model allows\n",
        "        self.text_set = self.text_set.map(lambda src, tgt:\n",
        "                                          (src[:self.src_max_len], tgt[:self.tgt_max_len])\n",
        "                                          ).prefetch(buffer_size)\n",
        "\n",
        "        # Reverse the source sentence if applicable\n",
        "        if self.hparams.source_reverse:\n",
        "            self.text_set = self.text_set.map(lambda src, tgt:\n",
        "                                              (tf.reverse(src, axis=[0]), tgt)\n",
        "                                              ).prefetch(buffer_size)\n",
        "\n",
        "        # Convert the word strings to ids.  Word strings that are not in the vocab get\n",
        "        # the lookup table's default_value integer.\n",
        "        self.id_set = self.text_set.map(lambda src, tgt:\n",
        "                                        (tf.cast(self.vocab_table.lookup(src), tf.int32),\n",
        "                                         tf.cast(self.vocab_table.lookup(tgt), tf.int32))\n",
        "                                        ).prefetch(buffer_size)\n",
        "\n",
        "\n",
        "def check_vocab(vocab_file):\n",
        "    \"\"\"Check to make sure vocab_file exists\"\"\"\n",
        "    if tf.gfile.Exists(vocab_file):\n",
        "        vocab_list = []\n",
        "        with codecs.getreader(\"utf-8\")(tf.gfile.GFile(vocab_file, \"rb\")) as f:\n",
        "            for word in f:\n",
        "                vocab_list.append(word.strip())\n",
        "    else:\n",
        "        raise ValueError(\"The vocab_file does not exist. Please run the script to create it.\")\n",
        "\n",
        "    return len(vocab_list), vocab_list\n",
        "\n",
        "\n",
        "def prepare_case_table():\n",
        "    keys = tf.constant([chr(i) for i in range(32, 127)])\n",
        "\n",
        "    l1 = [chr(i) for i in range(32, 65)]\n",
        "    l2 = [chr(i) for i in range(97, 123)]\n",
        "    l3 = [chr(i) for i in range(91, 127)]\n",
        "    values = tf.constant(l1 + l2 + l3)\n",
        "\n",
        "    return tf.contrib.lookup.HashTable(\n",
        "        tf.contrib.lookup.KeyValueTensorInitializer(keys, values), ' ')\n",
        "\n",
        "\n",
        "class BatchedInput(namedtuple(\"BatchedInput\",\n",
        "                              [\"initializer\",\n",
        "                               \"source\",\n",
        "                               \"target_input\",\n",
        "                               \"target_output\",\n",
        "                               \"source_sequence_length\",\n",
        "                               \"target_sequence_length\"])):\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_initializer(init_op, seed=None, init_weight=None):\n",
        "    \"\"\"Create an initializer. init_weight is only for uniform.\"\"\"\n",
        "    if init_op == \"uniform\":\n",
        "        assert init_weight\n",
        "        return tf.random_uniform_initializer(-init_weight, init_weight, seed=seed)\n",
        "    elif init_op == \"glorot_normal\":\n",
        "        return tf.contrib.keras.initializers.glorot_normal(seed=seed)\n",
        "    elif init_op == \"glorot_uniform\":\n",
        "        return tf.contrib.keras.initializers.glorot_uniform(seed=seed)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown init_op %s\" % init_op)\n",
        "\n",
        "\n",
        "# def get_device_str(device_id, num_gpus):\n",
        "#     \"\"\"Return a device string for multi-GPU setup.\"\"\"\n",
        "#     if num_gpus == 0:\n",
        "#         return \"/cpu:0\"\n",
        "#     device_str_output = \"/gpu:%d\" % (device_id % num_gpus)\n",
        "#     return device_str_output\n",
        "\n",
        "\n",
        "def create_embbeding(vocab_size, embed_size, dtype=tf.float32, scope=None):\n",
        "    \"\"\"Create embedding matrix for both encoder and decoder.\"\"\"\n",
        "    with tf.variable_scope(scope or \"embeddings\", dtype=dtype):\n",
        "        embedding = tf.get_variable(\"embedding\", [vocab_size, embed_size], dtype)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "\n",
        "def _single_cell(num_units, keep_prob, device_str=None):\n",
        "    \"\"\"Create an instance of a single RNN cell.\"\"\"\n",
        "    single_cell = tf.contrib.rnn.GRUCell(num_units)\n",
        "\n",
        "    if keep_prob < 1.0:\n",
        "        single_cell = tf.contrib.rnn.DropoutWrapper(cell=single_cell, input_keep_prob=keep_prob)\n",
        "\n",
        "    # Device Wrapper\n",
        "    if device_str:\n",
        "        single_cell = tf.contrib.rnn.DeviceWrapper(single_cell, device_str)\n",
        "\n",
        "    return single_cell\n",
        "\n",
        "\n",
        "def create_rnn_cell(num_units, num_layers, keep_prob):\n",
        "    \"\"\"Create multi-layer RNN cell.\"\"\"\n",
        "    cell_list = []\n",
        "    for i in range(num_layers):\n",
        "        single_cell = _single_cell(num_units=num_units, keep_prob=keep_prob)\n",
        "        cell_list.append(single_cell)\n",
        "\n",
        "    if len(cell_list) == 1:  # Single layer.\n",
        "        return cell_list[0]\n",
        "    else:  # Multi layers\n",
        "        return tf.contrib.rnn.MultiRNNCell(cell_list)\n",
        "\n",
        "\n",
        "def gradient_clip(gradients, max_gradient_norm):\n",
        "    \"\"\"Clipping gradients of a model.\"\"\"\n",
        "    clipped_gradients, gradient_norm = tf.clip_by_global_norm(gradients, max_gradient_norm)\n",
        "    gradient_norm_summary = [tf.summary.scalar(\"grad_norm\", gradient_norm)]\n",
        "    gradient_norm_summary.append(\n",
        "        tf.summary.scalar(\"clipped_gradient\", tf.global_norm(clipped_gradients)))\n",
        "\n",
        "    return clipped_gradients, gradient_norm_summary\n",
        "\n",
        "from tensorflow.python.layers import core as layers_core\n",
        "\n",
        "\n",
        "class ModelCreator(object):\n",
        "    \"\"\"Sequence-to-sequence model creator to create models for training or inference\"\"\"\n",
        "    def __init__(self, training, tokenized_data, batch_input, scope=None):\n",
        "        \"\"\"\n",
        "        Create the model.\n",
        "\n",
        "        Args:\n",
        "            training: A boolean value to indicate whether this model will be used for training.\n",
        "            tokenized_data: The data object containing all information required for the model.\n",
        "            scope: scope of the model.\n",
        "        \"\"\"\n",
        "        self.training = training\n",
        "        self.batch_input = batch_input\n",
        "        self.vocab_table = tokenized_data.vocab_table\n",
        "        self.vocab_size = tokenized_data.vocab_size\n",
        "        self.reverse_vocab_table = tokenized_data.reverse_vocab_table\n",
        "\n",
        "        hparams = tokenized_data.hparams\n",
        "        self.hparams = hparams\n",
        "\n",
        "        self.num_layers = hparams.num_layers\n",
        "        self.time_major = hparams.time_major\n",
        "\n",
        "        # Initializer\n",
        "        initializer = get_initializer(\n",
        "            hparams.init_op, hparams.random_seed, hparams.init_weight)\n",
        "        tf.get_variable_scope().set_initializer(initializer)\n",
        "\n",
        "        # Embeddings\n",
        "        self.embedding = (create_embbeding(vocab_size=self.vocab_size,\n",
        "                                                        embed_size=hparams.num_units,\n",
        "                                                        scope=scope))\n",
        "        # This batch_size might vary among each batch instance due to the bucketing and/or reach\n",
        "        # the end of the training set. Treat it as size_of_the_batch.\n",
        "        self.batch_size = tf.size(self.batch_input.source_sequence_length)\n",
        "\n",
        "        # Projection\n",
        "        with tf.variable_scope(scope or \"build_network\"):\n",
        "            with tf.variable_scope(\"decoder/output_projection\"):\n",
        "                self.output_layer = layers_core.Dense(\n",
        "                    self.vocab_size, use_bias=False, name=\"output_projection\")\n",
        "\n",
        "        # Training or inference graph\n",
        "        print(\"# Building graph for the model ...\")\n",
        "        res = self.build_graph(hparams, scope=scope)\n",
        "\n",
        "        if training:\n",
        "            self.train_loss = res[1]\n",
        "            self.word_count = tf.reduce_sum(self.batch_input.source_sequence_length) + \\\n",
        "                              tf.reduce_sum(self.batch_input.target_sequence_length)\n",
        "            # Count the number of predicted words for compute perplexity.\n",
        "            self.predict_count = tf.reduce_sum(self.batch_input.target_sequence_length)\n",
        "        else:\n",
        "            self.infer_logits, _, self.final_context_state, self.sample_id = res\n",
        "            self.sample_words = self.reverse_vocab_table.lookup(tf.to_int64(self.sample_id))\n",
        "\n",
        "        self.global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "        params = tf.trainable_variables()\n",
        "\n",
        "        # Gradients update operation for training the model.\n",
        "        if training:\n",
        "            self.learning_rate = tf.placeholder(tf.float32, shape=[], name='learning_rate')\n",
        "            opt = tf.train.AdamOptimizer(self.learning_rate)\n",
        "\n",
        "            gradients = tf.gradients(self.train_loss, params)\n",
        "\n",
        "            clipped_gradients, gradient_norm_summary = gradient_clip(\n",
        "                gradients, max_gradient_norm=hparams.max_gradient_norm)\n",
        "\n",
        "            self.update = opt.apply_gradients(\n",
        "                zip(clipped_gradients, params), global_step=self.global_step)\n",
        "\n",
        "            # Summary\n",
        "            self.train_summary = tf.summary.merge([\n",
        "                tf.summary.scalar(\"learning_rate\", self.learning_rate),\n",
        "                tf.summary.scalar(\"train_loss\", self.train_loss),\n",
        "            ] + gradient_norm_summary)\n",
        "        else:\n",
        "            self.infer_summary = tf.no_op()\n",
        "\n",
        "        # Saver\n",
        "        self.saver = tf.train.Saver(tf.global_variables())\n",
        "\n",
        "        # Print trainable variables\n",
        "        if training:\n",
        "            print(\"# Trainable variables:\")\n",
        "            for param in params:\n",
        "                print(\"  {}, {}, {}\".format(param.name, str(param.get_shape()), param.op.device))\n",
        "\n",
        "    def train_step(self, sess, learning_rate):\n",
        "        \"\"\"Run one step of training.\"\"\"\n",
        "        assert self.training\n",
        "\n",
        "        return sess.run([self.update,\n",
        "                         self.train_loss,\n",
        "                         self.predict_count,\n",
        "                         self.train_summary,\n",
        "                         self.global_step,\n",
        "                         self.word_count,\n",
        "                         self.batch_size],\n",
        "                        feed_dict={self.learning_rate: learning_rate})\n",
        "\n",
        "    def build_graph(self, hparams, scope=None):\n",
        "        \"\"\"Creates a sequence-to-sequence model with dynamic RNN decoder API.\"\"\"\n",
        "        dtype = tf.float32\n",
        "\n",
        "        with tf.variable_scope(scope or \"dynamic_seq2seq\", dtype=dtype):\n",
        "            # Encoder\n",
        "            encoder_outputs, encoder_state = self._build_encoder(hparams)\n",
        "\n",
        "            # Decoder\n",
        "            logits, sample_id, final_context_state = self._build_decoder(\n",
        "                encoder_outputs, encoder_state, hparams)\n",
        "\n",
        "            # Loss\n",
        "            if self.training:\n",
        "                loss = self._compute_loss(logits)\n",
        "            else:\n",
        "                loss = None\n",
        "\n",
        "            return logits, loss, final_context_state, sample_id\n",
        "\n",
        "    def _build_encoder(self, hparams):\n",
        "        \"\"\"Build an encoder.\"\"\"\n",
        "        source = self.batch_input.source\n",
        "        if self.time_major:\n",
        "            source = tf.transpose(source)\n",
        "\n",
        "        with tf.variable_scope(\"encoder\") as scope:\n",
        "            dtype = scope.dtype\n",
        "            # Look up embedding, emp_inp: [max_time, batch_size, num_units]\n",
        "            encoder_emb_inp = tf.nn.embedding_lookup(self.embedding, source)\n",
        "\n",
        "            # Encoder_outpus: [max_time, batch_size, num_units]\n",
        "            cell = self._build_encoder_cell(hparams)\n",
        "\n",
        "            encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
        "                cell,\n",
        "                encoder_emb_inp,\n",
        "                dtype=dtype,\n",
        "                sequence_length=self.batch_input.source_sequence_length,\n",
        "                time_major=self.time_major)\n",
        "\n",
        "        return encoder_outputs, encoder_state\n",
        "\n",
        "    def _build_encoder_cell(self, hparams):\n",
        "        \"\"\"Build a multi-layer RNN cell that can be used by encoder.\"\"\"\n",
        "        return create_rnn_cell(\n",
        "            num_units=hparams.num_units,\n",
        "            num_layers=hparams.num_layers,\n",
        "            keep_prob=hparams.keep_prob)\n",
        "\n",
        "    def _build_decoder(self, encoder_outputs, encoder_state, hparams):\n",
        "        \"\"\"Build and run a RNN decoder with a final projection layer.\"\"\"\n",
        "        bos_id = tf.cast(self.vocab_table.lookup(tf.constant(hparams.bos_token)), tf.int32)\n",
        "        eos_id = tf.cast(self.vocab_table.lookup(tf.constant(hparams.eos_token)), tf.int32)\n",
        "\n",
        "        # maximum_iteration: The maximum decoding steps.\n",
        "        if hparams.tgt_max_len_infer:\n",
        "            maximum_iterations = hparams.tgt_max_len_infer\n",
        "        else:\n",
        "            decoding_length_factor = 2.0\n",
        "            max_encoder_length = tf.reduce_max(self.batch_input.source_sequence_length)\n",
        "            maximum_iterations = tf.to_int32(tf.round(\n",
        "                tf.to_float(max_encoder_length) * decoding_length_factor))\n",
        "\n",
        "        # Decoder.\n",
        "        with tf.variable_scope(\"decoder\") as decoder_scope:\n",
        "            cell, decoder_initial_state = self._build_decoder_cell(\n",
        "                hparams, encoder_outputs, encoder_state,\n",
        "                self.batch_input.source_sequence_length)\n",
        "\n",
        "            # Training\n",
        "            if self.training:\n",
        "                # decoder_emp_inp: [max_time, batch_size, num_units]\n",
        "                target_input = self.batch_input.target_input\n",
        "                if self.time_major:\n",
        "                    target_input = tf.transpose(target_input)\n",
        "                decoder_emb_inp = tf.nn.embedding_lookup(self.embedding, target_input)\n",
        "\n",
        "                # Helper\n",
        "                helper = tf.contrib.seq2seq.TrainingHelper(\n",
        "                    decoder_emb_inp, self.batch_input.target_sequence_length,\n",
        "                    time_major=self.time_major)\n",
        "\n",
        "                # Decoder\n",
        "                my_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
        "                    cell,\n",
        "                    helper,\n",
        "                    decoder_initial_state,)\n",
        "\n",
        "                # Dynamic decoding\n",
        "                outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
        "                    my_decoder,\n",
        "                    output_time_major=self.time_major,\n",
        "                    swap_memory=True,\n",
        "                    scope=decoder_scope)\n",
        "\n",
        "                sample_id = outputs.sample_id\n",
        "                logits = self.output_layer(outputs.rnn_output)\n",
        "            # Inference\n",
        "            else:\n",
        "                beam_width = hparams.beam_width\n",
        "                length_penalty_weight = hparams.length_penalty_weight\n",
        "                start_tokens = tf.fill([self.batch_size], bos_id)\n",
        "                end_token = eos_id\n",
        "\n",
        "                if beam_width > 0:\n",
        "                    my_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
        "                        cell=cell,\n",
        "                        embedding=self.embedding,\n",
        "                        start_tokens=start_tokens,\n",
        "                        end_token=end_token,\n",
        "                        initial_state=decoder_initial_state,\n",
        "                        beam_width=beam_width,\n",
        "                        output_layer=self.output_layer,\n",
        "                        length_penalty_weight=length_penalty_weight)\n",
        "                else:\n",
        "                    # Helper\n",
        "                    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
        "                        self.embedding, start_tokens, end_token)\n",
        "\n",
        "                    # Decoder\n",
        "                    my_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
        "                        cell,\n",
        "                        helper,\n",
        "                        decoder_initial_state,\n",
        "                        output_layer=self.output_layer  # applied per timestep\n",
        "                    )\n",
        "\n",
        "                # Dynamic decoding\n",
        "                outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
        "                    my_decoder,\n",
        "                    maximum_iterations=maximum_iterations,\n",
        "                    output_time_major=self.time_major,\n",
        "                    swap_memory=True,\n",
        "                    scope=decoder_scope)\n",
        "\n",
        "                if beam_width > 0:\n",
        "                    logits = tf.no_op()\n",
        "                    sample_id = outputs.predicted_ids\n",
        "                else:\n",
        "                    logits = outputs.rnn_output\n",
        "                    sample_id = outputs.sample_id\n",
        "\n",
        "        return logits, sample_id, final_context_state\n",
        "\n",
        "    def _build_decoder_cell(self, hparams, encoder_outputs, encoder_state,\n",
        "                            source_sequence_length):\n",
        "        \"\"\"Build a RNN cell with attention mechanism that can be used by decoder.\"\"\"\n",
        "        num_units = hparams.num_units\n",
        "        num_layers = hparams.num_layers\n",
        "        beam_width = hparams.beam_width\n",
        "\n",
        "        dtype = tf.float32\n",
        "\n",
        "        if self.time_major:\n",
        "            memory = tf.transpose(encoder_outputs, [1, 0, 2])\n",
        "        else:\n",
        "            memory = encoder_outputs\n",
        "\n",
        "        if not self.training and beam_width > 0:\n",
        "            memory = tf.contrib.seq2seq.tile_batch(memory, multiplier=beam_width)\n",
        "            source_sequence_length = tf.contrib.seq2seq.tile_batch(source_sequence_length,\n",
        "                                                                   multiplier=beam_width)\n",
        "            encoder_state = tf.contrib.seq2seq.tile_batch(encoder_state,\n",
        "                                                          multiplier=beam_width)\n",
        "            batch_size = self.batch_size * beam_width\n",
        "        else:\n",
        "            batch_size = self.batch_size\n",
        "\n",
        "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
        "            num_units, memory, memory_sequence_length=source_sequence_length)\n",
        "\n",
        "        cell = create_rnn_cell(\n",
        "            num_units=num_units,\n",
        "            num_layers=num_layers,\n",
        "            keep_prob=hparams.keep_prob)\n",
        "\n",
        "        # Only generate alignment in greedy INFER mode.\n",
        "        alignment_history = (not self.training and beam_width == 0)\n",
        "        cell = tf.contrib.seq2seq.AttentionWrapper(\n",
        "            cell,\n",
        "            attention_mechanism,\n",
        "            attention_layer_size=num_units,\n",
        "            alignment_history=alignment_history,\n",
        "            name=\"attention\")\n",
        "\n",
        "        if hparams.pass_hidden_state:\n",
        "            decoder_initial_state = cell.zero_state(batch_size, dtype).clone(cell_state=encoder_state)\n",
        "        else:\n",
        "            decoder_initial_state = cell.zero_state(batch_size, dtype)\n",
        "\n",
        "        return cell, decoder_initial_state\n",
        "\n",
        "    def _compute_loss(self, logits):\n",
        "        \"\"\"Compute optimization loss.\"\"\"\n",
        "        target_output = self.batch_input.target_output\n",
        "        if self.time_major:\n",
        "            target_output = tf.transpose(target_output)\n",
        "        max_time = self.get_max_time(target_output)\n",
        "        crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            labels=target_output, logits=logits)\n",
        "        target_weights = tf.sequence_mask(\n",
        "            self.batch_input.target_sequence_length, max_time, dtype=logits.dtype)\n",
        "        if self.time_major:\n",
        "            target_weights = tf.transpose(target_weights)\n",
        "\n",
        "        loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(self.batch_size)\n",
        "        return loss\n",
        "\n",
        "    def get_max_time(self, tensor):\n",
        "        time_axis = 0 if self.time_major else 1\n",
        "        return tensor.shape[time_axis].value or tf.shape(tensor)[time_axis]\n",
        "\n",
        "    def infer(self, sess):\n",
        "        assert not self.training\n",
        "        _, infer_summary, _, sample_words = sess.run([\n",
        "            self.infer_logits, self.infer_summary, self.sample_id, self.sample_words\n",
        "        ])\n",
        "\n",
        "        # make sure outputs is of shape [batch_size, time]\n",
        "        if self.time_major:\n",
        "            sample_words = sample_words.transpose()\n",
        "\n",
        "        return sample_words, infer_summary\n",
        "      \n",
        "import os\n",
        "\n",
        "UPPER_FILE = \"upper_words.txt\"\n",
        "STORIES_FILE = \"stories.txt\"\n",
        "JOKES_FILE = \"jokes.txt\"\n",
        "\n",
        "\n",
        "class KnowledgeBase:\n",
        "    def __init__(self):\n",
        "        self.upper_words = {}\n",
        "        self.stories = {}\n",
        "        self.jokes = []\n",
        "\n",
        "    def load_knbase(self, knbase_dir):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "             knbase_dir: Name of the KnowledgeBase folder. The file names inside are fixed.\n",
        "        \"\"\"\n",
        "        upper_file_name = os.path.join(knbase_dir, UPPER_FILE)\n",
        "        stories_file_name = os.path.join(knbase_dir, STORIES_FILE)\n",
        "        jokes_file_name = os.path.join(knbase_dir, JOKES_FILE)\n",
        "\n",
        "        with open(upper_file_name, 'r') as upper_f:\n",
        "            for line in upper_f:\n",
        "                ln = line.strip()\n",
        "                if not ln or ln.startswith('#'):\n",
        "                    continue\n",
        "                cap_words = ln.split(',')\n",
        "                for cpw in cap_words:\n",
        "                    tmp = cpw.strip()\n",
        "                    self.upper_words[tmp.lower()] = tmp\n",
        "\n",
        "        with open(stories_file_name, 'r') as stories_f:\n",
        "            s_name, s_content = '', ''\n",
        "            for line in stories_f:\n",
        "                ln = line.strip()\n",
        "                if not ln or ln.startswith('#'):\n",
        "                    continue\n",
        "                if ln.startswith('_NAME:'):\n",
        "                    if s_name != '' and s_content != '':\n",
        "                        self.stories[s_name] = s_content\n",
        "                        s_name, s_content = '', ''\n",
        "                    s_name = ln[6:].strip().lower()\n",
        "                elif ln.startswith('_CONTENT:'):\n",
        "                    s_content = ln[9:].strip()\n",
        "                else:\n",
        "                    s_content += ' ' + ln.strip()\n",
        "\n",
        "            if s_name != '' and s_content != '':  # The last one\n",
        "                self.stories[s_name] = s_content\n",
        "\n",
        "        with open(jokes_file_name, 'r') as jokes_f:\n",
        "            for line in jokes_f:\n",
        "                ln = line.strip()\n",
        "                if not ln or ln.startswith('#'):\n",
        "                    continue\n",
        "                self.jokes.append(ln)\n",
        "                \n",
        "class SessionData:\n",
        "    def __init__(self):\n",
        "        self.session_dict = {}\n",
        "\n",
        "    def add_session(self):\n",
        "        items = self.session_dict.items()\n",
        "        if items:\n",
        "            last_id = max(k for k, v in items)\n",
        "        else:\n",
        "            last_id = 0\n",
        "        new_id = last_id + 1\n",
        "\n",
        "        self.session_dict[new_id] = ChatSession(new_id)\n",
        "        return new_id\n",
        "\n",
        "    def get_session(self, session_id):\n",
        "        return self.session_dict[session_id]\n",
        "\n",
        "\n",
        "class ChatSession:\n",
        "    def __init__(self, session_id):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            session_id: The integer ID of the chat session.\n",
        "        \"\"\"\n",
        "        self.session_id = session_id\n",
        "\n",
        "        self.howru_asked = False\n",
        "\n",
        "        self.user_name = None\n",
        "        self.call_me = None\n",
        "\n",
        "        self.last_question = None\n",
        "        self.last_answer = None\n",
        "        self.update_pair = True\n",
        "\n",
        "        self.last_topic = None\n",
        "        self.keep_topic = False\n",
        "\n",
        "        # Will be storing the information of the pending action:\n",
        "        # The action function name, the parameter for answer yes, and the parameter for answer no.\n",
        "        self.pending_action = {'func': None, 'Yes': None, 'No': None}\n",
        "\n",
        "    def before_prediction(self):\n",
        "        self.update_pair = True\n",
        "        self.keep_topic = False\n",
        "\n",
        "    def after_prediction(self, new_question, new_answer):\n",
        "        self._update_last_pair(new_question, new_answer)\n",
        "        self._clear_last_topic()\n",
        "\n",
        "    def _update_last_pair(self, new_question, new_answer):\n",
        "        \"\"\"\n",
        "        Last pair is updated after each prediction except in a few cases.\n",
        "        \"\"\"\n",
        "        if self.update_pair:\n",
        "            self.last_question = new_question\n",
        "            self.last_answer = new_answer\n",
        "\n",
        "    def _clear_last_topic(self):\n",
        "        \"\"\"\n",
        "        Last topic is cleared after each prediction except in a few cases.\n",
        "        \"\"\"\n",
        "        if not self.keep_topic:\n",
        "            self.last_topic = None\n",
        "\n",
        "    def update_pending_action(self, func_name, yes_para, no_para):\n",
        "        self.pending_action['func'] = func_name\n",
        "        self.pending_action['Yes'] = yes_para\n",
        "        self.pending_action['No'] = no_para\n",
        "\n",
        "    def clear_pending_action(self):\n",
        "        \"\"\"\n",
        "        Pending action is, and only is, cleared at the end of function: execute_pending_action_and_reply.\n",
        "        \"\"\"\n",
        "        self.pending_action['func'] = None\n",
        "        self.pending_action['Yes'] = None\n",
        "        self.pending_action['No'] = None\n",
        "        \n",
        "import re\n",
        "\n",
        "\n",
        "def check_patterns_and_replace(question):\n",
        "    pat_matched, new_sentence, para_list = _check_arithmetic_pattern_and_replace(question)\n",
        "\n",
        "    if not pat_matched:\n",
        "        pat_matched, new_sentence, para_list = _check_not_username_pattern_and_replace(new_sentence)\n",
        "\n",
        "    if not pat_matched:\n",
        "        pat_matched, new_sentence, para_list = _check_username_callme_pattern_and_replace(new_sentence)\n",
        "\n",
        "    return pat_matched, new_sentence, para_list\n",
        "\n",
        "\n",
        "def _check_arithmetic_pattern_and_replace(sentence):\n",
        "    pat_matched, ind_list, num_list = _contains_arithmetic_pattern(sentence)\n",
        "    if pat_matched:\n",
        "        s1, e1 = ind_list[0]\n",
        "        s2, e2 = ind_list[1]\n",
        "        # Leave spaces around the special tokens so that NLTK knows they are separate tokens\n",
        "        new_sentence = sentence[:s1] + ' _num1_ ' + sentence[e1:s2] + ' _num2_ ' + sentence[e2:]\n",
        "        return True, new_sentence, num_list\n",
        "    else:\n",
        "        return False, sentence, num_list\n",
        "\n",
        "\n",
        "def _contains_arithmetic_pattern(sentence):\n",
        "    numbers = [\n",
        "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\",\n",
        "        \"eight\", \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\",\n",
        "        \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
        "        \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\",\n",
        "        \"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
        "\n",
        "    pat_op1 = re.compile(\n",
        "        r'\\s(plus|add|added|\\+|minus|subtract|subtracted|-|times|multiply|multiplied|\\*|divide|(divided\\s+by)|/)\\s',\n",
        "        re.IGNORECASE)\n",
        "    pat_op2 = re.compile(r'\\s((sum\\s+of)|(product\\s+of))\\s', re.IGNORECASE)\n",
        "    pat_as = re.compile(r'((\\bis\\b)|=|(\\bequals\\b)|(\\bget\\b))', re.IGNORECASE)\n",
        "\n",
        "    mat_op1 = re.search(pat_op1, sentence)\n",
        "    mat_op2 = re.search(pat_op2, sentence)\n",
        "    mat_as = re.search(pat_as, sentence)\n",
        "    if (mat_op1 or mat_op2) and mat_as:  # contains an arithmetic operator and an assign operator\n",
        "        # Replace all occurrences of word \"and\" with 3 whitespaces before feeding to\n",
        "        # the pattern matcher.\n",
        "        pat_and = re.compile(r'\\band\\b', re.IGNORECASE)\n",
        "        if mat_op1:\n",
        "            tmp_sentence = pat_and.sub('   ', sentence)\n",
        "        else:  # Do not support word 'and' in the English numbers any more as that can be ambiguous.\n",
        "            tmp_sentence = pat_and.sub('_T_', sentence)\n",
        "\n",
        "        number_rx = r'(?:{})'.format('|'.join(numbers))\n",
        "        pat_num = re.compile(r'\\b{0}(?:(?:\\s+(?:and\\s+)?|-){0})*\\b|\\d+'.format(number_rx),\n",
        "                             re.IGNORECASE)\n",
        "        ind_list = [(m.start(0), m.end(0)) for m in re.finditer(pat_num, tmp_sentence)]\n",
        "        num_list = []\n",
        "        if len(ind_list) == 2:  # contains exactly two numbers\n",
        "            for start, end in ind_list:\n",
        "                text = sentence[start:end]\n",
        "                text_int = _text2int(text)\n",
        "                if text_int == -1:\n",
        "                    return False, [], []\n",
        "                num_list.append(text_int)\n",
        "\n",
        "            return True, ind_list, num_list\n",
        "\n",
        "    return False, [], []\n",
        "\n",
        "\n",
        "def _text2int(text):\n",
        "    if text.isdigit():\n",
        "        return int(text)\n",
        "\n",
        "    num_words = {}\n",
        "    units = [\n",
        "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
        "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
        "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
        "    ]\n",
        "    tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
        "    scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
        "\n",
        "    num_words[\"and\"] = (1, 0)\n",
        "    for idx, word in enumerate(units):\n",
        "        num_words[word] = (1, idx)\n",
        "    for idx, word in enumerate(tens):\n",
        "        num_words[word] = (1, idx * 10)\n",
        "    for idx, word in enumerate(scales):\n",
        "        num_words[word] = (10 ** (idx * 3 or 2), 0)\n",
        "\n",
        "    current = result = 0\n",
        "    for word in text.replace(\"-\", \" \").lower().split():\n",
        "        if word not in num_words:\n",
        "            return -1\n",
        "\n",
        "        scale, increment = num_words[word]\n",
        "        current = current * scale + increment\n",
        "        if scale > 100:\n",
        "            result += current\n",
        "            current = 0\n",
        "\n",
        "    return result + current\n",
        "\n",
        "\n",
        "def _check_not_username_pattern_and_replace(sentence):\n",
        "    import nltk\n",
        "\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tmp_sentence = ' '.join(tokens[:]).strip()\n",
        "\n",
        "    pat_not_but = re.compile(r'(\\s|^)my\\s+name\\s+is\\s+(not|n\\'t)\\s+(.+?)(\\s\\.|\\s,|\\s!)\\s*but\\s+(.+?)(\\s\\.|\\s,|\\s!|$)',\n",
        "                             re.IGNORECASE)\n",
        "    mat_not_but = re.search(pat_not_but, tmp_sentence)\n",
        "\n",
        "    pat_not = re.compile(r'(\\s|^)my\\s+name\\s+is\\s+(not|n\\'t)\\s+(.+?)(\\s\\.|\\s,|\\s!|$)', re.IGNORECASE)\n",
        "    mat_not = re.search(pat_not, tmp_sentence)\n",
        "\n",
        "    para_list = []\n",
        "    found = 0\n",
        "    if mat_not_but:\n",
        "        wrong_name = mat_not_but.group(3).strip()\n",
        "        correct_name = mat_not_but.group(5).strip()\n",
        "        para_list.append(correct_name)\n",
        "        new_sentence = sentence.replace(wrong_name, ' _ignored_ ', 1).replace(correct_name, ' _name_ ', 1)\n",
        "        # print(\"User name is not: {}, but {}.\".format(wrong_name, correct_name))\n",
        "        found += 1\n",
        "    elif mat_not:\n",
        "        wrong_name = mat_not.group(3).strip()\n",
        "        new_sentence = sentence.replace(wrong_name, ' _ignored_ ', 1)\n",
        "        # print(\"User name is not: {}.\".format(wrong_name))\n",
        "        found += 1\n",
        "    else:\n",
        "        new_sentence = sentence\n",
        "        # print(\"Wrong name not found.\")\n",
        "\n",
        "    if found >= 1:\n",
        "        return True, new_sentence, para_list\n",
        "    else:\n",
        "        return False, sentence, para_list\n",
        "\n",
        "\n",
        "def _check_username_callme_pattern_and_replace(sentence):\n",
        "    import nltk\n",
        "\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tmp_sentence = ' '.join(tokens[:]).strip()\n",
        "\n",
        "    pat_name = re.compile(r'(\\s|^)my\\s+name\\s+is\\s+(.+?)(\\s\\.|\\s,|\\s!|$)', re.IGNORECASE)\n",
        "    pat_call = re.compile(r'(\\s|^)call\\s+me\\s+(.+?)(\\s(please|pls))?(\\s\\.|\\s,|\\s!|$)', re.IGNORECASE)\n",
        "\n",
        "    mat_name = re.search(pat_name, tmp_sentence)\n",
        "    mat_call = re.search(pat_call, tmp_sentence)\n",
        "\n",
        "    para_list = []\n",
        "    found = 0\n",
        "    if mat_name:\n",
        "        user_name = mat_name.group(2).strip()\n",
        "        para_list.append(user_name)\n",
        "        new_sentence = sentence.replace(user_name, ' _name_ ', 1)\n",
        "        # print(\"User name is: {}.\".format(user_name))\n",
        "        found += 1\n",
        "    else:\n",
        "        para_list.append('')  # reserve the slot\n",
        "        new_sentence = sentence\n",
        "        # print(\"User name not found.\")\n",
        "\n",
        "    if mat_call:\n",
        "        call_me = mat_call.group(2).strip()\n",
        "        para_list.append(call_me)\n",
        "        new_sentence = new_sentence.replace(call_me, ' _callme_ ')\n",
        "        # print(\"Call me {}.\".format(call_me))\n",
        "        found += 1\n",
        "    else:\n",
        "        para_list.append('')\n",
        "        # print(\"call me not found.\")\n",
        "\n",
        "    if found >= 1:\n",
        "        return True, new_sentence, para_list\n",
        "    else:\n",
        "        return False, sentence, para_list\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sentence = \"My name is jack brown. Please call me Mr. Brown.\"\n",
        "    print(\"# {}\".format(sentence))\n",
        "    _, ns, _ = _check_username_callme_pattern_and_replace(sentence)\n",
        "    print(ns)\n",
        "\n",
        "    sentence = \"My name is Bo Shao.\"\n",
        "    print(\"# {}\".format(sentence))\n",
        "    _, ns, _ = _check_username_callme_pattern_and_replace(sentence)\n",
        "    print(ns)\n",
        "\n",
        "    sentence = \"You can call me Dr. Shao.\"\n",
        "    print(\"# {}\".format(sentence))\n",
        "    _, ns, _ = _check_username_callme_pattern_and_replace(sentence)\n",
        "    print(ns)\n",
        "\n",
        "    sentence = \"Call me Ms. Tailor please.\"\n",
        "    print(\"# {}\".format(sentence))\n",
        "    _, ns, _ = _check_username_callme_pattern_and_replace(sentence)\n",
        "    print(ns)\n",
        "\n",
        "    sentence = \"My name is Mark. Please call me Mark D.\"\n",
        "    print(\"# {}\".format(sentence))\n",
        "    _, ns, _ = _check_username_callme_pattern_and_replace(sentence)\n",
        "    print(ns)\n",
        "\n",
        "    sentence = \"My name is not just Shao, but Bo Shao.\"\n",
        "    print(\"# {}\".format(sentence))\n",
        "    _, ns, _ = _check_not_username_pattern_and_replace(sentence)\n",
        "    print(ns)\n",
        "\n",
        "    sentence = \"My name is not just Shao.\"\n",
        "    print(\"# {}\".format(sentence))\n",
        "    _, ns, _ = _check_not_username_pattern_and_replace(sentence)\n",
        "    print(ns)\n",
        "    \n",
        "import calendar as cal\n",
        "import datetime as dt\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "\n",
        "\n",
        "class FunctionData:\n",
        "    easy_list = [\n",
        "        \"\", \"\",\n",
        "        \"Here you are: \",\n",
        "        \"Here is the result: \",\n",
        "        \"That's easy: \",\n",
        "        \"That was an easy one: \",\n",
        "        \"It was a piece of cake: \",\n",
        "        \"That's simple, and I know how to solve it: \",\n",
        "        \"That wasn't hard. Here is the result: \",\n",
        "        \"Oh, I know how to deal with this: \"\n",
        "    ]\n",
        "    hard_list = [\n",
        "        \"\", \"\",\n",
        "        \"Here you are: \",\n",
        "        \"Here is the result: \",\n",
        "        \"That's a little hard: \",\n",
        "        \"That was an tough one, and I had to use a calculator: \",\n",
        "        \"That's a little difficult, but I know how to solve it: \",\n",
        "        \"It was hard and took me a little while to figure it out. Here is the result: \",\n",
        "        \"It took me a little while, and finally I got the result: \",\n",
        "        \"I had to use my cell phone for this calculation. Here is the outcome: \"\n",
        "    ]\n",
        "    ask_howru_list = [\n",
        "        \"And you?\",\n",
        "        \"How are you?\",\n",
        "        \"How about yourself?\"\n",
        "    ]\n",
        "    ask_name_list = [\n",
        "        \"May I also have your name, please?\",\n",
        "        \"Would you also like to tell me your name, please?\",\n",
        "        \"And, how should I call you, please?\",\n",
        "        \"And, what do you want me to call you, dear sir or madam?\"\n",
        "    ]\n",
        "\n",
        "    def __init__(self, knowledge_base, chat_session, html_format):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            knowledge_base: The knowledge base data needed for prediction.\n",
        "            chat_session: The chat session object that can be read and written.\n",
        "            html_format: Whether out_sentence is in HTML format.\n",
        "        \"\"\"\n",
        "        self.knowledge_base = knowledge_base\n",
        "        self.chat_session = chat_session\n",
        "        self.html_format = html_format\n",
        "\n",
        "    \"\"\"\n",
        "    # Rule 2: Date and Time\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def get_date_time():\n",
        "        return time.strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "    @staticmethod\n",
        "    def get_time():\n",
        "        return time.strftime(\"%I:%M %p\")\n",
        "\n",
        "    @staticmethod\n",
        "    def get_today():\n",
        "        return \"{:%B %d, %Y}\".format(dt.date.today())\n",
        "\n",
        "    @staticmethod\n",
        "    def get_weekday(day_delta):\n",
        "        now = dt.datetime.now()\n",
        "        if day_delta == 'd_2':\n",
        "            day_time = now - dt.timedelta(days=2)\n",
        "        elif day_delta == 'd_1':\n",
        "            day_time = now - dt.timedelta(days=1)\n",
        "        elif day_delta == 'd1':\n",
        "            day_time = now + dt.timedelta(days=1)\n",
        "        elif day_delta == 'd2':\n",
        "            day_time = now + dt.timedelta(days=2)\n",
        "        else:\n",
        "            day_time = now\n",
        "\n",
        "        weekday = cal.day_name[day_time.weekday()]\n",
        "        return \"{}, {:%B %d, %Y}\".format(weekday, day_time)\n",
        "\n",
        "    \"\"\"\n",
        "    # Rule 3: Stories and Jokes, and last topic\n",
        "    \"\"\"\n",
        "    def get_story_any(self):\n",
        "        self.chat_session.last_topic = \"STORY\"\n",
        "        self.chat_session.keep_topic = True\n",
        "\n",
        "        stories = self.knowledge_base.stories\n",
        "        _, content = random.choice(list(stories.items()))\n",
        "        if not self.html_format:\n",
        "            content = re.sub(r'_np_', '', content)\n",
        "        return content\n",
        "\n",
        "    def get_story_name(self, story_name):\n",
        "        self.chat_session.last_topic = \"STORY\"\n",
        "        self.chat_session.keep_topic = True\n",
        "\n",
        "        stories = self.knowledge_base.stories\n",
        "        content = stories[story_name]\n",
        "        if not self.html_format:\n",
        "            content = re.sub(r'_np_', '', content)\n",
        "        return content\n",
        "\n",
        "    def get_joke_any(self):\n",
        "        self.chat_session.last_topic = \"JOKE\"\n",
        "        self.chat_session.keep_topic = True\n",
        "\n",
        "        jokes = self.knowledge_base.jokes\n",
        "        content = random.choice(jokes)\n",
        "        if not self.html_format:\n",
        "            content = re.sub(r'_np_', '', content)\n",
        "        return content\n",
        "\n",
        "    def continue_last_topic(self):\n",
        "        if self.chat_session.last_topic == \"STORY\":\n",
        "            self.chat_session.keep_topic = True\n",
        "            return self.get_story_any()\n",
        "        elif self.chat_session.last_topic == \"JOKE\":\n",
        "            self.chat_session.keep_topic = True\n",
        "            return self.get_joke_any()\n",
        "        else:\n",
        "            return \"Sorry, but what topic do you prefer?\"\n",
        "\n",
        "    \"\"\"\n",
        "    # Rule 4: Arithmetic ops\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def get_number_plus(num1, num2):\n",
        "        res = num1 + num2\n",
        "        desc = random.choice(FunctionData.easy_list)\n",
        "        return \"{}{} + {} = {}\".format(desc, num1, num2, res)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_number_minus(num1, num2):\n",
        "        res = num1 - num2\n",
        "        desc = random.choice(FunctionData.easy_list)\n",
        "        return \"{}{} - {} = {}\".format(desc, num1, num2, res)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_number_multiply(num1, num2):\n",
        "        res = num1 * num2\n",
        "        if num1 > 100 and num2 > 100 and num1 % 2 == 1 and num2 % 2 == 1:\n",
        "            desc = random.choice(FunctionData.hard_list)\n",
        "        else:\n",
        "            desc = random.choice(FunctionData.easy_list)\n",
        "        return \"{}{} * {} = {}\".format(desc, num1, num2, res)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_number_divide(num1, num2):\n",
        "        if num2 == 0:\n",
        "            return \"Sorry, but that does not make sense as the divisor cannot be zero.\"\n",
        "        else:\n",
        "            res = num1 / num2\n",
        "            if isinstance(res, int):\n",
        "                if 50 < num1 != num2 > 50:\n",
        "                    desc = random.choice(FunctionData.hard_list)\n",
        "                else:\n",
        "                    desc = random.choice(FunctionData.easy_list)\n",
        "                return \"{}{} / {} = {}\".format(desc, num1, num2, res)\n",
        "            else:\n",
        "                if num1 > 20 and num2 > 20:\n",
        "                    desc = random.choice(FunctionData.hard_list)\n",
        "                else:\n",
        "                    desc = random.choice(FunctionData.easy_list)\n",
        "                return \"{}{} / {} = {:.2f}\".format(desc, num1, num2, res)\n",
        "\n",
        "    \"\"\"\n",
        "    # Rule 5: User name, call me information, and last question and answer\n",
        "    \"\"\"\n",
        "    def ask_howru_if_not_yet(self):\n",
        "        howru_asked = self.chat_session.howru_asked\n",
        "        if howru_asked:\n",
        "            return \"\"\n",
        "        else:\n",
        "            self.chat_session.howru_asked = True\n",
        "            return random.choice(FunctionData.ask_howru_list)\n",
        "\n",
        "    def ask_name_if_not_yet(self):\n",
        "        user_name = self.chat_session.user_name\n",
        "        call_me = self.chat_session.call_me\n",
        "        if user_name or call_me:\n",
        "            return \"\"\n",
        "        else:\n",
        "            return random.choice(FunctionData.ask_name_list)\n",
        "\n",
        "    def get_user_name_and_reply(self):\n",
        "        user_name = self.chat_session.user_name\n",
        "        if user_name and user_name.strip() != '':\n",
        "            return user_name\n",
        "        else:\n",
        "            return \"Did you tell me your name? Sorry, I missed that.\"\n",
        "\n",
        "    def get_callme(self, punc_type):\n",
        "        call_me = self.chat_session.call_me\n",
        "        user_name = self.chat_session.user_name\n",
        "\n",
        "        if call_me and call_me.strip() != '':\n",
        "            if punc_type == 'comma0':\n",
        "                return \", {}\".format(call_me)\n",
        "            else:\n",
        "                return call_me\n",
        "        elif user_name and user_name.strip() != '':\n",
        "            if punc_type == 'comma0':\n",
        "                return \", {}\".format(user_name)\n",
        "            else:\n",
        "                return user_name\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    def get_last_question(self):\n",
        "        # Do not record this pair as the last question and answer\n",
        "        self.chat_session.update_pair = False\n",
        "\n",
        "        last_question = self.chat_session.last_question\n",
        "        if last_question is None or last_question.strip() == '':\n",
        "            return \"You did not say anything.\"\n",
        "        else:\n",
        "            return \"You have just said: {}\".format(last_question)\n",
        "\n",
        "    def get_last_answer(self):\n",
        "        # Do not record this pair as the last question and answer\n",
        "        self.chat_session.update_pair = False\n",
        "\n",
        "        last_answer = self.chat_session.last_answer\n",
        "        if last_answer is None or last_answer.strip() == '':\n",
        "            return \"I did not say anything.\"\n",
        "        else:\n",
        "            return \"I have just said: {}\".format(last_answer)\n",
        "\n",
        "    def update_user_name(self, new_name):\n",
        "        return self.update_user_name_and_call_me(new_name=new_name)\n",
        "\n",
        "    def update_call_me(self, new_call):\n",
        "        return self.update_user_name_and_call_me(new_call=new_call)\n",
        "\n",
        "    def update_user_name_and_call_me(self, new_name=None, new_call=None):\n",
        "        user_name = self.chat_session.user_name\n",
        "        call_me = self.chat_session.call_me\n",
        "        # print(\"{}; {}; {}; {}\".format(user_name, call_me, new_name, new_call))\n",
        "\n",
        "        if user_name and new_name and new_name.strip() != '':\n",
        "            if new_name.lower() != user_name.lower():\n",
        "                self.chat_session.update_pending_action('update_user_name_confirmed', None, new_name)\n",
        "                return \"I am confused. I have your name as {}. Did I get it correctly?\".format(user_name)\n",
        "            else:\n",
        "                return \"You told me your name already. Thank you, {}, for assuring me.\".format(user_name)\n",
        "\n",
        "        if call_me and new_call and new_call.strip() != '':\n",
        "            if new_call.lower() != call_me.lower():\n",
        "                self.chat_session.update_pending_action('update_call_me_confirmed', new_call, None)\n",
        "                return \"You wanted me to call you {}. Would you like me to call you {} now?\"\\\n",
        "                    .format(call_me, new_call)\n",
        "            else:\n",
        "                return \"Thank you for letting me again, {}.\".format(call_me)\n",
        "\n",
        "        if new_call and new_call.strip() != '':\n",
        "            if new_name and new_name.strip() != '':\n",
        "                self.chat_session.user_name = new_name\n",
        "\n",
        "            self.chat_session.call_me = new_call\n",
        "            return \"Thank you, {}.\".format(new_call)\n",
        "        elif new_name and new_name.strip() != '':\n",
        "            self.chat_session.user_name = new_name\n",
        "            return \"Thank you, {}.\".format(new_name)\n",
        "\n",
        "        return \"Sorry, I am confused. I could not figure out what you meant.\"\n",
        "\n",
        "    def update_user_name_enforced(self, new_name):\n",
        "        if new_name and new_name.strip() != '':\n",
        "            self.chat_session.user_name = new_name\n",
        "            return \"OK, thank you, {}.\".format(new_name)\n",
        "        else:\n",
        "            self.chat_session.user_name = None  # Clear the existing user_name, if any.\n",
        "            return \"Sorry, I am lost.\"\n",
        "\n",
        "    def update_call_me_enforced(self, new_call):\n",
        "        if new_call and new_call.strip() != '':\n",
        "            self.chat_session.call_me = new_call\n",
        "            return \"OK, got it. Thank you, {}.\".format(new_call)\n",
        "        else:\n",
        "            self.chat_session.call_me = None  # Clear the existing call_me, if any.\n",
        "            return \"Sorry, I am totally lost.\"\n",
        "\n",
        "    def update_user_name_and_reply_papaya(self, new_name):\n",
        "        user_name = self.chat_session.user_name\n",
        "\n",
        "        if new_name and new_name.strip() != '':\n",
        "            if user_name:\n",
        "                if new_name.lower() != user_name.lower():\n",
        "                    self.chat_session.update_pending_action('update_user_name_confirmed', None, new_name)\n",
        "                    return \"I am confused. I have your name as {}. Did I get it correctly?\".format(user_name)\n",
        "                else:\n",
        "                    return \"Thank you, {}, for assuring me your name. My name is Papaya.\".format(user_name)\n",
        "            else:\n",
        "                self.chat_session.user_name = new_name\n",
        "                return \"Thank you, {}. BTW, my name is Papaya.\".format(new_name)\n",
        "        else:\n",
        "            return \"My name is Papaya. Thanks.\"\n",
        "\n",
        "    def correct_user_name(self, new_name):\n",
        "        if new_name and new_name.strip() != '':\n",
        "            self.chat_session.user_name = new_name\n",
        "            return \"Thank you, {}.\".format(new_name)\n",
        "        else:\n",
        "            # Clear the existing user_name and call_me information\n",
        "            self.chat_session.user_name = None\n",
        "            self.chat_session.call_me = None\n",
        "            return \"I am totally lost.\"\n",
        "\n",
        "    def clear_user_name_and_call_me(self):\n",
        "        self.chat_session.user_name = None\n",
        "        self.chat_session.call_me = None\n",
        "\n",
        "    def execute_pending_action_and_reply(self, answer):\n",
        "        func = self.chat_session.pending_action['func']\n",
        "        if func == 'update_user_name_confirmed':\n",
        "            if answer.lower() == 'yes':\n",
        "                reply = \"Thank you, {}, for confirming this.\".format(self.chat_session.user_name)\n",
        "            else:\n",
        "                new_name = self.chat_session.pending_action['No']\n",
        "                self.chat_session.user_name = new_name\n",
        "                reply = \"Thank you, {}, for correcting me.\".format(new_name)\n",
        "        elif func == 'update_call_me_confirmed':\n",
        "            if answer.lower() == 'yes':\n",
        "                new_call = self.chat_session.pending_action['Yes']\n",
        "                self.chat_session.call_me = new_call\n",
        "                reply = \"Thank you, {}, for correcting me.\".format(new_call)\n",
        "            else:\n",
        "                reply = \"Thank you. I will continue to call you {}.\".format(self.chat_session.call_me)\n",
        "        else:\n",
        "            reply = \"OK, thanks.\"  # Just presents a reply that is good for most situations\n",
        "\n",
        "        # Clear the pending action anyway\n",
        "        self.chat_session.clear_pending_action()\n",
        "        return reply\n",
        "\n",
        "    \"\"\"\n",
        "    # Other Rules: Client Code\n",
        "    \"\"\"\n",
        "    def client_code_show_picture_randomly(self, picture_name):\n",
        "        if not self.html_format:  # Ignored in the command line interface\n",
        "            return ''\n",
        "        else:\n",
        "            return ' _cc_start_show_picture_randomly_para1_' + picture_name + '_cc_end_'\n",
        "\n",
        "\n",
        "def call_function(func_info, knowledge_base=None, chat_session=None, para_list=None,\n",
        "                  html_format=False):\n",
        "    func_data = FunctionData(knowledge_base, chat_session, html_format=html_format)\n",
        "\n",
        "    func_dict = {\n",
        "        'get_date_time': FunctionData.get_date_time,\n",
        "        'get_time': FunctionData.get_time,\n",
        "        'get_today': FunctionData.get_today,\n",
        "        'get_weekday': FunctionData.get_weekday,\n",
        "\n",
        "        'get_story_any': func_data.get_story_any,\n",
        "        'get_story_name': func_data.get_story_name,\n",
        "        'get_joke_any': func_data.get_joke_any,\n",
        "        'continue_last_topic': func_data.continue_last_topic,\n",
        "\n",
        "        'get_number_plus': FunctionData.get_number_plus,\n",
        "        'get_number_minus': FunctionData.get_number_minus,\n",
        "        'get_number_multiply': FunctionData.get_number_multiply,\n",
        "        'get_number_divide': FunctionData.get_number_divide,\n",
        "\n",
        "        'ask_howru_if_not_yet': func_data.ask_howru_if_not_yet,\n",
        "        'ask_name_if_not_yet': func_data.ask_name_if_not_yet,\n",
        "        'get_user_name_and_reply': func_data.get_user_name_and_reply,\n",
        "        'get_callme': func_data.get_callme,\n",
        "        'get_last_question': func_data.get_last_question,\n",
        "        'get_last_answer': func_data.get_last_answer,\n",
        "\n",
        "        'update_user_name': func_data.update_user_name,\n",
        "        'update_call_me': func_data.update_call_me,\n",
        "        'update_user_name_and_call_me': func_data.update_user_name_and_call_me,\n",
        "        'update_user_name_enforced': func_data.update_user_name_enforced,\n",
        "        'update_call_me_enforced': func_data.update_call_me_enforced,\n",
        "        'update_user_name_and_reply_papaya': func_data.update_user_name_and_reply_papaya,\n",
        "\n",
        "        'correct_user_name': func_data.correct_user_name,\n",
        "        'clear_user_name_and_call_me': func_data.clear_user_name_and_call_me,\n",
        "\n",
        "        'execute_pending_action_and_reply': func_data.execute_pending_action_and_reply,\n",
        "\n",
        "        'client_code_show_picture_randomly': func_data.client_code_show_picture_randomly\n",
        "    }\n",
        "\n",
        "    para1_index = func_info.find('_para1_')\n",
        "    para2_index = func_info.find('_para2_')\n",
        "    if para1_index == -1:  # No parameter at all\n",
        "        func_name = func_info\n",
        "        if func_name in func_dict:\n",
        "            return func_dict[func_name]()\n",
        "    else:\n",
        "        func_name = func_info[:para1_index]\n",
        "        if para2_index == -1:  # Only one parameter\n",
        "            func_para = func_info[para1_index+7:]\n",
        "            if func_para == '_name_' and para_list is not None and len(para_list) >= 1:\n",
        "                return func_dict[func_name](para_list[0])\n",
        "            elif func_para == '_callme_' and para_list is not None and len(para_list) >= 2:\n",
        "                return func_dict[func_name](para_list[1])\n",
        "            else:  # The parameter value was embedded in the text (part of the string) of the training example.\n",
        "                return func_dict[func_name](func_para)\n",
        "        else:\n",
        "            func_para1 = func_info[para1_index+7:para2_index]\n",
        "            func_para2 = func_info[para2_index+7:]\n",
        "            if para_list is not None and len(para_list) >= 2:\n",
        "                para1_val = para_list[0]\n",
        "                para2_val = para_list[1]\n",
        "\n",
        "                if func_para1 == '_num1_' and func_para2 == '_num2_':\n",
        "                    return func_dict[func_name](para1_val, para2_val)\n",
        "                elif func_para1 == '_num2_' and func_para2 == '_num1_':\n",
        "                    return func_dict[func_name](para2_val, para1_val)\n",
        "                elif func_para1 == '_name_' and func_para2 == '_callme_':\n",
        "                    return func_dict[func_name](para1_val, para2_val)\n",
        "\n",
        "    return \"You beat me to it, and I cannot tell which is which for this question.\"\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "\n",
        "class BotPredictor(object):\n",
        "    def __init__(self, session, corpus_dir, knbase_dir, result_dir, result_file):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            session: The TensorFlow session.\n",
        "            corpus_dir: Name of the folder storing corpus files and vocab information.\n",
        "            knbase_dir: Name of the folder storing data files for the knowledge base.\n",
        "            result_dir: The folder containing the trained result files.\n",
        "            result_file: The file name of the trained model.\n",
        "        \"\"\"\n",
        "        self.session = session\n",
        "\n",
        "        # Prepare data and hyper parameters\n",
        "        print(\"# Prepare dataset placeholder and hyper parameters ...\")\n",
        "        tokenized_data = TokenizedData(corpus_dir=corpus_dir, training=False)\n",
        "\n",
        "        self.knowledge_base = KnowledgeBase()\n",
        "        self.knowledge_base.load_knbase(knbase_dir)\n",
        "\n",
        "        self.session_data = SessionData()\n",
        "\n",
        "        self.hparams = tokenized_data.hparams\n",
        "        self.src_placeholder = tf.placeholder(shape=[None], dtype=tf.string)\n",
        "        src_dataset = tf.data.Dataset.from_tensor_slices(self.src_placeholder)\n",
        "        self.infer_batch = tokenized_data.get_inference_batch(src_dataset)\n",
        "\n",
        "        # Create model\n",
        "        print(\"# Creating inference model ...\")\n",
        "        self.model = ModelCreator(training=False, tokenized_data=tokenized_data,\n",
        "                                  batch_input=self.infer_batch)\n",
        "        # Restore model weights\n",
        "        print(\"# Restoring model weights ...\")\n",
        "        self.model.saver.restore(session, os.path.join(result_dir, result_file))\n",
        "\n",
        "        self.session.run(tf.tables_initializer())\n",
        "\n",
        "    def predict(self, session_id, question, html_format=False):\n",
        "        chat_session = self.session_data.get_session(session_id)\n",
        "        chat_session.before_prediction()  # Reset before each prediction\n",
        "\n",
        "        if question.strip() == '':\n",
        "            answer = \"Don't you want to say something to me?\"\n",
        "            chat_session.after_prediction(question, answer)\n",
        "            return answer\n",
        "\n",
        "        pat_matched, new_sentence, para_list = check_patterns_and_replace(question)\n",
        "\n",
        "        for pre_time in range(2):\n",
        "            tokens = nltk.word_tokenize(new_sentence.lower())\n",
        "            tmp_sentence = [' '.join(tokens[:]).strip()]\n",
        "\n",
        "            self.session.run(self.infer_batch.initializer,\n",
        "                             feed_dict={self.src_placeholder: tmp_sentence})\n",
        "\n",
        "            outputs, _ = self.model.infer(self.session)\n",
        "\n",
        "            if self.hparams.beam_width > 0:\n",
        "                outputs = outputs[0]\n",
        "\n",
        "            eos_token = self.hparams.eos_token.encode(\"utf-8\")\n",
        "            outputs = outputs.tolist()[0]\n",
        "\n",
        "            if eos_token in outputs:\n",
        "                outputs = outputs[:outputs.index(eos_token)]\n",
        "\n",
        "            if pat_matched and pre_time == 0:\n",
        "                out_sentence, if_func_val = self._get_final_output(outputs, chat_session,\n",
        "                                                                   para_list=para_list,\n",
        "                                                                   html_format=html_format)\n",
        "                if if_func_val:\n",
        "                    chat_session.after_prediction(question, out_sentence)\n",
        "                    return out_sentence\n",
        "                else:\n",
        "                    new_sentence = question\n",
        "            else:\n",
        "                out_sentence, _ = self._get_final_output(outputs, chat_session,\n",
        "                                                         html_format=html_format)\n",
        "                chat_session.after_prediction(question, out_sentence)\n",
        "                return out_sentence\n",
        "\n",
        "    def _get_final_output(self, sentence, chat_session, para_list=None, html_format=False):\n",
        "        sentence = b' '.join(sentence).decode('utf-8')\n",
        "        if sentence == '':\n",
        "            return \"I don't know what to say.\", False\n",
        "\n",
        "        if_func_val = False\n",
        "        last_word = None\n",
        "        word_list = []\n",
        "        for word in sentence.split(' '):\n",
        "            word = word.strip()\n",
        "            if not word:\n",
        "                continue\n",
        "\n",
        "            if word.startswith('_func_val_'):\n",
        "                if_func_val = True\n",
        "                word = call_function(word[10:], knowledge_base=self.knowledge_base,\n",
        "                                     chat_session=chat_session, para_list=para_list,\n",
        "                                     html_format=html_format)\n",
        "                if word is None or word == '':\n",
        "                    continue\n",
        "            else:\n",
        "                if word in self.knowledge_base.upper_words:\n",
        "                    word = self.knowledge_base.upper_words[word]\n",
        "\n",
        "                if (last_word is None or last_word in ['.', '!', '?']) and not word[0].isupper():\n",
        "                    word = word.capitalize()\n",
        "\n",
        "            if not word.startswith('\\'') and word != 'n\\'t' \\\n",
        "                and (word[0] not in string.punctuation or word in ['(', '[', '{', '``', '$']) \\\n",
        "                and last_word not in ['(', '[', '{', '``', '$']:\n",
        "                word = ' ' + word\n",
        "\n",
        "            word_list.append(word)\n",
        "            last_word = word\n",
        "\n",
        "        return ''.join(word_list).strip(), if_func_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1gO1hZCdGYD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "PROJECT_ROOT = \"drive/AgateV2\"\n",
        "\n",
        "def initBot():\n",
        "    try:\n",
        "        answer = callBot(\"Hi\")\n",
        "    except:\n",
        "        global predictor\n",
        "        predictor = BotPredictor(tf.Session(), corpus_dir=os.path.join(PROJECT_ROOT, 'Data', 'Corpus'), knbase_dir=os.path.join(PROJECT_ROOT, 'Data', 'KnowledgeBase'), result_dir=os.path.join(PROJECT_ROOT, 'Data', 'Result'), result_file='basic')\n",
        "        global session_id \n",
        "        session_id = predictor.session_data.add_session()\n",
        "\n",
        "def callBot(sentence):\n",
        "    return predictor.predict(session_id, sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mtoFqilqLDzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "client = Bot(description=\"JADE AI\", command_prefix=\"\", pm_help = False)\n",
        "setup(client)\n",
        "\n",
        "@client.event\n",
        "async def on_ready():\n",
        "    initBot()\n",
        "    print('Logged in as '+client.user.name+' (ID:'+client.user.id+') | Connected to '+str(len(client.servers))+' servers | Connected to '+ str(len(set(client.get_all_members()))) +' users')\n",
        "    print('--------')\n",
        "    print('You are running Agate AI v0.2') #Do not change this. This will really help us support you, if you need support.\n",
        "    print('--------')\n",
        "    resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
        "    return await client.change_presence(game=discord.Game(name=\"with my sister, Jade! ||| I've been invited to \"+str(len(client.servers))+\" homes, and \"+ str(len(set(client.get_all_members())))+ \" people are my friends! ||| AG is my prefix!\")) #This is buggy, let us know if it doesn't work."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3D0chZZKLXpG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@client.event\n",
        "async def on_message(message):\n",
        "  if not message.server == None and not message.author.bot:\n",
        "    if message.content.startswith('AG ') or message.content.startswith('ag '):\n",
        "        initBot()\n",
        "        ModMessage = message.content[3:]\n",
        "        print('\\n' + str(message.server) + '\\n' + str(message.author) + \": \" + ModMessage)\n",
        "        ModMessage = ModMessage.replace(\"Agate\", \"Papaya\")\n",
        "        await client.send_typing(message.channel)\n",
        "        if ModMessage == \"Play GO\":\n",
        "          await run(message.channel)\n",
        "        answer = callBot(ModMessage)\n",
        "        answer = answer.replace(\"Papaya\", \"Agate\")\n",
        "        answer = answer.replace(\"father\", \"daughter\")\n",
        "        answer = answer.replace(\"male\", \"female\")\n",
        "        answer = answer.replace(\"boy\", \"girl\")\n",
        "        answer = answer.replace(\"Although being a robot, I look like a normal 9 year old boy.\", \"I look pretty good ;D\")\n",
        "        if ModMessage.lower == \"what's your memory usage?\":\n",
        "          process = psutil.Process(os.getpid())\n",
        "          answer = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
        "        await client.send_message(message.channel, answer)\n",
        "        print(\"Agate: \" + answer)\n",
        "        \n",
        "  elif message.server == None and not message.author.bot:\n",
        "        initBot()\n",
        "        print('\\n' + str(message.server) + '\\n' + str(message.author) + \": \" + message.content)\n",
        "        ModMessage = message.content.replace(\"Agate\", \"Papaya\")\n",
        "        await client.send_typing(message.channel)\n",
        "        if ModMessage == \"Play GO\":\n",
        "          await run(message.channel)\n",
        "        answer = callBot(ModMessage)\n",
        "        answer = answer.replace(\"Papaya\", \"Agate\")\n",
        "        answer = answer.replace(\"father\", \"daughter\")\n",
        "        answer = answer.replace(\"male\", \"female\")\n",
        "        answer = answer.replace(\"boy\", \"girl\")\n",
        "        answer = answer.replace(\"Although being a robot, I look like a normal 9 year old boy.\", \"I look pretty good ;D\")\n",
        "        if ModMessage.lower == \"what's your memory usage?\":\n",
        "          answer = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
        "        await client.send_message(message.channel, answer)\n",
        "        print(\"Agate: \" + answer)\n",
        "        \n",
        "  await client.change_presence(game=discord.Game(name=\"with my sister, Jade! ||| I've been invited to \"+str(len(client.servers))+\" homes, and \"+ str(len(set(client.get_all_members())))+ \" people are my friends! ||| AG is my prefix!\"))\n",
        "        \n",
        "client.run('Token')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
